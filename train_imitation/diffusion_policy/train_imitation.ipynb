{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "success_rate, time_taken, distance_travelled, straight_distance, (optimal_time or dijsktra_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_718</th>\n",
       "      <th>lidar_719</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.975059</td>\n",
       "      <td>2.950377</td>\n",
       "      <td>2.938696</td>\n",
       "      <td>2.933910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950528</td>\n",
       "      <td>2.976332</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.570909</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.975632</td>\n",
       "      <td>2.949891</td>\n",
       "      <td>2.938163</td>\n",
       "      <td>2.934393</td>\n",
       "      <td>...</td>\n",
       "      <td>2.949972</td>\n",
       "      <td>2.976789</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.570903</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.974015</td>\n",
       "      <td>2.950373</td>\n",
       "      <td>2.940136</td>\n",
       "      <td>2.935323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.951352</td>\n",
       "      <td>2.975511</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>1.570919</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.972146</td>\n",
       "      <td>2.951025</td>\n",
       "      <td>2.939157</td>\n",
       "      <td>2.935039</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950131</td>\n",
       "      <td>2.976381</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.570933</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.974818</td>\n",
       "      <td>2.951458</td>\n",
       "      <td>2.940485</td>\n",
       "      <td>2.935588</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950873</td>\n",
       "      <td>2.976459</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.570969</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  actual_time  optimal_time  goal_x  goal_y  world_idx   lidar_0  \\\n",
       "0     True       16.639      6.796149     0.0    10.0          0  2.975059   \n",
       "1     True       16.639      6.796149     0.0    10.0          0  2.975632   \n",
       "2     True       16.639      6.796149     0.0    10.0          0  2.974015   \n",
       "3     True       16.639      6.796149     0.0    10.0          0  2.972146   \n",
       "4     True       16.639      6.796149     0.0    10.0          0  2.974818   \n",
       "\n",
       "    lidar_1   lidar_2   lidar_3  ...  lidar_718  lidar_719     pos_x  \\\n",
       "0  2.950377  2.938696  2.933910  ...   2.950528   2.976332 -0.000009   \n",
       "1  2.949891  2.938163  2.934393  ...   2.949972   2.976789 -0.000009   \n",
       "2  2.950373  2.940136  2.935323  ...   2.951352   2.975511 -0.000009   \n",
       "3  2.951025  2.939157  2.935039  ...   2.950131   2.976381 -0.000009   \n",
       "4  2.951458  2.940485  2.935588  ...   2.950873   2.976459 -0.000009   \n",
       "\n",
       "      pos_y  pose_heading  twist_linear  twist_angular  cmd_vel_linear  \\\n",
       "0  0.000073      1.570909      0.000043       0.008641           0.006   \n",
       "1  0.000073      1.570903      0.000043       0.003630           0.012   \n",
       "2  0.000193      1.570919      0.003106       0.004454           0.018   \n",
       "3  0.000432      1.570933      0.007701       0.001190           0.024   \n",
       "4  0.000792      1.570969      0.013069       0.005987           0.030   \n",
       "\n",
       "   cmd_vel_angular  timestep  \n",
       "0         0.000665         0  \n",
       "1         0.001330         1  \n",
       "2         0.001996         2  \n",
       "3         0.002661         3  \n",
       "4         0.003326         4  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data_sorted.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_718</th>\n",
       "      <th>lidar_719</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.975059</td>\n",
       "      <td>2.950377</td>\n",
       "      <td>2.938696</td>\n",
       "      <td>2.933910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950528</td>\n",
       "      <td>2.976332</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.570909</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.975632</td>\n",
       "      <td>2.949891</td>\n",
       "      <td>2.938163</td>\n",
       "      <td>2.934393</td>\n",
       "      <td>...</td>\n",
       "      <td>2.949972</td>\n",
       "      <td>2.976789</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.570903</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.974015</td>\n",
       "      <td>2.950373</td>\n",
       "      <td>2.940136</td>\n",
       "      <td>2.935323</td>\n",
       "      <td>...</td>\n",
       "      <td>2.951352</td>\n",
       "      <td>2.975511</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>1.570919</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.972146</td>\n",
       "      <td>2.951025</td>\n",
       "      <td>2.939157</td>\n",
       "      <td>2.935039</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950131</td>\n",
       "      <td>2.976381</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.570933</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.974818</td>\n",
       "      <td>2.951458</td>\n",
       "      <td>2.940485</td>\n",
       "      <td>2.935588</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950873</td>\n",
       "      <td>2.976459</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1.570969</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  actual_time  optimal_time  goal_x  goal_y  world_idx   lidar_0  \\\n",
       "0     True       16.639      6.796149     0.0    10.0          0  2.975059   \n",
       "1     True       16.639      6.796149     0.0    10.0          0  2.975632   \n",
       "2     True       16.639      6.796149     0.0    10.0          0  2.974015   \n",
       "3     True       16.639      6.796149     0.0    10.0          0  2.972146   \n",
       "4     True       16.639      6.796149     0.0    10.0          0  2.974818   \n",
       "\n",
       "    lidar_1   lidar_2   lidar_3  ...  lidar_718  lidar_719     pos_x  \\\n",
       "0  2.950377  2.938696  2.933910  ...   2.950528   2.976332 -0.000009   \n",
       "1  2.949891  2.938163  2.934393  ...   2.949972   2.976789 -0.000009   \n",
       "2  2.950373  2.940136  2.935323  ...   2.951352   2.975511 -0.000009   \n",
       "3  2.951025  2.939157  2.935039  ...   2.950131   2.976381 -0.000009   \n",
       "4  2.951458  2.940485  2.935588  ...   2.950873   2.976459 -0.000009   \n",
       "\n",
       "      pos_y  pose_heading  twist_linear  twist_angular  cmd_vel_linear  \\\n",
       "0  0.000073      1.570909      0.000043       0.008641           0.006   \n",
       "1  0.000073      1.570903      0.000043       0.003630           0.012   \n",
       "2  0.000193      1.570919      0.003106       0.004454           0.018   \n",
       "3  0.000432      1.570933      0.007701       0.001190           0.024   \n",
       "4  0.000792      1.570969      0.013069       0.005987           0.030   \n",
       "\n",
       "   cmd_vel_angular  timestep  \n",
       "0         0.000665         0  \n",
       "1         0.001330         1  \n",
       "2         0.001996         2  \n",
       "3         0.002661         3  \n",
       "4         0.003326         4  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all lidar 30 to 10\n",
    "lidar_cols = [col for col in df.columns if 'lidar' in col]\n",
    "\n",
    "# only apply when x == 30\n",
    "df[lidar_cols] = df[lidar_cols].applymap(lambda x: x/3 if x == 30.0 else x)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>lidar_4</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_718</th>\n",
       "      <th>lidar_719</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.0</td>\n",
       "      <td>202569.0</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.902522</td>\n",
       "      <td>5.715869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>151.958370</td>\n",
       "      <td>2.967450</td>\n",
       "      <td>2.963673</td>\n",
       "      <td>2.958833</td>\n",
       "      <td>2.954727</td>\n",
       "      <td>2.950740</td>\n",
       "      <td>...</td>\n",
       "      <td>2.974099</td>\n",
       "      <td>2.981155</td>\n",
       "      <td>-0.040379</td>\n",
       "      <td>4.130155</td>\n",
       "      <td>1.548915</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.705616</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>343.772685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.451819</td>\n",
       "      <td>0.375246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.229118</td>\n",
       "      <td>2.081454</td>\n",
       "      <td>2.094368</td>\n",
       "      <td>2.106192</td>\n",
       "      <td>2.118302</td>\n",
       "      <td>2.130334</td>\n",
       "      <td>...</td>\n",
       "      <td>2.211840</td>\n",
       "      <td>2.201695</td>\n",
       "      <td>0.530169</td>\n",
       "      <td>2.789321</td>\n",
       "      <td>0.385390</td>\n",
       "      <td>0.211738</td>\n",
       "      <td>0.259670</td>\n",
       "      <td>0.208302</td>\n",
       "      <td>0.233824</td>\n",
       "      <td>210.896994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.784000</td>\n",
       "      <td>5.026614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292403</td>\n",
       "      <td>0.291040</td>\n",
       "      <td>0.289275</td>\n",
       "      <td>0.287048</td>\n",
       "      <td>0.286279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292182</td>\n",
       "      <td>0.293237</td>\n",
       "      <td>-1.714366</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.141397</td>\n",
       "      <td>-0.337823</td>\n",
       "      <td>-2.126267</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.937000</td>\n",
       "      <td>5.446358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.691495</td>\n",
       "      <td>1.684698</td>\n",
       "      <td>1.677570</td>\n",
       "      <td>1.671675</td>\n",
       "      <td>1.666527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.601476</td>\n",
       "      <td>1.608613</td>\n",
       "      <td>-0.308475</td>\n",
       "      <td>1.634119</td>\n",
       "      <td>1.465763</td>\n",
       "      <td>0.799501</td>\n",
       "      <td>-0.062289</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.067353</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.136000</td>\n",
       "      <td>5.617254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>2.879177</td>\n",
       "      <td>2.865790</td>\n",
       "      <td>2.851509</td>\n",
       "      <td>2.837667</td>\n",
       "      <td>2.824436</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823026</td>\n",
       "      <td>2.836414</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>4.026890</td>\n",
       "      <td>1.578731</td>\n",
       "      <td>0.800233</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.518000</td>\n",
       "      <td>5.922971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>3.195433</td>\n",
       "      <td>3.179926</td>\n",
       "      <td>3.163331</td>\n",
       "      <td>3.149627</td>\n",
       "      <td>3.134901</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162534</td>\n",
       "      <td>3.180164</td>\n",
       "      <td>0.208518</td>\n",
       "      <td>6.519710</td>\n",
       "      <td>1.678931</td>\n",
       "      <td>0.801077</td>\n",
       "      <td>0.044440</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.052444</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.686000</td>\n",
       "      <td>6.867653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.653924</td>\n",
       "      <td>9.367064</td>\n",
       "      <td>3.140065</td>\n",
       "      <td>0.811978</td>\n",
       "      <td>2.186863</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>1375.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 733 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_time   optimal_time    goal_x    goal_y      world_idx  \\\n",
       "count  202569.000000  202569.000000  202569.0  202569.0  202569.000000   \n",
       "mean       12.902522       5.715869       0.0      10.0     151.958370   \n",
       "std         2.451819       0.375246       0.0       0.0      87.229118   \n",
       "min        11.784000       5.026614       0.0      10.0       0.000000   \n",
       "25%        11.937000       5.446358       0.0      10.0      76.000000   \n",
       "50%        12.136000       5.617254       0.0      10.0     153.000000   \n",
       "75%        12.518000       5.922971       0.0      10.0     228.000000   \n",
       "max        26.686000       6.867653       0.0      10.0     299.000000   \n",
       "\n",
       "             lidar_0        lidar_1        lidar_2        lidar_3  \\\n",
       "count  202569.000000  202569.000000  202569.000000  202569.000000   \n",
       "mean        2.967450       2.963673       2.958833       2.954727   \n",
       "std         2.081454       2.094368       2.106192       2.118302   \n",
       "min         0.292403       0.291040       0.289275       0.287048   \n",
       "25%         1.691495       1.684698       1.677570       1.671675   \n",
       "50%         2.879177       2.865790       2.851509       2.837667   \n",
       "75%         3.195433       3.179926       3.163331       3.149627   \n",
       "max        10.000000      10.000000      10.000000      10.000000   \n",
       "\n",
       "             lidar_4  ...      lidar_718      lidar_719          pos_x  \\\n",
       "count  202569.000000  ...  202569.000000  202569.000000  202569.000000   \n",
       "mean        2.950740  ...       2.974099       2.981155      -0.040379   \n",
       "std         2.130334  ...       2.211840       2.201695       0.530169   \n",
       "min         0.286279  ...       0.292182       0.293237      -1.714366   \n",
       "25%         1.666527  ...       1.601476       1.608613      -0.308475   \n",
       "50%         2.824436  ...       2.823026       2.836414      -0.006654   \n",
       "75%         3.134901  ...       3.162534       3.180164       0.208518   \n",
       "max        10.000000  ...      10.000000      10.000000       1.653924   \n",
       "\n",
       "               pos_y   pose_heading   twist_linear  twist_angular  \\\n",
       "count  202569.000000  202569.000000  202569.000000  202569.000000   \n",
       "mean        4.130155       1.548915       0.704698      -0.003710   \n",
       "std         2.789321       0.385390       0.211738       0.259670   \n",
       "min        -0.000258      -3.141397      -0.337823      -2.126267   \n",
       "25%         1.634119       1.465763       0.799501      -0.062289   \n",
       "50%         4.026890       1.578731       0.800233      -0.001211   \n",
       "75%         6.519710       1.678931       0.801077       0.044440   \n",
       "max         9.367064       3.140065       0.811978       2.186863   \n",
       "\n",
       "       cmd_vel_linear  cmd_vel_angular       timestep  \n",
       "count   202569.000000    202569.000000  202569.000000  \n",
       "mean         0.705616        -0.002722     343.772685  \n",
       "std          0.208302         0.233824     210.896994  \n",
       "min         -0.300000        -1.570796       0.000000  \n",
       "25%          0.800000        -0.067353     168.000000  \n",
       "50%          0.800000         0.000042     337.000000  \n",
       "75%          0.800000         0.052444     506.000000  \n",
       "max          0.800000         1.570796    1375.000000  \n",
       "\n",
       "[8 rows x 733 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_718</th>\n",
       "      <th>lidar_719</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666581</td>\n",
       "      <td>3.652730</td>\n",
       "      <td>3.649681</td>\n",
       "      <td>3.584681</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.154316</td>\n",
       "      <td>9.090973</td>\n",
       "      <td>1.470047</td>\n",
       "      <td>0.799829</td>\n",
       "      <td>-0.120723</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.089870</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.675501</td>\n",
       "      <td>3.662295</td>\n",
       "      <td>3.660145</td>\n",
       "      <td>3.589608</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.152694</td>\n",
       "      <td>9.106894</td>\n",
       "      <td>1.467542</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>-0.127706</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.096375</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.685948</td>\n",
       "      <td>3.674437</td>\n",
       "      <td>3.672085</td>\n",
       "      <td>3.594452</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.150949</td>\n",
       "      <td>9.123609</td>\n",
       "      <td>1.464971</td>\n",
       "      <td>0.800214</td>\n",
       "      <td>-0.124623</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.096375</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.692733</td>\n",
       "      <td>3.684892</td>\n",
       "      <td>3.685170</td>\n",
       "      <td>3.596872</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.149249</td>\n",
       "      <td>9.139523</td>\n",
       "      <td>1.462841</td>\n",
       "      <td>0.800263</td>\n",
       "      <td>-0.112804</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.096375</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>True</td>\n",
       "      <td>16.639</td>\n",
       "      <td>6.796149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.700053</td>\n",
       "      <td>3.694029</td>\n",
       "      <td>3.696630</td>\n",
       "      <td>3.597999</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.147606</td>\n",
       "      <td>9.154639</td>\n",
       "      <td>1.461815</td>\n",
       "      <td>0.800296</td>\n",
       "      <td>-0.058685</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.075198</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     success  actual_time  optimal_time  goal_x  goal_y  world_idx   lidar_0  \\\n",
       "877     True       16.639      6.796149     0.0    10.0          0  3.666581   \n",
       "878     True       16.639      6.796149     0.0    10.0          0  3.675501   \n",
       "879     True       16.639      6.796149     0.0    10.0          0  3.685948   \n",
       "880     True       16.639      6.796149     0.0    10.0          0  3.692733   \n",
       "881     True       16.639      6.796149     0.0    10.0          0  3.700053   \n",
       "\n",
       "      lidar_1   lidar_2   lidar_3  ...  lidar_718  lidar_719     pos_x  \\\n",
       "877  3.652730  3.649681  3.584681  ...       10.0       10.0 -0.154316   \n",
       "878  3.662295  3.660145  3.589608  ...       10.0       10.0 -0.152694   \n",
       "879  3.674437  3.672085  3.594452  ...       10.0       10.0 -0.150949   \n",
       "880  3.684892  3.685170  3.596872  ...       10.0       10.0 -0.149249   \n",
       "881  3.694029  3.696630  3.597999  ...       10.0       10.0 -0.147606   \n",
       "\n",
       "        pos_y  pose_heading  twist_linear  twist_angular  cmd_vel_linear  \\\n",
       "877  9.090973      1.470047      0.799829      -0.120723             0.8   \n",
       "878  9.106894      1.467542      0.800057      -0.127706             0.8   \n",
       "879  9.123609      1.464971      0.800214      -0.124623             0.8   \n",
       "880  9.139523      1.462841      0.800263      -0.112804             0.8   \n",
       "881  9.154639      1.461815      0.800296      -0.058685             0.8   \n",
       "\n",
       "     cmd_vel_angular  timestep  \n",
       "877        -0.089870       877  \n",
       "878        -0.096375       878  \n",
       "879        -0.096375       879  \n",
       "880        -0.096375       880  \n",
       "881        -0.075198       881  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check last step of world_idx 0\n",
    "df[df['world_idx'] == 0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>lidar_4</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_718</th>\n",
       "      <th>lidar_719</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.0</td>\n",
       "      <td>202569.0</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "      <td>202569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.902522</td>\n",
       "      <td>5.715869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>151.958370</td>\n",
       "      <td>2.967450</td>\n",
       "      <td>2.963673</td>\n",
       "      <td>2.958833</td>\n",
       "      <td>2.954727</td>\n",
       "      <td>2.950740</td>\n",
       "      <td>...</td>\n",
       "      <td>2.974099</td>\n",
       "      <td>2.981155</td>\n",
       "      <td>-0.040379</td>\n",
       "      <td>4.130155</td>\n",
       "      <td>1.548915</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.705616</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>343.772685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.451819</td>\n",
       "      <td>0.375246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.229118</td>\n",
       "      <td>2.081454</td>\n",
       "      <td>2.094368</td>\n",
       "      <td>2.106192</td>\n",
       "      <td>2.118302</td>\n",
       "      <td>2.130334</td>\n",
       "      <td>...</td>\n",
       "      <td>2.211840</td>\n",
       "      <td>2.201695</td>\n",
       "      <td>0.530169</td>\n",
       "      <td>2.789321</td>\n",
       "      <td>0.385390</td>\n",
       "      <td>0.211738</td>\n",
       "      <td>0.259670</td>\n",
       "      <td>0.208302</td>\n",
       "      <td>0.233824</td>\n",
       "      <td>210.896994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.784000</td>\n",
       "      <td>5.026614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292403</td>\n",
       "      <td>0.291040</td>\n",
       "      <td>0.289275</td>\n",
       "      <td>0.287048</td>\n",
       "      <td>0.286279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292182</td>\n",
       "      <td>0.293237</td>\n",
       "      <td>-1.714366</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.141397</td>\n",
       "      <td>-0.337823</td>\n",
       "      <td>-2.126267</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.937000</td>\n",
       "      <td>5.446358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.691495</td>\n",
       "      <td>1.684698</td>\n",
       "      <td>1.677570</td>\n",
       "      <td>1.671675</td>\n",
       "      <td>1.666527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.601476</td>\n",
       "      <td>1.608613</td>\n",
       "      <td>-0.308475</td>\n",
       "      <td>1.634119</td>\n",
       "      <td>1.465763</td>\n",
       "      <td>0.799501</td>\n",
       "      <td>-0.062289</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.067353</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.136000</td>\n",
       "      <td>5.617254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>2.879177</td>\n",
       "      <td>2.865790</td>\n",
       "      <td>2.851509</td>\n",
       "      <td>2.837667</td>\n",
       "      <td>2.824436</td>\n",
       "      <td>...</td>\n",
       "      <td>2.823026</td>\n",
       "      <td>2.836414</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>4.026890</td>\n",
       "      <td>1.578731</td>\n",
       "      <td>0.800233</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.518000</td>\n",
       "      <td>5.922971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>3.195433</td>\n",
       "      <td>3.179926</td>\n",
       "      <td>3.163331</td>\n",
       "      <td>3.149627</td>\n",
       "      <td>3.134901</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162534</td>\n",
       "      <td>3.180164</td>\n",
       "      <td>0.208518</td>\n",
       "      <td>6.519710</td>\n",
       "      <td>1.678931</td>\n",
       "      <td>0.801077</td>\n",
       "      <td>0.044440</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.052444</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.686000</td>\n",
       "      <td>6.867653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.653924</td>\n",
       "      <td>9.367064</td>\n",
       "      <td>3.140065</td>\n",
       "      <td>0.811978</td>\n",
       "      <td>2.186863</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>1375.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 733 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_time   optimal_time    goal_x    goal_y      world_idx  \\\n",
       "count  202569.000000  202569.000000  202569.0  202569.0  202569.000000   \n",
       "mean       12.902522       5.715869       0.0      10.0     151.958370   \n",
       "std         2.451819       0.375246       0.0       0.0      87.229118   \n",
       "min        11.784000       5.026614       0.0      10.0       0.000000   \n",
       "25%        11.937000       5.446358       0.0      10.0      76.000000   \n",
       "50%        12.136000       5.617254       0.0      10.0     153.000000   \n",
       "75%        12.518000       5.922971       0.0      10.0     228.000000   \n",
       "max        26.686000       6.867653       0.0      10.0     299.000000   \n",
       "\n",
       "             lidar_0        lidar_1        lidar_2        lidar_3  \\\n",
       "count  202569.000000  202569.000000  202569.000000  202569.000000   \n",
       "mean        2.967450       2.963673       2.958833       2.954727   \n",
       "std         2.081454       2.094368       2.106192       2.118302   \n",
       "min         0.292403       0.291040       0.289275       0.287048   \n",
       "25%         1.691495       1.684698       1.677570       1.671675   \n",
       "50%         2.879177       2.865790       2.851509       2.837667   \n",
       "75%         3.195433       3.179926       3.163331       3.149627   \n",
       "max        10.000000      10.000000      10.000000      10.000000   \n",
       "\n",
       "             lidar_4  ...      lidar_718      lidar_719          pos_x  \\\n",
       "count  202569.000000  ...  202569.000000  202569.000000  202569.000000   \n",
       "mean        2.950740  ...       2.974099       2.981155      -0.040379   \n",
       "std         2.130334  ...       2.211840       2.201695       0.530169   \n",
       "min         0.286279  ...       0.292182       0.293237      -1.714366   \n",
       "25%         1.666527  ...       1.601476       1.608613      -0.308475   \n",
       "50%         2.824436  ...       2.823026       2.836414      -0.006654   \n",
       "75%         3.134901  ...       3.162534       3.180164       0.208518   \n",
       "max        10.000000  ...      10.000000      10.000000       1.653924   \n",
       "\n",
       "               pos_y   pose_heading   twist_linear  twist_angular  \\\n",
       "count  202569.000000  202569.000000  202569.000000  202569.000000   \n",
       "mean        4.130155       1.548915       0.704698      -0.003710   \n",
       "std         2.789321       0.385390       0.211738       0.259670   \n",
       "min        -0.000258      -3.141397      -0.337823      -2.126267   \n",
       "25%         1.634119       1.465763       0.799501      -0.062289   \n",
       "50%         4.026890       1.578731       0.800233      -0.001211   \n",
       "75%         6.519710       1.678931       0.801077       0.044440   \n",
       "max         9.367064       3.140065       0.811978       2.186863   \n",
       "\n",
       "       cmd_vel_linear  cmd_vel_angular       timestep  \n",
       "count   202569.000000    202569.000000  202569.000000  \n",
       "mean         0.705616        -0.002722     343.772685  \n",
       "std          0.208302         0.233824     210.896994  \n",
       "min         -0.300000        -1.570796       0.000000  \n",
       "25%          0.800000        -0.067353     168.000000  \n",
       "50%          0.800000         0.000042     337.000000  \n",
       "75%          0.800000         0.052444     506.000000  \n",
       "max          0.800000         1.570796    1375.000000  \n",
       "\n",
       "[8 rows x 733 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class KULBarnDataset(Dataset):\n",
    "    def get_local_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        self.data['local_x'] = (goal_x - x) * np.cos(theta) + (goal_y - y) * np.sin(theta)\n",
    "        self.data['local_y'] = -(goal_x - x) * np.sin(theta) + (goal_y - y) * np.cos(theta)\n",
    "        self.data['distance'] = np.sqrt((goal_x - x)**2 + (goal_y - y)**2)\n",
    "        self.data['local_x'] /= self.data['distance']\n",
    "        self.data['local_y'] /= self.data['distance']\n",
    "    \n",
    "    def __init__(self, df, mode=\"train\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = df\n",
    "        self.get_local_goal()  \n",
    "        \n",
    "        self.data = self.data.drop(columns=[\n",
    "            'world_idx', 'timestep', 'actual_time', 'optimal_time', 'success'\n",
    "        ])\n",
    "\n",
    "        # get all the column values that contain the word lidar\n",
    "        self.lidar_cols = [\"lidar_\" + str(i) for i in range(0, 720, 1)]\n",
    "        # get actions columns\n",
    "        # self.actions_cols = ['cmd_vel_linear', 'cmd_vel_angular']\n",
    "        self.actions_cols = ['cmd_vel_angular']\n",
    "        # get other columns\n",
    "        self.non_lidar_cols = ['twist_linear', 'twist_angular', 'local_x', 'local_y', 'distance', 'pose_heading']\n",
    "\n",
    "        if mode == \"train\":\n",
    "            # Manually compute the min and max values for each column\n",
    "            self.min = self.data.min()\n",
    "            self.max = self.data.max()\n",
    "\n",
    "            # Save the mean and std to a JSON file\n",
    "            scaler_params = {\n",
    "                'min': self.min.to_dict(),\n",
    "                'max': self.max.to_dict()\n",
    "            }\n",
    "            with open('scaler_params.json', 'w') as f:\n",
    "                json.dump(scaler_params, f)\n",
    "        else:\n",
    "            # Load the mean and std from the JSON file\n",
    "            with open('scaler_params.json', 'r') as f:\n",
    "                scaler_params = json.load(f)\n",
    "            self.min = pd.Series(scaler_params['min'])\n",
    "            self.max = pd.Series(scaler_params['max'])\n",
    "        \n",
    "        # dont normalizer local_x and local_y\n",
    "        self.normalized_data = (self.data - self.min) / (self.max - self.min)\n",
    "        self.normalized_data[['local_x', 'local_y']] = self.data[['local_x', 'local_y']]\n",
    "        \n",
    "        self.lidar_data = self.normalized_data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.normalized_data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.normalized_data[self.actions_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lidar = self.lidar_data[idx]\n",
    "        non_lidar = self.non_lidar_data[idx]\n",
    "        actions = self.actions_data[idx]\n",
    "        return lidar, non_lidar, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "import random\n",
    "# set random seed\n",
    "random.seed(42)\n",
    "\n",
    "NO_WORLDS = 300\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "world_ids = [i for i in range(NO_WORLDS)]\n",
    "test_ids = [id for id in range(0, NO_WORLDS, 5)]\n",
    "train_evals = [id for id in world_ids if id not in test_ids]\n",
    "train_ids = random.sample(train_evals, int(NO_WORLDS * TRAIN_RATIO))\n",
    "val_ids = [id for id in train_evals if id not in train_ids]\n",
    "\n",
    "train_df = df[df['world_idx'].isin(train_ids)]\n",
    "val_df = df[df['world_idx'].isin(val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "30\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids))\n",
    "print(len(val_ids))\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 27, 37, 56, 57, 83, 98, 106, 107, 132, 142, 144, 149, 153, 154, 158, 166, 176, 187, 194, 221, 238, 242, 247, 253, 258, 262, 278, 286, 289]\n"
     ]
    }
   ],
   "source": [
    "print(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141967\n",
      "20248\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KULBarnDataset(train_df, \"train\")\n",
    "val_dataset = KULBarnDataset(val_df, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 141967\n",
      "Val Dataset Length: 20248\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Length:\", len(train_dataset))\n",
    "print(\"Val Dataset Length:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non lidar shape: torch.Size([64, 6])\n",
      "Lidar shape: torch.Size([64, 720])\n",
      "Train loader size: 2219\n",
      "Val loader size: 317\n",
      "tensor([[0.1349, 0.1342, 0.1341,  ..., 0.2026, 0.2024, 0.2026],\n",
      "        [0.2472, 0.2461, 0.2457,  ..., 0.4628, 0.4740, 0.4694],\n",
      "        [0.2554, 0.2557, 0.2564,  ..., 0.3171, 0.3188, 0.3285],\n",
      "        ...,\n",
      "        [0.2815, 0.2746, 0.2722,  ..., 0.2721, 0.2739, 0.2815],\n",
      "        [0.3674, 0.3670, 0.3557,  ..., 0.0370, 0.0372, 0.0376],\n",
      "        [0.3249, 0.3224, 0.3213,  ..., 0.2421, 0.2455, 0.2491]],\n",
      "       dtype=torch.float64) tensor([[ 9.9221e-01,  4.7796e-01,  9.9237e-01, -1.2326e-01,  6.4269e-01,\n",
      "          7.5640e-01],\n",
      "        [ 9.9277e-01,  5.2382e-01,  8.7925e-01, -4.7636e-01,  8.2362e-01,\n",
      "          8.2051e-01],\n",
      "        [ 9.9284e-01,  4.8625e-01,  9.7745e-01, -2.1118e-01,  8.4190e-01,\n",
      "          7.8045e-01],\n",
      "        [ 2.9252e-01,  7.3219e-01, -1.2427e-01, -9.9225e-01,  4.8490e-01,\n",
      "          1.9115e-02],\n",
      "        [ 3.2979e-01,  2.5446e-01,  4.0205e-01,  9.1562e-01,  5.2613e-01,\n",
      "          5.2908e-01],\n",
      "        [ 9.9020e-01,  4.6528e-01,  9.9618e-01, -8.7375e-02,  3.7962e-02,\n",
      "          7.3331e-01],\n",
      "        [ 9.9007e-01,  5.1403e-01,  9.9751e-01,  7.0560e-02,  5.4626e-01,\n",
      "          7.4533e-01],\n",
      "        [ 9.9107e-01,  5.9637e-01,  9.7597e-01, -2.1792e-01,  5.7842e-01,\n",
      "          7.6957e-01],\n",
      "        [ 5.6730e-01,  4.8513e-01,  9.9992e-01, -1.2490e-02,  9.8162e-01,\n",
      "          7.5215e-01],\n",
      "        [ 9.8976e-01,  4.9093e-01,  9.9901e-01,  4.4509e-02,  7.2558e-02,\n",
      "          7.5975e-01],\n",
      "        [ 3.7309e-01,  4.8523e-01,  1.0000e+00, -3.8962e-04,  9.9835e-01,\n",
      "          7.5024e-01],\n",
      "        [ 9.8954e-01,  4.5833e-01,  9.9781e-01, -6.6187e-02,  4.0487e-02,\n",
      "          7.3918e-01],\n",
      "        [ 5.2808e-01,  4.8368e-01,  5.8242e-01,  8.1289e-01,  6.2796e-01,\n",
      "          6.0825e-01],\n",
      "        [ 9.8965e-01,  4.6180e-01,  9.9259e-01, -1.2154e-01,  4.1083e-01,\n",
      "          7.3135e-01],\n",
      "        [ 9.8931e-01,  4.5973e-01,  9.9409e-01, -1.0859e-01,  1.4431e-01,\n",
      "          7.2627e-01],\n",
      "        [ 7.1854e-01,  1.5430e-01,  9.9975e-01,  2.2425e-02,  4.4824e-01,\n",
      "          7.6054e-01],\n",
      "        [ 3.8920e-01,  4.8450e-01,  1.0000e+00, -6.6135e-04,  9.9753e-01,\n",
      "          7.5028e-01],\n",
      "        [ 9.8729e-01,  4.7552e-01,  9.9995e-01, -9.5574e-03,  8.8509e-01,\n",
      "          7.5148e-01],\n",
      "        [ 9.9017e-01,  4.8568e-01,  9.4539e-01,  3.2593e-01,  5.9297e-01,\n",
      "          6.7469e-01],\n",
      "        [ 7.9886e-01,  4.9679e-01,  9.9574e-01, -9.2221e-02,  9.3866e-01,\n",
      "          7.6438e-01],\n",
      "        [ 9.8948e-01,  4.6743e-01,  9.9733e-01, -7.3053e-02,  7.1902e-02,\n",
      "          7.5000e-01],\n",
      "        [ 9.8964e-01,  4.9833e-01,  9.5849e-01, -2.8513e-01,  4.1659e-01,\n",
      "          7.8779e-01],\n",
      "        [ 9.9105e-01,  5.6234e-01,  4.4735e-01,  8.9436e-01,  6.3595e-01,\n",
      "          5.6152e-01],\n",
      "        [ 5.3399e-01,  4.8729e-01,  1.0000e+00, -1.3536e-04,  9.8553e-01,\n",
      "          7.5020e-01],\n",
      "        [ 9.9017e-01,  5.3286e-01,  9.6644e-01,  2.5691e-01,  5.7263e-01,\n",
      "          7.4431e-01],\n",
      "        [ 9.8951e-01,  4.8552e-01,  9.9887e-01, -4.7448e-02,  2.8218e-01,\n",
      "          7.4842e-01],\n",
      "        [ 4.3266e-01,  4.8499e-01,  1.0000e+00, -7.9301e-05,  9.9493e-01,\n",
      "          7.5019e-01],\n",
      "        [ 9.9118e-01,  5.0669e-01,  9.9646e-01,  8.4126e-02,  3.7745e-01,\n",
      "          7.9166e-01],\n",
      "        [ 9.8951e-01,  4.6194e-01,  9.9574e-01, -9.2160e-02,  2.0771e-01,\n",
      "          7.4707e-01],\n",
      "        [ 9.8972e-01,  4.6894e-01,  9.9269e-01, -1.2069e-01,  2.0602e-01,\n",
      "          7.1838e-01],\n",
      "        [ 9.9234e-01,  4.6207e-01,  9.9287e-01,  1.1917e-01,  7.6837e-01,\n",
      "          7.3120e-01],\n",
      "        [ 9.8448e-01,  4.7684e-01,  9.8805e-01,  1.5413e-01,  8.8632e-01,\n",
      "          7.2706e-01],\n",
      "        [ 9.9046e-01,  4.7901e-01,  9.9248e-01, -1.2241e-01,  6.0520e-01,\n",
      "          7.6118e-01],\n",
      "        [ 1.6495e-02,  4.8364e-01,  7.1038e-01, -7.0382e-01,  5.6001e-01,\n",
      "          8.4192e-01],\n",
      "        [ 7.1379e-01,  4.8425e-01,  9.9432e-01,  1.0645e-01,  9.5736e-01,\n",
      "          7.3356e-01],\n",
      "        [ 9.8952e-01,  5.8667e-01,  9.8659e-01,  1.6320e-01,  5.2817e-01,\n",
      "          7.6363e-01],\n",
      "        [ 4.6948e-01,  4.7767e-01,  9.9999e-01,  4.4592e-03,  9.9216e-01,\n",
      "          7.4946e-01],\n",
      "        [ 9.9169e-01,  5.1626e-01,  9.7956e-01,  2.0114e-01,  7.2826e-01,\n",
      "          7.2495e-01],\n",
      "        [ 5.5823e-01,  4.9208e-01,  9.9992e-01, -1.2674e-02,  9.8276e-01,\n",
      "          7.5217e-01],\n",
      "        [ 9.9097e-01,  4.8099e-01,  9.9899e-01, -4.4974e-02,  6.8057e-01,\n",
      "          7.5559e-01],\n",
      "        [ 9.8953e-01,  4.8074e-01,  9.9698e-01, -7.7601e-02,  1.7940e-01,\n",
      "          7.5043e-01],\n",
      "        [ 9.4601e-01,  5.0015e-01,  9.9315e-01, -1.1688e-01,  8.9845e-01,\n",
      "          7.6766e-01],\n",
      "        [ 3.2572e-01,  4.8166e-01,  1.0000e+00, -3.3497e-04,  9.9957e-01,\n",
      "          7.5022e-01],\n",
      "        [ 9.9123e-01,  4.7719e-01,  9.9889e-01, -4.7075e-02,  6.9644e-01,\n",
      "          7.5607e-01],\n",
      "        [ 9.8966e-01,  5.1747e-01,  7.7818e-01, -6.2804e-01,  3.8711e-01,\n",
      "          8.5383e-01],\n",
      "        [ 9.9217e-01,  4.8293e-01,  9.2635e-01,  3.7666e-01,  7.4853e-01,\n",
      "          6.9843e-01],\n",
      "        [ 9.9267e-01,  4.6615e-01,  7.6634e-01,  6.4244e-01,  7.7519e-01,\n",
      "          6.5277e-01],\n",
      "        [ 5.0009e-01,  4.6858e-01,  9.9984e-01,  1.7990e-02,  9.8942e-01,\n",
      "          7.4732e-01],\n",
      "        [ 3.8906e-01,  4.8637e-01,  1.0000e+00, -1.5359e-03,  9.9747e-01,\n",
      "          7.5042e-01],\n",
      "        [ 9.2405e-01,  4.5593e-01,  9.9152e-01,  1.2998e-01,  9.0515e-01,\n",
      "          7.3049e-01],\n",
      "        [ 9.9173e-01,  4.8600e-01,  9.6824e-01, -2.5002e-01,  7.6151e-01,\n",
      "          7.8034e-01],\n",
      "        [ 9.8981e-01,  4.8199e-01,  9.9971e-01,  2.4084e-02,  2.9604e-01,\n",
      "          7.5381e-01],\n",
      "        [ 3.0852e-01,  4.8272e-01,  1.0000e+00, -6.7026e-05,  9.9977e-01,\n",
      "          7.5019e-01],\n",
      "        [ 3.9680e-01,  4.7680e-01,  9.9999e-01,  4.2889e-03,  9.9703e-01,\n",
      "          7.4952e-01],\n",
      "        [ 9.9085e-01,  4.4615e-01,  9.9805e-01, -6.2378e-02,  6.6795e-01,\n",
      "          7.4639e-01],\n",
      "        [ 5.1174e-01,  4.6888e-01,  9.9976e-01,  2.1892e-02,  9.8800e-01,\n",
      "          7.4669e-01],\n",
      "        [ 9.9088e-01,  5.0425e-01,  8.6539e-01, -5.0110e-01,  6.4070e-01,\n",
      "          8.1581e-01],\n",
      "        [ 9.9088e-01,  4.8899e-01,  9.8366e-01, -1.8003e-01,  6.2233e-01,\n",
      "          7.8508e-01],\n",
      "        [ 9.9051e-01,  4.7366e-01,  9.9194e-01,  1.2667e-01,  6.4514e-01,\n",
      "          7.3243e-01],\n",
      "        [ 8.9726e-01,  4.8981e-01,  9.9944e-01, -3.3577e-02,  9.1259e-01,\n",
      "          7.5523e-01],\n",
      "        [ 2.9384e-01,  4.8447e-01,  1.0000e+00, -5.9791e-05,  9.9989e-01,\n",
      "          7.5019e-01],\n",
      "        [ 5.2643e-01,  4.8505e-01,  1.0000e+00,  4.0941e-04,  9.8667e-01,\n",
      "          7.5011e-01],\n",
      "        [ 2.8405e-02,  4.8388e-01,  9.4070e-01,  3.3923e-01,  4.8890e-01,\n",
      "          7.0436e-01],\n",
      "        [ 8.4250e-01,  4.4865e-01,  9.8934e-01,  1.4560e-01,  9.2788e-01,\n",
      "          7.2759e-01]], dtype=torch.float64) tensor([[0.4785],\n",
      "        [0.5393],\n",
      "        [0.5058],\n",
      "        [0.7387],\n",
      "        [0.2647],\n",
      "        [0.4697],\n",
      "        [0.5290],\n",
      "        [0.6097],\n",
      "        [0.5076],\n",
      "        [0.5111],\n",
      "        [0.5024],\n",
      "        [0.4729],\n",
      "        [0.4713],\n",
      "        [0.4858],\n",
      "        [0.4753],\n",
      "        [0.0193],\n",
      "        [0.5043],\n",
      "        [0.4898],\n",
      "        [0.5001],\n",
      "        [0.5136],\n",
      "        [0.4795],\n",
      "        [0.5252],\n",
      "        [0.6379],\n",
      "        [0.5000],\n",
      "        [0.5404],\n",
      "        [0.5036],\n",
      "        [0.5000],\n",
      "        [0.5138],\n",
      "        [0.4822],\n",
      "        [0.4734],\n",
      "        [0.4822],\n",
      "        [0.4794],\n",
      "        [0.4892],\n",
      "        [0.5000],\n",
      "        [0.6417],\n",
      "        [0.5855],\n",
      "        [0.4924],\n",
      "        [0.5385],\n",
      "        [0.5077],\n",
      "        [0.4901],\n",
      "        [0.4920],\n",
      "        [0.5144],\n",
      "        [0.5019],\n",
      "        [0.4912],\n",
      "        [0.5274],\n",
      "        [0.4589],\n",
      "        [0.4795],\n",
      "        [0.4840],\n",
      "        [0.5098],\n",
      "        [0.4713],\n",
      "        [0.4299],\n",
      "        [0.5007],\n",
      "        [0.5000],\n",
      "        [0.4851],\n",
      "        [0.4619],\n",
      "        [0.4834],\n",
      "        [0.5383],\n",
      "        [0.5210],\n",
      "        [0.4829],\n",
      "        [0.5043],\n",
      "        [0.5000],\n",
      "        [0.4999],\n",
      "        [0.5000],\n",
      "        [0.4665]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "# test dataloader\n",
    "lidar, non_lidar, actions = next(iter(train_loader))\n",
    "print(f\"Non lidar shape: {non_lidar.shape}\")\n",
    "print(f\"Lidar shape: {lidar.shape}\")\n",
    "# print size dataloader\n",
    "print(f\"Train loader size: {len(train_loader)}\")\n",
    "print(f\"Val loader size: {len(val_loader)}\")\n",
    "print(lidar, non_lidar, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1349, 0.1342, 0.1341,  ..., 0.2026, 0.2024, 0.2026],\n",
       "        [0.2472, 0.2461, 0.2457,  ..., 0.4628, 0.4740, 0.4694],\n",
       "        [0.2554, 0.2557, 0.2564,  ..., 0.3171, 0.3188, 0.3285],\n",
       "        ...,\n",
       "        [0.2815, 0.2746, 0.2722,  ..., 0.2721, 0.2739, 0.2815],\n",
       "        [0.3674, 0.3670, 0.3557,  ..., 0.0370, 0.0372, 0.0376],\n",
       "        [0.3249, 0.3224, 0.3213,  ..., 0.2421, 0.2455, 0.2491]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.9221e-01,  4.7796e-01,  9.9237e-01, -1.2326e-01,  6.4269e-01,\n",
       "          7.5640e-01],\n",
       "        [ 9.9277e-01,  5.2382e-01,  8.7925e-01, -4.7636e-01,  8.2362e-01,\n",
       "          8.2051e-01],\n",
       "        [ 9.9284e-01,  4.8625e-01,  9.7745e-01, -2.1118e-01,  8.4190e-01,\n",
       "          7.8045e-01],\n",
       "        [ 2.9252e-01,  7.3219e-01, -1.2427e-01, -9.9225e-01,  4.8490e-01,\n",
       "          1.9115e-02],\n",
       "        [ 3.2979e-01,  2.5446e-01,  4.0205e-01,  9.1562e-01,  5.2613e-01,\n",
       "          5.2908e-01],\n",
       "        [ 9.9020e-01,  4.6528e-01,  9.9618e-01, -8.7375e-02,  3.7962e-02,\n",
       "          7.3331e-01],\n",
       "        [ 9.9007e-01,  5.1403e-01,  9.9751e-01,  7.0560e-02,  5.4626e-01,\n",
       "          7.4533e-01],\n",
       "        [ 9.9107e-01,  5.9637e-01,  9.7597e-01, -2.1792e-01,  5.7842e-01,\n",
       "          7.6957e-01],\n",
       "        [ 5.6730e-01,  4.8513e-01,  9.9992e-01, -1.2490e-02,  9.8162e-01,\n",
       "          7.5215e-01],\n",
       "        [ 9.8976e-01,  4.9093e-01,  9.9901e-01,  4.4509e-02,  7.2558e-02,\n",
       "          7.5975e-01],\n",
       "        [ 3.7309e-01,  4.8523e-01,  1.0000e+00, -3.8962e-04,  9.9835e-01,\n",
       "          7.5024e-01],\n",
       "        [ 9.8954e-01,  4.5833e-01,  9.9781e-01, -6.6187e-02,  4.0487e-02,\n",
       "          7.3918e-01],\n",
       "        [ 5.2808e-01,  4.8368e-01,  5.8242e-01,  8.1289e-01,  6.2796e-01,\n",
       "          6.0825e-01],\n",
       "        [ 9.8965e-01,  4.6180e-01,  9.9259e-01, -1.2154e-01,  4.1083e-01,\n",
       "          7.3135e-01],\n",
       "        [ 9.8931e-01,  4.5973e-01,  9.9409e-01, -1.0859e-01,  1.4431e-01,\n",
       "          7.2627e-01],\n",
       "        [ 7.1854e-01,  1.5430e-01,  9.9975e-01,  2.2425e-02,  4.4824e-01,\n",
       "          7.6054e-01],\n",
       "        [ 3.8920e-01,  4.8450e-01,  1.0000e+00, -6.6135e-04,  9.9753e-01,\n",
       "          7.5028e-01],\n",
       "        [ 9.8729e-01,  4.7552e-01,  9.9995e-01, -9.5574e-03,  8.8509e-01,\n",
       "          7.5148e-01],\n",
       "        [ 9.9017e-01,  4.8568e-01,  9.4539e-01,  3.2593e-01,  5.9297e-01,\n",
       "          6.7469e-01],\n",
       "        [ 7.9886e-01,  4.9679e-01,  9.9574e-01, -9.2221e-02,  9.3866e-01,\n",
       "          7.6438e-01],\n",
       "        [ 9.8948e-01,  4.6743e-01,  9.9733e-01, -7.3053e-02,  7.1902e-02,\n",
       "          7.5000e-01],\n",
       "        [ 9.8964e-01,  4.9833e-01,  9.5849e-01, -2.8513e-01,  4.1659e-01,\n",
       "          7.8779e-01],\n",
       "        [ 9.9105e-01,  5.6234e-01,  4.4735e-01,  8.9436e-01,  6.3595e-01,\n",
       "          5.6152e-01],\n",
       "        [ 5.3399e-01,  4.8729e-01,  1.0000e+00, -1.3536e-04,  9.8553e-01,\n",
       "          7.5020e-01],\n",
       "        [ 9.9017e-01,  5.3286e-01,  9.6644e-01,  2.5691e-01,  5.7263e-01,\n",
       "          7.4431e-01],\n",
       "        [ 9.8951e-01,  4.8552e-01,  9.9887e-01, -4.7448e-02,  2.8218e-01,\n",
       "          7.4842e-01],\n",
       "        [ 4.3266e-01,  4.8499e-01,  1.0000e+00, -7.9301e-05,  9.9493e-01,\n",
       "          7.5019e-01],\n",
       "        [ 9.9118e-01,  5.0669e-01,  9.9646e-01,  8.4126e-02,  3.7745e-01,\n",
       "          7.9166e-01],\n",
       "        [ 9.8951e-01,  4.6194e-01,  9.9574e-01, -9.2160e-02,  2.0771e-01,\n",
       "          7.4707e-01],\n",
       "        [ 9.8972e-01,  4.6894e-01,  9.9269e-01, -1.2069e-01,  2.0602e-01,\n",
       "          7.1838e-01],\n",
       "        [ 9.9234e-01,  4.6207e-01,  9.9287e-01,  1.1917e-01,  7.6837e-01,\n",
       "          7.3120e-01],\n",
       "        [ 9.8448e-01,  4.7684e-01,  9.8805e-01,  1.5413e-01,  8.8632e-01,\n",
       "          7.2706e-01],\n",
       "        [ 9.9046e-01,  4.7901e-01,  9.9248e-01, -1.2241e-01,  6.0520e-01,\n",
       "          7.6118e-01],\n",
       "        [ 1.6495e-02,  4.8364e-01,  7.1038e-01, -7.0382e-01,  5.6001e-01,\n",
       "          8.4192e-01],\n",
       "        [ 7.1379e-01,  4.8425e-01,  9.9432e-01,  1.0645e-01,  9.5736e-01,\n",
       "          7.3356e-01],\n",
       "        [ 9.8952e-01,  5.8667e-01,  9.8659e-01,  1.6320e-01,  5.2817e-01,\n",
       "          7.6363e-01],\n",
       "        [ 4.6948e-01,  4.7767e-01,  9.9999e-01,  4.4592e-03,  9.9216e-01,\n",
       "          7.4946e-01],\n",
       "        [ 9.9169e-01,  5.1626e-01,  9.7956e-01,  2.0114e-01,  7.2826e-01,\n",
       "          7.2495e-01],\n",
       "        [ 5.5823e-01,  4.9208e-01,  9.9992e-01, -1.2674e-02,  9.8276e-01,\n",
       "          7.5217e-01],\n",
       "        [ 9.9097e-01,  4.8099e-01,  9.9899e-01, -4.4974e-02,  6.8057e-01,\n",
       "          7.5559e-01],\n",
       "        [ 9.8953e-01,  4.8074e-01,  9.9698e-01, -7.7601e-02,  1.7940e-01,\n",
       "          7.5043e-01],\n",
       "        [ 9.4601e-01,  5.0015e-01,  9.9315e-01, -1.1688e-01,  8.9845e-01,\n",
       "          7.6766e-01],\n",
       "        [ 3.2572e-01,  4.8166e-01,  1.0000e+00, -3.3497e-04,  9.9957e-01,\n",
       "          7.5022e-01],\n",
       "        [ 9.9123e-01,  4.7719e-01,  9.9889e-01, -4.7075e-02,  6.9644e-01,\n",
       "          7.5607e-01],\n",
       "        [ 9.8966e-01,  5.1747e-01,  7.7818e-01, -6.2804e-01,  3.8711e-01,\n",
       "          8.5383e-01],\n",
       "        [ 9.9217e-01,  4.8293e-01,  9.2635e-01,  3.7666e-01,  7.4853e-01,\n",
       "          6.9843e-01],\n",
       "        [ 9.9267e-01,  4.6615e-01,  7.6634e-01,  6.4244e-01,  7.7519e-01,\n",
       "          6.5277e-01],\n",
       "        [ 5.0009e-01,  4.6858e-01,  9.9984e-01,  1.7990e-02,  9.8942e-01,\n",
       "          7.4732e-01],\n",
       "        [ 3.8906e-01,  4.8637e-01,  1.0000e+00, -1.5359e-03,  9.9747e-01,\n",
       "          7.5042e-01],\n",
       "        [ 9.2405e-01,  4.5593e-01,  9.9152e-01,  1.2998e-01,  9.0515e-01,\n",
       "          7.3049e-01],\n",
       "        [ 9.9173e-01,  4.8600e-01,  9.6824e-01, -2.5002e-01,  7.6151e-01,\n",
       "          7.8034e-01],\n",
       "        [ 9.8981e-01,  4.8199e-01,  9.9971e-01,  2.4084e-02,  2.9604e-01,\n",
       "          7.5381e-01],\n",
       "        [ 3.0852e-01,  4.8272e-01,  1.0000e+00, -6.7026e-05,  9.9977e-01,\n",
       "          7.5019e-01],\n",
       "        [ 3.9680e-01,  4.7680e-01,  9.9999e-01,  4.2889e-03,  9.9703e-01,\n",
       "          7.4952e-01],\n",
       "        [ 9.9085e-01,  4.4615e-01,  9.9805e-01, -6.2378e-02,  6.6795e-01,\n",
       "          7.4639e-01],\n",
       "        [ 5.1174e-01,  4.6888e-01,  9.9976e-01,  2.1892e-02,  9.8800e-01,\n",
       "          7.4669e-01],\n",
       "        [ 9.9088e-01,  5.0425e-01,  8.6539e-01, -5.0110e-01,  6.4070e-01,\n",
       "          8.1581e-01],\n",
       "        [ 9.9088e-01,  4.8899e-01,  9.8366e-01, -1.8003e-01,  6.2233e-01,\n",
       "          7.8508e-01],\n",
       "        [ 9.9051e-01,  4.7366e-01,  9.9194e-01,  1.2667e-01,  6.4514e-01,\n",
       "          7.3243e-01],\n",
       "        [ 8.9726e-01,  4.8981e-01,  9.9944e-01, -3.3577e-02,  9.1259e-01,\n",
       "          7.5523e-01],\n",
       "        [ 2.9384e-01,  4.8447e-01,  1.0000e+00, -5.9791e-05,  9.9989e-01,\n",
       "          7.5019e-01],\n",
       "        [ 5.2643e-01,  4.8505e-01,  1.0000e+00,  4.0941e-04,  9.8667e-01,\n",
       "          7.5011e-01],\n",
       "        [ 2.8405e-02,  4.8388e-01,  9.4070e-01,  3.3923e-01,  4.8890e-01,\n",
       "          7.0436e-01],\n",
       "        [ 8.4250e-01,  4.4865e-01,  9.8934e-01,  1.4560e-01,  9.2788e-01,\n",
       "          7.2759e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4785],\n",
       "        [0.5393],\n",
       "        [0.5058],\n",
       "        [0.7387],\n",
       "        [0.2647],\n",
       "        [0.4697],\n",
       "        [0.5290],\n",
       "        [0.6097],\n",
       "        [0.5076],\n",
       "        [0.5111],\n",
       "        [0.5024],\n",
       "        [0.4729],\n",
       "        [0.4713],\n",
       "        [0.4858],\n",
       "        [0.4753],\n",
       "        [0.0193],\n",
       "        [0.5043],\n",
       "        [0.4898],\n",
       "        [0.5001],\n",
       "        [0.5136],\n",
       "        [0.4795],\n",
       "        [0.5252],\n",
       "        [0.6379],\n",
       "        [0.5000],\n",
       "        [0.5404],\n",
       "        [0.5036],\n",
       "        [0.5000],\n",
       "        [0.5138],\n",
       "        [0.4822],\n",
       "        [0.4734],\n",
       "        [0.4822],\n",
       "        [0.4794],\n",
       "        [0.4892],\n",
       "        [0.5000],\n",
       "        [0.6417],\n",
       "        [0.5855],\n",
       "        [0.4924],\n",
       "        [0.5385],\n",
       "        [0.5077],\n",
       "        [0.4901],\n",
       "        [0.4920],\n",
       "        [0.5144],\n",
       "        [0.5019],\n",
       "        [0.4912],\n",
       "        [0.5274],\n",
       "        [0.4589],\n",
       "        [0.4795],\n",
       "        [0.4840],\n",
       "        [0.5098],\n",
       "        [0.4713],\n",
       "        [0.4299],\n",
       "        [0.5007],\n",
       "        [0.5000],\n",
       "        [0.4851],\n",
       "        [0.4619],\n",
       "        [0.4834],\n",
       "        [0.5383],\n",
       "        [0.5210],\n",
       "        [0.4829],\n",
       "        [0.5043],\n",
       "        [0.5000],\n",
       "        [0.4999],\n",
       "        [0.5000],\n",
       "        [0.4665]], dtype=torch.float64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_lidar_features, num_non_lidar_features, num_actions, nframes=1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.act_fea_cv1 = nn.Conv1d(\n",
    "            in_channels=nframes, out_channels=32, kernel_size=5, stride=2, padding=6, padding_mode='circular'\n",
    "        )\n",
    "        self.act_fea_cv2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "\n",
    "        conv_output_size = (num_lidar_features - 5 + 2*6) // 2 + 1  # Output size after self.act_fea_cv1\n",
    "        conv_output_size = (conv_output_size - 3 + 2*1) // 2 + 1  # Output size after self.act_fea_cv2\n",
    "        conv_output_size *= 32  # Multiply by the number of output channels\n",
    "\n",
    "        # Calculate the output size of the CNN\n",
    "        self.fc1 = nn.Linear(conv_output_size, 64)\n",
    "        self.fc2 = nn.Linear(64 + num_non_lidar_features, 32)\n",
    "        self.fc3 = nn.Linear(32, num_actions)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, lidar, non_lidar):\n",
    "        lidar = lidar.unsqueeze(1)  # Add channel dimension\n",
    "        feat = F.relu(self.act_fea_cv1(lidar))\n",
    "        feat = F.relu(self.act_fea_cv2(feat))\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        feat = F.relu(self.fc1(feat))\n",
    "        feat = torch.cat((feat, non_lidar), dim=-1)\n",
    "        feat = F.relu(self.fc2(feat))\n",
    "        feat = self.fc3(feat)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device)\n",
    "        non_lidar = non_lidar.to(device)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device)\n",
    "        non_lidar = non_lidar.to(device)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:01<00:00, 216.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.0675285269847075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:17<00:00, 127.83it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 275.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.005474378791680319 | Val Loss: 0.004408208947855026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:18<00:00, 118.18it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 334.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 0.0033988027345549037 | Val Loss: 0.0037823448540790306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:18<00:00, 122.27it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 253.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 0.003018434997120748 | Val Loss: 0.003355540681817792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:19<00:00, 114.44it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 303.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 0.0027529854657720866 | Val Loss: 0.0031988966202104742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:17<00:00, 128.00it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 368.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 0.0025143854920697786 | Val Loss: 0.002967282718413983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:13<00:00, 163.78it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 563.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Train Loss: 0.0023035279298103096 | Val Loss: 0.0027970620298150154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:11<00:00, 199.19it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 578.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Train Loss: 0.002149671249597578 | Val Loss: 0.0026270369565063677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:16<00:00, 137.33it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 374.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Train Loss: 0.002014688928800181 | Val Loss: 0.0026065852484388865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:14<00:00, 147.97it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 410.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Train Loss: 0.0019007644270611892 | Val Loss: 0.0025615527200932645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:14<00:00, 148.51it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 496.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Train Loss: 0.0017966266190745448 | Val Loss: 0.00247368280233155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:19<00:00, 112.88it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 238.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Train Loss: 0.0017048315332013986 | Val Loss: 0.0023942148522560517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:17<00:00, 126.46it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 189.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Train Loss: 0.0016257938353160444 | Val Loss: 0.0023373762474941536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 140.90it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 494.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Train Loss: 0.0015522366316813628 | Val Loss: 0.0022884152681284667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 140.22it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 282.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Train Loss: 0.0014862630574996724 | Val Loss: 0.0022761510729627102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 146.04it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 318.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Train Loss: 0.0014263134260761895 | Val Loss: 0.00222881823252717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:14<00:00, 151.27it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 294.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Train Loss: 0.0013727136721263008 | Val Loss: 0.002157571793922953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 146.05it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 310.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Train Loss: 0.0013237657838101216 | Val Loss: 0.0022022826371557065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:14<00:00, 148.07it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 310.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Train Loss: 0.0012826303821373434 | Val Loss: 0.0020992085489541686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 146.45it/s]\n",
      "100%|██████████| 317/317 [00:00<00:00, 467.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Train Loss: 0.0012428994644485198 | Val Loss: 0.002087378516458924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:15<00:00, 138.78it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 280.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Train Loss: 0.0012029923081208933 | Val Loss: 0.002056850580329726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "sys.stdout.flush()\n",
    "\n",
    "cnn_train_losses = []\n",
    "cnn_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    cnn_train_losses.append(train_loss)\n",
    "    cnn_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cnn_train_losses, label='Train Loss')\n",
    "plt.plot(cnn_val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:00<00:00, 817.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val loss: 0.024586481111963446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load file and check MSELoss\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "model.load_state_dict(torch.load('cnn_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0][df['timestep']>200], \"val\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_lidar_features, num_non_lidar_features, num_actions, d_model=32, nhead=4, num_encoder_layers=3, num_patches=36):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_patches = num_patches  # Number of patches\n",
    "        self.patch_size = num_lidar_features // self.num_patches\n",
    "\n",
    "        # Positional Encoding for the Encoder\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(self.num_patches, d_model))\n",
    "\n",
    "        # Input Embedding for Encoder (LiDAR data)\n",
    "        self.lidar_embedding = nn.Linear(self.patch_size, d_model)\n",
    "\n",
    "        # Transformer Encoder for LiDAR data (first encoder)\n",
    "        encoder_layer_1 = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder_1 = nn.TransformerEncoder(encoder_layer_1, num_layers=num_encoder_layers)\n",
    "\n",
    "        # Input Embedding for Non-LiDAR data (values)\n",
    "        self.non_lidar_embedding = nn.Linear(num_non_lidar_features, d_model)\n",
    "\n",
    "        # Transformer Decoder (cross-attention using Q and K from LiDAR encoder and V from non-lidar data)\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead)\n",
    "\n",
    "        # Second Encoder Layer for post-processing\n",
    "        encoder_layer_2 = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder_2 = nn.TransformerEncoder(encoder_layer_2, num_layers=num_encoder_layers)\n",
    "\n",
    "        # Linear layer to map the transformer output to actions\n",
    "        self.fc_out = nn.Linear(d_model * num_patches, num_actions)\n",
    "\n",
    "    def forward(self, lidar, non_lidar):\n",
    "        batch_size = lidar.size(0)\n",
    "        \n",
    "        # Reshape LiDAR input into patches\n",
    "        lidar_patches = lidar.view(batch_size, self.num_patches, self.patch_size)\n",
    "\n",
    "        # Linear projection of LiDAR patches and adding positional encoding\n",
    "        lidar_embed = self.lidar_embedding(lidar_patches) + self.positional_encoding.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        lidar_embed = lidar_embed.permute(1, 0, 2)  # Convert to (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Process through the transformer encoder for LiDAR data\n",
    "        lidar_encoded = self.transformer_encoder_1(lidar_embed)  # Shape: (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Process non-lidar data through input embedding\n",
    "        non_lidar_embed = self.non_lidar_embedding(non_lidar).unsqueeze(0)  # Shape: (1, batch_size, d_model)\n",
    "\n",
    "        # Repeat the non-lidar embeddings along the sequence length to match the LiDAR sequence length\n",
    "        non_lidar_embed = non_lidar_embed.repeat(self.num_patches, 1, 1)  # Shape: (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Cross-attention: Use LiDAR encoded data as Q and K, non-lidar as V\n",
    "        non_lidar_attended, _ = self.multihead_attention(query=lidar_encoded, key=lidar_encoded, value=non_lidar_embed)\n",
    "        non_lidar_attended = non_lidar_attended + lidar_encoded\n",
    "\n",
    "        # Process the output of the cross-attention through the second encoder layer\n",
    "        encoder_output = self.transformer_encoder_2(non_lidar_attended)  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Concatenate the encoder output over the sequence length\n",
    "        encoder_output = encoder_output.permute(1, 0, 2)\n",
    "        encoder_output = encoder_output.reshape(batch_size, -1)\n",
    "\n",
    "        # Final linear layer to get the predicted actions\n",
    "        actions = self.fc_out(encoder_output)\n",
    "\n",
    "        # clip to [0, 1] using sigmoid\n",
    "        actions = torch.sigmoid(actions)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomMSELoss(nn.Module):\n",
    "#     def __init__(self, weight):\n",
    "#         super(CustomMSELoss, self).__init__()\n",
    "#         self.weight = weight\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         # Assume output and target are two-element tuples\n",
    "#         loss1 = (output[:,0] - target[:,0]) ** 2\n",
    "#         loss2 = self.weight * (output[:,1] - target[:,1]) ** 4\n",
    "#         total_loss = loss1 + loss2\n",
    "#         return total_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "model = TransformerModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:02<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.020606965886991565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2219/2219 [00:46<00:00, 47.33it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 167.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.006295343419507988 | Val Loss: 0.005245321280968188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:43<00:00, 50.64it/s]\n",
      "100%|██████████| 317/317 [00:01<00:00, 165.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 0.005220670392852211 | Val Loss: 0.0047249793317713845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:43<00:00, 50.70it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 157.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.004749339213920065 | Val Loss: 0.0044819552039104225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:45<00:00, 48.69it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 154.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.004505234552440731 | Val Loss: 0.004358075894521879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:48<00:00, 45.93it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 146.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | Train Loss: 0.004339413077393383 | Val Loss: 0.0042590740423301635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:47<00:00, 47.11it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 151.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | Train Loss: 0.004216520624518992 | Val Loss: 0.004185543181126036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:45<00:00, 48.65it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 157.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | Train Loss: 0.004111427527950147 | Val Loss: 0.004099494381269508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:46<00:00, 47.27it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 155.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | Train Loss: 0.004002197315638785 | Val Loss: 0.0040118955596003345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:46<00:00, 47.28it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 154.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | Train Loss: 0.003917117697058129 | Val Loss: 0.003926660127947939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:46<00:00, 47.34it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 146.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | Train Loss: 0.0038092347742969095 | Val Loss: 0.0038094937293208894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:47<00:00, 46.59it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 155.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | Train Loss: 0.003689469914814544 | Val Loss: 0.0036687643675035165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:45<00:00, 48.41it/s]\n",
      "100%|██████████| 317/317 [00:04<00:00, 75.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | Train Loss: 0.0035529394930536233 | Val Loss: 0.0035105120043351437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:57<00:00, 38.43it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 112.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | Train Loss: 0.0034074200346485475 | Val Loss: 0.0032962705474105874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [00:48<00:00, 45.72it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 122.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | Train Loss: 0.0032283903146341003 | Val Loss: 0.0030735505617201578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [01:04<00:00, 34.36it/s]\n",
      "100%|██████████| 317/317 [00:02<00:00, 136.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | Train Loss: 0.0030905158650243354 | Val Loss: 0.002830392291964895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [01:08<00:00, 32.35it/s]\n",
      "100%|██████████| 317/317 [00:04<00:00, 74.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | Train Loss: 0.0029435572417193974 | Val Loss: 0.002625755016537202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [01:15<00:00, 29.38it/s]\n",
      "100%|██████████| 317/317 [00:03<00:00, 83.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | Train Loss: 0.0027981264996065356 | Val Loss: 0.002393611367647898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2219/2219 [01:09<00:00, 32.14it/s]\n",
      "100%|██████████| 317/317 [00:03<00:00, 93.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | Train Loss: 0.0026711529709332435 | Val Loss: 0.002271219360334709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 378/2219 [00:16<01:18, 23.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m no_improve_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m test_model(model, val_loader, loss_fn)\n\u001b[0;32m     16\u001b[0m     transformer_train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[151], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Save the loss\u001b[39;00m\n",
      "File \u001b[1;32md:\\Conda\\envs\\gpu-env\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Conda\\envs\\gpu-env\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "\n",
    "transformer_train_losses = []\n",
    "transformer_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    transformer_train_losses.append(train_loss)\n",
    "    transformer_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAACKVElEQVR4nOzdd3xN9x/H8dfN3oOQQRYiiBCCiE1T0Vppq1Rbq1raqupPB9oandRoVatVNTuNUhTVklZrxBZbrESCDDMhkXnP74/D5VbESnJuks/z8TiP5J77ved8zr24b+d8z/erUxRFQQghhBBC3BMzrQsQQgghhCiLJEQJIYQQQtwHCVFCCCGEEPdBQpQQQgghxH2QECWEEEIIcR8kRAkhhBBC3AcJUUIIIYQQ98FC6wLKM71ez5kzZ3B0dESn02ldjhBCCCHugqIoXL58GS8vL8zMbn++SUJUCTpz5gze3t5alyGEEEKI+5CUlET16tVv+7yEqBLk6OgIqB+Ck5OTxtUIIYQQ4m5kZGTg7e1t+B6/HQlRJej6JTwnJycJUUIIIUQZc6euONKxXAghhBDiPkiIEkIIIYS4DxKihBBCCCHug/SJEkKIckKv15Obm6t1GUKYPEtLS8zNzR94OxKihBCiHMjNzSU+Ph69Xq91KUKUCS4uLnh4eDzQOI4SooQQooxTFIXk5GTMzc3x9vYucnBAISo6RVHIysoiLS0NAE9Pz/veloQoIYQo4/Lz88nKysLLyws7OzutyxHC5Nna2gKQlpZG1apV7/vSnvx3RQghyriCggIArKysNK5EiLLj+n848vLy7nsbEqKEEKKckDk6hbh7xfH3RUKUEEIIIcR9kBAlhBBCCHEfJEQJIYQQ16SkpPDwww9jb2+Pi4uL1uWYHJ1Ox7Jly7Quw2RIiCqDsvMK2HnygtZlCCHEfdPpdEUu48aN06Suzz77jOTkZGJjYzly5IgmNTyohISEO76/8+bNu69tJycn88gjjzxQfX5+fkydOvWBtmEqZIiDMiY1I5t2k9ZToFfYMToCJxtLrUsSQoh7lpycbPh94cKFjBkzhri4OMM6BwcHw++KolBQUICFRcl/ZR0/fpzQ0FACAgLuexu5ubmleqdkXl4elpY3vgu8vb2N3t/JkyezZs0a1q1bZ1jn7Oxs+L2goACdTndX44t5eHgUU9Xlg5yJKmPcnWzwcrEht0DP34fTtC5HCGGCFEUhKzdfk0VRlLuq0cPDw7A4Ozuj0+kMjw8fPoyjoyO///47oaGhWFtbs3HjRo4fP0737t1xd3fHwcGBpk2bGgUDUM9yfPzxxzz33HM4Ojri4+PDzJkzDc/n5ubyyiuv4OnpiY2NDb6+vowfP97w2iVLlvDdd9+h0+no378/AImJiXTv3h0HBwecnJzo2bMnqamphm2OGzeOkJAQZs2ahb+/PzY2NoB6tu2bb76hS5cu2NnZUbduXWJiYjh27Bjt2rXD3t6eFi1acPz4caNjWL58OY0bN8bGxoYaNWrw3nvvkZ+fb3hep9Px9ddf061bN+zt7fnoo4+MXm9ubm70/jo4OGBhYWF4vGbNGjw9PVmxYgX16tXD2tqaxMREtm/fzsMPP4ybmxvOzs60bduWXbt2GW375st51894LV26lPbt22NnZ0fDhg2JiYm5qz8Dt/P1119Ts2ZNrKysCAwM5Pvvvzc8pygK48aNw8fHB2tra7y8vHj11VcNz3/11VcEBARgY2ODu7s7PXr0eKBa7kTORJVBnep7MP3v46zZn0L3kGpalyOEMDFX8wqoN+YPTfZ98P1I7KyK56tl5MiRTJ48mRo1auDq6kpSUhKPPvooH330EdbW1nz33Xd07dqVuLg4fHx8DK+bMmUKH3zwAW+//Ta//PILL730Em3btiUwMJBp06axYsUKFi1ahI+PD0lJSSQlJQGwfft2+vbti5OTE59//jm2trbo9XpDgPrnn3/Iz89nyJAh9OrVi/Xr1xv2eezYMZYsWcLSpUuNBm784IMP+PTTT/n0008ZMWIETz/9NDVq1GDUqFH4+Pjw3HPP8corr/D7778DsGHDBvr27cu0adNo3bo1x48fZ9CgQQCMHTvWsN1x48YxYcIEpk6del9n6LKysvjkk0+YNWsWlStXpmrVqpw4cYJ+/frxxRdfoCgKU6ZM4dFHH+Xo0aM4OjredlvvvPMOkydPJiAggHfeeYfevXtz7Nix+6rr119/ZdiwYUydOpWIiAhWrlzJgAEDqF69Ou3bt2fJkiV89tlnLFiwgKCgIFJSUtizZw8AO3bs4NVXX+X777+nRYsWXLhwgQ0bNtxzDfdCQlQZ9Eh9T6b/fZz1cWe5mluArdWDT6IohBCm5v333+fhhx82PK5UqRINGzY0PP7ggw/49ddfWbFiBa+88oph/aOPPsrLL78MwIgRI/jss8/4+++/CQwMJDExkYCAAFq1aoVOp8PX19fwuipVqmBtbY2tra3hstXatWvZt28f8fHxeHt7A/Ddd98RFBTE9u3badq0KaCe4fruu++oUqWK0TEMGDCAnj17GmoJDw9n9OjRREZGAjBs2DAGDBhgaP/ee+8xcuRI+vXrB0CNGjX44IMPeOutt4xC1NNPP230unuVl5fHV199ZfR+dujQwajNzJkzcXFx4Z9//qFLly633dYbb7xB586dDfUHBQVx7Ngx6tSpc891TZ48mf79+xs+v+HDh7NlyxYmT55M+/btSUxMxMPDg4iICCwtLfHx8aFZs2aAesbQ3t6eLl264OjoiK+vL40aNbrnGu6FhKgyKMjLiWoutpy+dJV/j54lMkiuUQshbrC1NOfg+5Ga7bu4NGnSxOjxlStXGDduHKtWrSI5OZn8/HyuXr1KYmKiUbsGDRoYfr9+mfD6PGn9+/fn4YcfJjAwkE6dOtGlSxc6dux42xoOHTqEt7e3IUAB1KtXDxcXFw4dOmQIUb6+vrcEqP/W4u7uDkBwcLDRuuzsbDIyMnBycmLPnj1s2rTJ6BJdQUEB2dnZZGVlGUbZ/u97c6+srKyMagNITU3l3XffZf369aSlpVFQUEBWVtYt729Rx3h9Hrq0tLT7ClGHDh0ynHm7rmXLlnz++ecAPPnkk0ydOpUaNWrQqVMnHn30Ubp27YqFhQUPP/wwvr6+huc6derEY489VqJTIUmfqDJIp9PRqb4anNbsT9G4GiGEqdHpdNhZWWiyFOeo6fb29kaP33jjDX799Vc+/vhjNmzYQGxsLMHBweTm5hq1u7mT9fX3Q6/XA9C4cWPi4+P54IMPuHr1Kj179iyWfjP/rbWwWq6/N4Wtu17flStXeO+994iNjTUs+/bt4+jRo4a+VkXt727Z2tre8ln169eP2NhYPv/8czZv3kxsbCyVK1e+5f29m2O8fjzFzdvbm7i4OL766itsbW15+eWXadOmDXl5eTg6OrJr1y5+/vlnPD09GTNmDA0bNuTSpUslUgtIiCqzroeodYdSyc0vmT+sQghhSjZt2kT//v157LHHCA4OxsPDg4SEhHvejpOTE7169eLbb79l4cKFLFmyhAsXCh82pm7dukb9pgAOHjzIpUuXqFev3v0eym01btyYuLg4atWqdctyN3fPPYhNmzbx6quv8uijjxIUFIS1tTXnzp0r0X3+V926ddm0adMtdd38Xtva2tK1a1emTZvG+vXriYmJYd++fQBYWFgQERHBxIkT2bt3LwkJCfz1118lVq9cziujGvu44uZgzbkrOcScOE/b2reeRhZCiPIkICCApUuX0rVrV3Q6HaNHj77nMx6ffvopnp6eNGrUCDMzMxYvXoyHh8dtB9aMiIggODiYZ555hqlTp5Kfn8/LL79M27ZtH/iSWmHGjBlDly5d8PHxoUePHpiZmbFnzx7279/Phx9+WOz7u1lAQADff/89TZo0ISMjgzfffBNbW9sS2dfp06eJjY01Wufr68ubb75Jz549adSoEREREfz2228sXbrUcBfmvHnzKCgoICwsDDs7O3744QdsbW3x9fVl5cqVnDhxgjZt2uDq6srq1avR6/UEBgaWyDGAnIkqs8zNdEQGqdfX5ZKeEKIi+PTTT3F1daVFixZ07dqVyMhIGjdufE/bcHR0ZOLEiTRp0oSmTZuSkJDA6tWrb3uWR6fTsXz5clxdXWnTpg0RERHUqFGDhQsXFsch3SIyMpKVK1fy559/0rRpU5o3b85nn31m1AG+pMyePZuLFy/SuHFj+vTpw6uvvkrVqlVLZF+TJ0+mUaNGRsuqVauIiori888/Z/LkyQQFBfHNN98wd+5c2rVrB4CLiwvffvstLVu2pEGDBqxbt47ffvuNypUr4+LiwtKlS+nQoQN169ZlxowZ/PzzzwQFBZXIMQDolLsd1EPcs4yMDJydnUlPT8fJyanYt7/h6Fn6zN6Gm4MVW9+OwNxMZnAXoiLKzs4mPj7eaIwiIUTRivp7c7ff33ImqgxrXqMyTjYWnLuSy44EmQZGCCGEKE0SosowS3MzIupdu6R3QC7pCSGEEKVJQlQZ90h9dUyOP/an3PV0C0IIIYR4cBKiyrjWAW7YWZlzJj2bfafTtS5HCCGEqDAkRJVxNpbmtA9U756Qu/SEEEKI0qN5iJo+fTp+fn7Y2NgQFhbGtm3bimy/ePFi6tSpg42NDcHBwaxevdroeUVRGDNmDJ6entja2hIREcHRo0dv2c6qVasICwvD1tYWV1dXoqKijJ5PTEykc+fO2NnZUbVqVd58802jWbRNSeRNo5fLJT0hhBCidGgaohYuXMjw4cMZO3Ysu3btomHDhkRGRhrmOPqvzZs307t3bwYOHMju3buJiooiKiqK/fv3G9pMnDiRadOmMWPGDLZu3Yq9vT2RkZFkZ2cb2ixZsoQ+ffowYMAAwzxFTz/9tOH5goICOnfuTG5uLps3b2b+/PnMmzePMWPGlNyb8QDaB1bBytyME+cyOZp2RetyhBBCiIpB0VCzZs2UIUOGGB4XFBQoXl5eyvjx4wtt37NnT6Vz585G68LCwpTBgwcriqIoer1e8fDwUCZNmmR4/tKlS4q1tbXy888/K4qiKHl5eUq1atWUWbNm3bau1atXK2ZmZkpKSoph3ddff604OTkpOTk5t31ddna2kp6ebliSkpIUQElPTy/iXSgez83dpviOWKl8vu5Iie9LCGFarl69qhw8eFC5evWq1qUIUWYU9fcmPT39rr6/NTsTlZuby86dO4mIiDCsMzMzIyIigpiYmEJfExMTY9Qe1NFdr7ePj48nJSXFqI2zszNhYWGGNrt27eL06dOYmZnRqFEjPD09eeSRR4zOZsXExBAcHGyYcfv6fjIyMjhw4MBtj2n8+PE4Ozsblptn/S5pkTIhsRBCPLCUlBQefvhh7O3tbzsVTEXi5+fH1KlTtS7DZGkWos6dO0dBQYFRUAFwd3cnJaXwIJCSklJk++s/i2pz4sQJAMaNG8e7777LypUrcXV1pV27doYJKG+3n5v3UZhRo0aRnp5uWG6esLKkRdR1x9xMx8HkDBLPZ5XafoUQ4n7odLoil3HjxmlS12effUZycjKxsbEcOXJEkxqKQ3BwMC+++GKhz33//ffFNrnwuHHjCAkJeeDtlFWadywvbdcnq3znnXd44oknCA0NZe7cueh0OhYvXvxA27a2tsbJycloKS2V7K0I868EwJoDyaW2XyGEuB/JycmGZerUqTg5ORmte+ONNwxtFUUptRt7jh8/TmhoKAEBAfc9b1xubm4xV1W0vLy8W9YNHDiQBQsWcPXq1Vuemzt3Lt26dcPNza00yivXNAtRbm5umJubk5qaarQ+NTUVDw+PQl/j4eFRZPvrP4tq4+mpDk5Zr149w/PW1tbUqFGDxMTEIvdz8z5MUSe5pCeEKCM8PDwMi7OzMzqdzvD48OHDODo68vvvvxMaGoq1tTUbN27k+PHjdO/eHXd3dxwcHGjatCnr1q0z2q6fnx8ff/wxzz33HI6Ojvj4+DBz5kzD87m5ubzyyit4enpiY2ODr68v48ePN7x2yZIlfPfdd+h0Ovr37w+od2t3794dBwcHnJyc6Nmzp9F3xPWzMbNmzTKah02n0/HNN9/QpUsX7OzsqFu3LjExMRw7dox27dphb29PixYtOH78uNExLF++nMaNG2NjY0ONGjV47733jEKkTqfj66+/plu3btjb2/PRRx/d8v4+++yzXL16lSVLlhitj4+PZ/369QwcOPCu3s8HtW/fPjp06ICtrS2VK1dm0KBBXLly4wao9evX06xZM8Pl05YtW3Ly5EkA9uzZQ/v27XF0dMTJyYnQ0FB27NhRrPU9KM1ClJWVFaGhoURHRxvW6fV6oqOjCQ8PL/Q14eHhRu0B1q5da2jv7++Ph4eHUZuMjAy2bt1qaHP9L2RcXJyhTV5eHgkJCYZZssPDw9m3b5/RXYJr167FycnJKHyZmsggNUTtSrxEakb2HVoLIcotRYHcTG2WYhxmZeTIkUyYMIFDhw7RoEEDrly5wqOPPkp0dDS7d++mU6dOdO3a1fAf4OumTJlCkyZN2L17Ny+//DIvvfSS4d/8adOmsWLFChYtWkRcXBw//vgjfn5+AGzfvp1OnTrRs2dPkpOT+fzzz9Hr9XTv3p0LFy7wzz//sHbtWk6cOEGvXr2M9nns2DGWLFnC0qVLiY2NNaz/4IMP6Nu3L7GxsdSpU4enn36awYMHM2rUKHbs2IGiKLzyyiuG9hs2bKBv374MGzaMgwcP8s033zBv3rxbgtK4ceN47LHH2LdvH88999wt752bmxvdu3dnzpw5RuvnzZtH9erV6dix412/n/crMzOTyMhIXF1d2b59O4sXL2bdunWG483PzycqKoq2bduyd+9eYmJiGDRoEDqdDoBnnnmG6tWrs337dnbu3MnIkSOxtLQsltqKTcn0eb87CxYsUKytrZV58+YpBw8eVAYNGqS4uLgY7orr06ePMnLkSEP7TZs2KRYWFsrkyZOVQ4cOKWPHjlUsLS2Vffv2GdpMmDBBcXFxUZYvX67s3btX6d69u+Lv72/U+37YsGFKtWrVlD/++EM5fPiwMnDgQKVq1arKhQsXFEVRlPz8fKV+/fpKx44dldjYWGXNmjVKlSpVlFGjRt3T8d1t7/7i9Nj0jYrviJXKd5vjS22fQght3XKXUc4VRRnrpM2Sc+We6587d67i7OxsePz3338rgLJs2bI7vjYoKEj54osvDI99fX2VZ5991vBYr9crVatWVb7++mtFURRl6NChSocOHRS9Xl/o9rp3767069fP8PjPP/9UzM3NlcTERMO6AwcOKICybds2RVEUw3dRWlqa0bYA5d133zU8jomJUQBl9uzZhnU///yzYmNjY3j80EMPKR9//LHRdr7//nvF09PTaLuvvfba7d+Ua9asWaPodDrlxIkThvfC19fXqKb/Kuz9/Oyzz27bfuzYsUrDhg0LfW7mzJmKq6urcuXKjT8Tq1atMtz9fv78eQVQ1q9fX+jrHR0dlXnz5hVxhA+mTN+dB9CrVy8mT57MmDFjCAkJITY2ljVr1hg6cScmJpKcfKN/T4sWLfjpp5+YOXMmDRs25JdffmHZsmXUr1/f0Oatt95i6NChDBo0iKZNm3LlyhXWrFljOL0KMGnSJJ566in69OlD06ZNOXnyJH/99Reurq4AmJubs3LlSszNzQkPD+fZZ5+lb9++vP/++6X0ztw/wyU9mZBYCFHGNWnSxOjxlStXeOONN6hbty4uLi44ODhw6NChW86cNGjQwPD79cuE168s9O/fn9jYWAIDA3n11Vf5888/i6zh0KFDeHt7G91tXa9ePVxcXDh06JBhna+vL1WqVLnl9TfXcv27LTg42GhddnY2GRkZgHoJ6/3338fBwcGwvPDCCyQnJ5OVdeOmof++N4V5+OGHqV69OnPnzgUgOjqaxMREBgwYANz9+3m/Dh06RMOGDbG3tzesa9myJXq9nri4OCpVqkT//v2JjIyka9eufP7550bf+cOHD+f5558nIiKCCRMm3HLZ0xRYaF3AK6+8YnQq82br16+/Zd2TTz7Jk08+edvt6XQ63n///SIDj6WlJZMnT2by5Mm3bePr63vLaOhlQacgTz5efZgtJy5wMTMXV3srrUsSQpQ2Szt4+4x2+y4mN3/5ArzxxhusXbuWyZMnU6tWLWxtbenRo8ctHbn/e8lHp9MZbipq3Lgx8fHx/P7776xbt46ePXsSERHBL7/8Uqy1FlbL9ctUha27Xt+VK1d47733ePzxx2/Z1s0nA263v5uZmZnRv39/5s+fz7hx45g7dy7t27enRo0awN2/nyVp7ty5vPrqq6xZs4aFCxfy7rvvsnbtWpo3b864ceN4+umnWbVqFb///jtjx45lwYIFPPbYY6VW351oHqJE8fKpbEc9TycOJmew9lAqPZuU3lhVQggTodOB1Z2/ZMuaTZs20b9/f8OX6JUrV0hISLjn7Tg5OdGrVy969epFjx496NSpExcuXKBSpUq3tK1bty5JSUkkJSUZzkYdPHiQS5culUgf2caNGxMXF0etWrWKZXsDBgzgww8/ZOnSpfz666/MmjXL8FxxvZ+3U7duXebNm0dmZqYh9G3atAkzMzMCAwMN7Ro1akSjRo0YNWoU4eHh/PTTTzRv3hyA2rVrU7t2bf73v//Ru3dv5s6dKyFKlKxO9T04mJzBH/tTJEQJIcqNgIAAli5dSteuXdHpdIwePdpwBuduffrpp3h6etKoUSPMzMxYvHgxHh4etx1YMyIiguDgYJ555hmmTp1Kfn4+L7/8Mm3btr2rS2r3asyYMXTp0gUfHx969OiBmZkZe/bsYf/+/Xz44Yf3vD1/f386dOjAoEGDsLa2NjrDVRzvJ8DVq1eNOtMDODo68swzzzB27Fj69evHuHHjOHv2LEOHDqVPnz64u7sTHx/PzJkz6datG15eXsTFxXH06FH69u3L1atXefPNN+nRowf+/v6cOnWK7du388QTT9xzfSWpwo0TVRFc7xe14eg5ruSY5qTJQghxrz799FNcXV1p0aIFXbt2JTIyksaNG9/TNhwdHZk4cSJNmjShadOmJCQksHr1aszMCv861Ol0LF++HFdXV9q0aUNERAQ1atRg4cKFxXFIt4iMjGTlypX8+eefNG3alObNm/PZZ58Z7h6/HwMHDuTixYs8/fTTRpcEi+P9BDhy5IjhbNL1ZfDgwdjZ2fHHH39w4cIFmjZtSo8ePXjooYf48ssvAbCzs+Pw4cM88cQT1K5dm0GDBjFkyBAGDx6Mubk558+fp2/fvtSuXZuePXvyyCOP8N577933+1ASdIpSjPejCiMZGRk4OzuTnp5eqgNvKorCQ1P+4cS5TL7o3YiuDb1Kbd9CiNKXnZ1NfHy80RhFQoiiFfX35m6/v+VMVDmk0+lkLj0hhBCihEmIKqceuRai/o5LIzuvQONqhBBCiPJHQlQ5FVzNGS9nG7JyC9hw9MEnmRRCCCGEMQlR5ZRc0hNCCCFKloSocqzTtbn01h1KJa/g3m9bFUKULXKfkBB3rzj+vkiIKsea+FXCzcGK9Kt5bDlxXutyhBAlxNzcHKBUR5oWoqy7Po3Og0xqLINtlmPmZjoerufBz9sSWbM/hdYBt87rJIQo+ywsLLCzs+Ps2bNYWlredswjIYR6BiorK4u0tDRcXFwM/wm5HxKiyrlO9dUQ9ceBVN7vXh9zM53WJQkhiplOp8PT05P4+HhOnjypdTlClAkuLi54eHg80DYkRJVz4TUq42hjwbkrOexOvEgTv1vnhhJClH1WVlYEBATIJT0h7oKlpeUDnYG6TkJUOWdlYUZEXXd+3X2a3/enSIgSohwzMzOTEcuFKEVy4bwC6HTTUAdy944QQghRPCREVQBtAqpga2nO6UtXOXAmQ+tyhBBCiHJBQlQFYGtlTrtA9c48GXhTCCGEKB4SoioIwyW9AxKihBBCiOIgIaqCaF+nKpbmOo6lXeFY2mWtyxFCCCHKPAlRFYSTjSWtarkBcklPCCGEKA4SoioQuaQnhBBCFB8JURVIRF13zHSw/3QGSReytC5HCCGEKNMkRFUglR2saeavDrb5h5yNEkIIIR6IhKgKplPQjYE3hRBCCHH/JERVMJHX+kXtTLxIWka2xtUIIYQQZZeEqArG09mWEG8XFAX+PJiqdTlCCCFEmSUhqgK6fpee9IsSQggh7p+EqAroer+omOPnuZSVq3E1QgghRNkkIaoC8nOzp46HI/l6hXWH0rQuRwghhCiTJERVUIaBN+UuPSGEEOK+mESImj59On5+ftjY2BAWFsa2bduKbL948WLq1KmDjY0NwcHBrF692uh5RVEYM2YMnp6e2NraEhERwdGjR43a+Pn5odPpjJYJEyYYnk9ISLjleZ1Ox5YtW4rvwDV0PUT9e/QsmTn5GlcjhBBClD2ah6iFCxcyfPhwxo4dy65du2jYsCGRkZGkpRV+mWnz5s307t2bgQMHsnv3bqKiooiKimL//v2GNhMnTmTatGnMmDGDrVu3Ym9vT2RkJNnZxrf0v//++yQnJxuWoUOH3rK/devWGbUJDQ0t3jdAI4HujvhVtiM3X8/6uLNalyOEEEKUOZqHqE8//ZQXXniBAQMGUK9ePWbMmIGdnR1z5swptP3nn39Op06dePPNN6lbty4ffPABjRs35ssvvwTUs1BTp07l3XffpXv37jRo0IDvvvuOM2fOsGzZMqNtOTo64uHhYVjs7e1v2V/lypWN2lhaWhb7e6AFnU5nGDNK5tITQggh7p2mISo3N5edO3cSERFhWGdmZkZERAQxMTGFviYmJsaoPUBkZKShfXx8PCkpKUZtnJ2dCQsLu2WbEyZMoHLlyjRq1IhJkyaRn3/rZa1u3bpRtWpVWrVqxYoVK4o8npycHDIyMowWU/ZIfU8A/jqUSnZegcbVCCGEEGWLpiHq3LlzFBQU4O7ubrTe3d2dlJTCz46kpKQU2f76zztt89VXX2XBggX8/fffDB48mI8//pi33nrL8LyDgwNTpkxh8eLFrFq1ilatWhEVFVVkkBo/fjzOzs6Gxdvb+y7eBe00qOaMp7MNmbkFbDp2TutyhBBCiDLFQusCtDJ8+HDD7w0aNMDKyorBgwczfvx4rK2tcXNzM2rTtGlTzpw5w6RJk+jWrVuh2xw1apTRazIyMkw6SJmZ6YgM8mDe5gTW7E/hobrud36REEIIIQCNz0S5ublhbm5Oaqrx9COpqal4eHgU+hoPD48i21//eS/bBAgLCyM/P5+EhIQi2xw7duy2z1tbW+Pk5GS0mLrIawNvrj2USn6BXuNqhBBCiLJD0xBlZWVFaGgo0dHRhnV6vZ7o6GjCw8MLfU14eLhRe4C1a9ca2vv7++Ph4WHUJiMjg61bt952mwCxsbGYmZlRtWrVItt4enre1bGVFc38K1HZ3opLWXlsjb+gdTlCCCFEmaH55bzhw4fTr18/mjRpQrNmzZg6dSqZmZkMGDAAgL59+1KtWjXGjx8PwLBhw2jbti1Tpkyhc+fOLFiwgB07djBz5kxAvevstdde48MPPyQgIAB/f39Gjx6Nl5cXUVFRgNo5fevWrbRv3x5HR0diYmL43//+x7PPPourqysA8+fPx8rKikaNGgGwdOlS5syZw6xZs0r5HSpZ5mY6Hq7nzoLtSazZn0LLWm5alySEEEKUCZqHqF69enH27FnGjBlDSkoKISEhrFmzxtAxPDExETOzGyfMWrRowU8//cS7777L22+/TUBAAMuWLaN+/fqGNm+99RaZmZkMGjSIS5cu0apVK9asWYONjQ2gXnZbsGAB48aNIycnB39/f/73v/8Z9WcC+OCDDzh58iQWFhbUqVOHhQsX0qNHj1J4V0pXZH0PFmxP4o8DKbzXLQgzM53WJQkhhBAmT6coiqJ1EeVVRkYGzs7OpKenm3T/qJz8App8sI7LOfkseakFob6uWpckhBBCaOZuv781H2xTaM/awpwOddW+YH/IwJtCCCHEXZEQJQB45Nro5b/vT0ZOTgohhBB3JiFKANCmdhVsLM1IunCVg8mmPdK6EEIIYQokRAkA7KwsaFu7CgB/7JdLekIIIcSdSIgSBp1kQmIhhBDirkmIEgYd6rhjaa7jSOoVjp+9onU5QgghhEmTECUMnG0taVFTHWxzjVzSE0IIIYokIaosStoGGz8rkU1fv6QnQx0IIYQQRZMQVdZciIfZD8O69+BsXLFv/uF67uh0sPdUOqcvXS327QshhBDlhYSosqaSP9TpAiglcjbKzcGapn6VALlLTwghhCiKhKiyqPW1Of72LoKLJ4t984/IXXpCCCHEHUmIKouqhUKN9qAUwKbPi33zkUFqiNqecIGkC1nFvn0hhBCiPJAQVVa1fl39ufsHuFy8Z4y8XGxpWasyigIfrjpYrNsWQgghygsJUWWVXyvwDoOCHIiZXuybH9MlCHMzHX8cSOXvuLRi374QQghR1kmIKqt0uhtno3bMgawLxbr5QA9HnmvpB8C4FQfIziso1u0LIYQQZZ2EqLIsoCO4B0PuFdg2s9g3PyyiNu5O1pw8n8W3/54o9u0LIYQQZZmEqLJMp7txp96WryHncrFu3sHagnc61wPgy7+PSSdzIYQQ4iYSosq6et2hci3IvgQ75hb75rs28CS8RmVy8vW8v1I6mQshhBDXSYgq68zModX/1N9jvoS87GLdvE6n4/3uQViY6Vh7MJW/DqcW6/aFEEKIskpCVHkQ3BOcqsOVVIj9odg3H+DuyMBW/gCMW3FQOpkLIYQQSIgqHyysoOUw9fdNn0NBXrHvYuhDAXg42ZB4IYsZ/xwv9u0LIYQQZY2EqPKicR+wrwKXEmHfL8W+eQdrC97tUheAr9YfJ/G8dDIXQghRsUmIKi8sbaH5y+rvGz8Fvb7Yd9E52JNWtdzIzdfz3m8Hin37QgghRFkiIao8afo8WDvDuSNw+Ldi37xOp2NctyAszXVEH05j3UHpZC6EEKLikhBVntg4Qdgg9fcNU0BRin0Xtao68HzrGgCM+01GMhdCCFFxSYgqb8JeAks7SN4Dx6JLZBdDO9TCy9mGUxev8tV66WQuhBCiYpIQVd7YV4bQAervG6aUyC7srCwY3UUdyXzGP8dJOJdZIvsRQgghTJmEqPKoxStgbgWJm+Hk5hLZRaf6HrQOUDuZj/vtAEoJXDoUQgghTJmEqPLIyQtCnlZ/L6GzUTqdjveudTJfH3eWP6WTuRBCiApGQlR51XIY6Mzg2Do4E1siu6hRxYFBbdRO5u//dpCrudLJXAghRMUhIaq8qlQD6vdQfy+hs1EAQ9rXopqLLacvXWX638dKbD9CCCGEqTGJEDV9+nT8/PywsbEhLCyMbdu2Fdl+8eLF1KlTBxsbG4KDg1m9erXR84qiMGbMGDw9PbG1tSUiIoKjR48atfHz80On0xktEyZMMGqzd+9eWrdujY2NDd7e3kycOLF4Dri0XJ+Y+NBvcDauRHZhZ2XBmK5qJ/OZ/57gxNkrJbIfIYQQwtRoHqIWLlzI8OHDGTt2LLt27aJhw4ZERkaSlpZWaPvNmzfTu3dvBg4cyO7du4mKiiIqKor9+/cb2kycOJFp06YxY8YMtm7dir29PZGRkWRnZxtt6/333yc5OdmwDB061PBcRkYGHTt2xNfXl507dzJp0iTGjRvHzJkzS+aNKAnu9aBOF0CBjVNLbDcd67nTLrAKuQV6xq6QTuZCCCEqCEVjzZo1U4YMGWJ4XFBQoHh5eSnjx48vtH3Pnj2Vzp07G60LCwtTBg8erCiKouj1esXDw0OZNGmS4flLly4p1tbWys8//2xY5+vrq3z22We3reurr75SXF1dlZycHMO6ESNGKIGBgbd9TXZ2tpKenm5YkpKSFEBJT0+/7WtKXNIORRnrpCjjXBXlQkKJ7Sb+7BUl4O3Viu+Ilcrv+86U2H6EEEKIkpaenn5X39+anonKzc1l586dREREGNaZmZkRERFBTExMoa+JiYkxag8QGRlpaB8fH09KSopRG2dnZ8LCwm7Z5oQJE6hcuTKNGjVi0qRJ5OfnG+2nTZs2WFlZGe0nLi6OixcvFlrb+PHjcXZ2Nize3t53+U6UoOqhUKMdKAWweVqJ7cbPzZ4X297oZJ6Vm3+HVwghhBBlm6Yh6ty5cxQUFODu7m603t3dnZSUlEJfk5KSUmT76z/vtM1XX32VBQsW8PfffzN48GA+/vhj3nrrrTvu5+Z9/NeoUaNIT083LElJSbc99lLV+g31567v4XLhtReHl9rVorqrLWfSs/niL+lkLoQQonzTvE+UVoYPH067du1o0KABL774IlOmTOGLL74gJyfnvrdpbW2Nk5OT0WIS/FpB9WZQkAMx00tsN7ZW5oztGgTArA0nOJYmncyFEEKUX5qGKDc3N8zNzUlNNR6oMTU1FQ8Pj0Jf4+HhUWT76z/vZZsAYWFh5Ofnk5CQUOR+bt5HmaHTQZtrZ6N2zIGsCyW2q4i6VelQpyp5BQrjpJO5EEKIckzTEGVlZUVoaCjR0TcmytXr9URHRxMeHl7oa8LDw43aA6xdu9bQ3t/fHw8PD6M2GRkZbN269bbbBIiNjcXMzIyqVasa9vPvv/+Sl5dntJ/AwEBcXV3v/WC1FtAR3IMh9wpsK7k7DHU6HWO71sPKwoyNx86xel/JXT4UQgghtKT55bzhw4fz7bffMn/+fA4dOsRLL71EZmYmAwaok+j27duXUaNGGdoPGzaMNWvWMGXKFA4fPsy4cePYsWMHr7zyCqB+ib/22mt8+OGHrFixgn379tG3b1+8vLyIiooC1E7jU6dOZc+ePZw4cYIff/yR//3vfzz77LOGgPT0009jZWXFwIEDOXDgAAsXLuTzzz9n+PDhpfsGFRedDlpfq33L15BzucR25VvZnpfb1QTgg5UHycyRTuZCCCHKodK5WbBoX3zxheLj46NYWVkpzZo1U7Zs2WJ4rm3btkq/fv2M2i9atEipXbu2YmVlpQQFBSmrVq0yel6v1yujR49W3N3dFWtra+Whhx5S4uLiDM/v3LlTCQsLU5ydnRUbGxulbt26yscff6xkZ2cbbWfPnj1Kq1atFGtra6VatWrKhAkT7um47vYWyVJTkK8onzdShzzY+HmJ7upqbr7S+pO/FN8RK5WPVx8s0X0JIYQQxeluv791iiKdVkpKRkYGzs7OpKenm04n813fw4pXwMEdhu0FS5sS29Vfh1N5bt4OLMx0/D6sNQHujiW2LyGEEKK43O33t+aX80Qpa9ALnKrDlVSI/aFEd9WhjjsRdd3J1yuMWS6dzIUQQpQvEqIqGgsraPmq+vumz6Egr+j2D2hs13pYW5gRc+I8v+1NLtF9CSGEEKVJQlRF1Lgv2FeBS4mw75cS3ZV3JTuGtK8FwIcrD3JFOpkLIYQoJyREVUSWttD8ZfX3jZ+CXl+iuxvUpga+le1Iu5zD5+uOlOi+hBBCiNIiIaqiajoQrJ3h3BE4vLJEd2Vjac64bupI5nM2JRCXUnLDKwghhBClRUJURWXjDGGD1N83TIYS7vTdPrAqkUHuFOgVxizfL53MhRBClHkSoiqysJfA0g6S98Dx6Du3f0Cju9TDxtKMrfEXWLHnTInvTwghhChJEqIqMvvKEKqODM+/U0p8d9Vd7RjaIQCAD1cdIiO7ZO8MFEIIIUqShKiKrsUrYG4FiZvh5OYS393zrf3xd7Pn7OUcpq49WuL7E0IIIUqKhKiKzskLQp5Wf9/waYnvztriRifz+TEJHErOKPF9CiGEECVBQpSAlsNAZwbH1sKZ2BLfXdvaVXikvoehk3mBXjqZCyGEKHskRAmoVAPqP6H+vrHkz0YBvNulHraW5mxPuMjA+dulf5QQQogyR0KUULUarv48uALOxpX47qq52PJZrxBsLM1YH3eWx6ZvIv5cZonvVwghhCguEqKEyr0eBHYGFNg4tVR22am+B4sHt8DT2YbjZzPp/uVGNhw9Wyr7FkIIIR6UhChxQ+vX1Z97F8LFk6Wyy+Dqzix/pSWNfFzIyM6n35xtzNkYL4NxCiGEMHkSosQN1UOhRjtQCmDztFLbbVVHGxYMak6P0OroFXh/5UFGLtlHTn5BqdUghBBC3CsJUcJY6zfUn7u+h8uppbZbawtzJvVowLud62Kmg4U7knjm262cvZxTajUIIYQQ90JClDDm1wqqN4OCHIj5slR3rdPpeL51Deb0b4qjjQU7Tl6k+5cbOXAmvVTrEEIIIe6GhChhTKe70TdqxxxIO1TqJbQLrMqyIS2p4WbPmfRsenwdw+p9yaVehxBCCFEUCVHiVrUjoXpTyL0Ccx+FM7tLvYSaVRz49eWWtKldhat5Bbz84y4+XXsEvQzMKYQQwkRIiBK30ung6UXg1RiuXoB5XUtlXr3/crazZE6/Jjzfyh+AadFHefnHXWTm5Jd6LUIIIcR/SYgShbOrBH2Xg29LyL0M3z8Ox9aVehkW5ma826UeE3s0wMrcjDUHUnji680kXcgq9VqEEEKIm0mIErdn4wTP/AK1Hob8q/DTU+qI5hro2cSbnweF4eZgzeGUy3Sfvolt8Rc0qUUIIYQACVHiTqzs4KmfoF530OfB4n4Q+7MmpYT6VmLFKy2pX82JC5m5PDNrCz9vS9SkFiGEEEJClLgzCyt4Yg6EPAOKHpa9CNu+1aQULxdbFg9uQecGnuQVKIxauo+xy/eTX6DXpB4hhBAVl4QocXfMLaDblxD2ovp49Ruw4VNNSrG1MufL3o14o2NtAObHnKTf3G1cysrVpB4hhBAVk4QocffMzKDTBGjzpvo4+j1Y9x5oMM+dTqfjlQ4BfNMnFDsrczYdO0/36Zs4mnq51GsRQghRMUmIEvdGp4MO70LEe+rjjZ/C6jdBr83ltMggD5a+3ILqrracPJ/FY19tJvpQ6U1XI4QQouKSECXuT6vXoPOngA62fwvLX4YCbcZvquPhxPIhLWnmX4krOfk8/90Ovl5/HEWDM2RCCCEqDglR4v41HQiPfQM6c9jzM/zSH/K1mTC4soM1PwwM4+kwHxQFPllzmP8tjCU7r0CTeoQQQpR/JhGipk+fjp+fHzY2NoSFhbFt27Yi2y9evJg6depgY2NDcHAwq1evNnpeURTGjBmDp6cntra2REREcPTo0UK3lZOTQ0hICDqdjtjYWMP6hIQEdDrdLcuWLVse+HjLlYa9oOd3YG4Fh36Dn3tDrjYDYVpZmPHxY8F80D0IczMdy2LP0OubGFLSszWpRwghRPmmeYhauHAhw4cPZ+zYsezatYuGDRsSGRlJWlpaoe03b95M7969GThwILt37yYqKoqoqCj2799vaDNx4kSmTZvGjBkz2Lp1K/b29kRGRpKdfeuX6VtvvYWXl9dt61u3bh3JycmGJTQ09MEPuryp2wWeXgiWdnA8Gn54ArLTNSunT7gf3z/XDBc7S/acSqfrlxtZtTdZLu8JIYQoVjpF42+WsLAwmjZtypdffgmAXq/H29uboUOHMnLkyFva9+rVi8zMTFauXGlY17x5c0JCQpgxYwaKouDl5cXrr7/OG2+8AUB6ejru7u7MmzePp556yvC633//neHDh7NkyRKCgoLYvXs3ISEhgHomyt/f32jdvcrIyMDZ2Zn09HScnJzuaxtlSuIW+PFJyMkAzxB4dinYV9aunPNZPP/ddo6kXgGgRc3KvNctiAB3R81qEkIIYfru9vtb0zNRubm57Ny5k4iICMM6MzMzIiIiiImJKfQ1MTExRu0BIiMjDe3j4+NJSUkxauPs7ExYWJjRNlNTU3nhhRf4/vvvsbOzu22N3bp1o2rVqrRq1YoVK4qe8iQnJ4eMjAyjpULxaQ79fgO7ypAcC/MehYxk7cqpbMeKV1ox7KEArCzM2Hz8PI98voEPVh4kIztPs7qEEEKUD5qGqHPnzlFQUIC7u7vRend3d1JSUgp9TUpKSpHtr/8sqo2iKPTv358XX3yRJk2aFLofBwcHpkyZwuLFi1m1ahWtWrUiKiqqyCA1fvx4nJ2dDYu3t3cRR19OeYXAgN/B0RPOHoa5neDiSc3KsbE0538P12bd/9rycD138vUKszfG02HyPyzZeQq9Xi7xCSGEuD+a94nSwhdffMHly5cZNWrUbdu4ubkxfPhww+XGCRMm8OyzzzJp0qTbvmbUqFGkp6cblqSkpJIo3/RVCYTn1oCLL1xMgDmd4OwRTUvyqWzHt32bMG9AU/zd7Dl3JYfXF+/hyW9i2H9au/5bQgghyi5NQ5Sbmxvm5uakphoPjpiamoqHh0ehr/Hw8Ciy/fWfRbX566+/iImJwdraGgsLC2rVqgVAkyZN6Nev323rDQsL49ixY7d93traGicnJ6OlwnL1U4OUWyBcPgNzH4HkPVpXRbvAqqx5rTUjOtXBzsqcnScv0vXLjbzz6z4uZsq0MUIIIe6epiHKysqK0NBQoqOjDev0ej3R0dGEh4cX+prw8HCj9gBr1641tPf398fDw8OoTUZGBlu3bjW0mTZtGnv27CE2NpbY2FjDEAkLFy7ko48+um29sbGxeHp63t/BVkROXuqlPc+GkHUO5nWFxK1aV4W1hTkvtavJX6+3o1tDLxQFftyaSPsp6/lx60kK5BKfEEKIu2ChdQHDhw+nX79+NGnShGbNmjF16lQyMzMZMGAAAH379qVatWqMHz8egGHDhtG2bVumTJlC586dWbBgATt27GDmzJmAOqfaa6+9xocffkhAQAD+/v6MHj0aLy8voqKiAPDx8TGqwcHBAYCaNWtSvXp1AObPn4+VlRWNGjUCYOnSpcyZM4dZs2aV+HtSrthXVjub/9gTkrbA91Hw1E9Qs73WleHhbMO03o14OsyHscsPEJd6mXd+3c/P2xJ5r1t9Qn1dtS5RCCGECdM8RPXq1YuzZ88yZswYUlJSCAkJYc2aNYaO4YmJiZiZ3Thh1qJFC3766Sfeffdd3n77bQICAli2bBn169c3tHnrrbfIzMxk0KBBXLp0iVatWrFmzRpsbGzuqbYPPviAkydPYmFhQZ06dVi4cCE9evQongOvSGycoc9SWPgsHP8LfuoJT86HOo9qXRkAzWtUZtWrrfh+y0k+XXuE/aczeOLrzTzRuDojHgmkquO9/bkRQghRMWg+TlR5VuHGibqT/Bz45Tk4vFKdKuaxb6DBk1pXZeTclRwmrjnMoh2nAHC0tmBYRAD9WvhhaV4h78MQQogK526/vyVElSAJUYUoyIflQ2DvAkAHj06Cps+DTqd1ZUZ2J15k7IoD7D2l3rkXUNWB97oF0aKWm8aVCSGEKGkSokyAhKjb0Oth9RuwY7b62CMYWr4G9aLAXPMrzAZ6vcKiHUl8suYwF7PUwTk7B3vyTue6eLnYalydEEKIkiIhygRIiCqCosC/k2Hjp5B3bcJiZx8IHwKNngVrB23ru8mlrFw+XXuEH7acRK+AraU5r3SoxfOt/bG2MNe6PCGEEMVMQpQJkBB1F7IuwPbZsHWGOgwCgI0LNHsBmg0Ghyqalnezg2cyGLtiP9sTLgLgV9mOsV2DaF+nqsaVCSGEKE4SokyAhKh7kHcV9vwMm7+ACyfUdebWEPI0tBgKlWtqW981iqKwPPYMH60+xNnLOQBE1K3K6C718K1sr3F1QgghioOEKBMgIeo+6Avg8CrYNBVO77y2Ugd1u6j9pqoXPtdhabucnccXfx1jzsZ48vUKluY6ujWsxsBW/tTzks9aCCHKMglRJkBC1ANQFDi5GTZPgyNrbqz3bQktXoWAjmCm/ZADx9Iu895vB9lw9JxhXXiNygxs5U+HOlUxMzOtuw6FEELcmYQoEyAhqpikHVIv8+1dBHr1Ljmq1FEv8wU/CRbW2taHOiTC7I3x/L4/xTBtTA03ewa09OOJ0OrYWZnOXYdCCCGKVqIhKikpCZ1OZ5giZdu2bfz000/Uq1ePQYMG3X/V5YyEqGKWcQa2fA0750FOhrrO0ROavwSh/dWR0TV2+tJV5m9O4OdtiVzOzgfA2daSp8N86Bfuh4ezjH4uhBCmrkRDVOvWrRk0aBB9+vQhJSWFwMBAgoKCOHr0KEOHDmXMmDEPVHx5ISGqhGSnq0Fqy9dwOVldZ+UITQaogcrJS9PyAK7k5PPLjiTmbk7g5Hl1CAcLMx2dG3gysJU/Daq7aFugEEKI2yrREOXq6sqWLVsIDAxk2rRpLFy4kE2bNvHnn3/y4osvcuLEiQcqvryQEFXC8nNh32K139TZw+o6M0to0FO91Fe1rrb1AQV6hXWHUpm9MZ5t8RcM65v6uTKwVQ0erueOufSbEkIIk1KiIcrBwYH9+/fj5+dHt27daNmyJSNGjCAxMZHAwECuXr36QMWXFxKiSoleD0f/VMPUyU031gdEQsth4NvCJKaV2XcqnTmb4vltzxnyr/Wb8qlkR/8WfvRs6o2DtfSbEkIIU1CiISosLIz27dvTuXNnOnbsyJYtW2jYsCFbtmyhR48enDp16oGKLy8kRGng1A7Y9Dkc+g249ke7WiiEvQj1uptEJ/SU9Gy+i0ngp22JXLo2nYyjtQVPNfOmXws/qrvaaVyhEEJUbCUaotavX89jjz1GRkYG/fr1Y86cOQC8/fbbHD58mKVLl95/5eWIhCgNnT8OMV/C7h+hQB0UE/uqagf0JgNMot/U1dwCluw6xZxN8Zw4mwmAuZmOTkEePNfKn1BfV40rFEKIiqnEhzgoKCggIyMDV9cb/9AnJCRgZ2dH1aoyDQZIiDIJV86qndB3zL7RCV1nDnW7QrNBJnGpT69XWH8kjdkb49l07LxhfSMfFwa28qdTkAcW5tqPiSWEEBVFiYaoq1evoigKdnbqZYeTJ0/y66+/UrduXSIjI++/6nJGQpQJKchTR0LfNtO435R7fXWevuAnwUr7aVsOJWcwZ2M8y2PPkFugB6Caiy39WvjSq6kPzraWGlcohBDlX4mGqI4dO/L444/z4osvcunSJerUqYOlpSXnzp3j008/5aWXXnqg4ssLCVEmKmU/bP9WHbwzTx1+ABtnaNQHmg6ESjW0rQ9Iu5zND1sS+XHLSc5n5gJgb2XOk028ea6lPz6Vpd+UEEKUlBINUW5ubvzzzz8EBQUxa9YsvvjiC3bv3s2SJUsYM2YMhw4deqDiywsJUSbu6kWI/Qm2fQsX46+t1KlTyjQbBDU7aD61THZeActjTzN7YzxHUq+oFeqgYz13nm9dgya+ruhM4M5DIYQoT0o0RNnZ2XH48GF8fHzo2bMnQUFBjB07lqSkJAIDA8nKynqg4ssLCVFlhF4Px9apl/qOrb2xvlINaPoChDwNti6alQegKAobjp5j9sZ4/jly1rC+QXVnBrby59FgTyyl35QQQhSLEg1RDRo04Pnnn+exxx6jfv36rFmzhvDwcHbu3Ennzp1JSUl5oOLLCwlRZdD547B9Nuz+AXLS1XWW9tCwlxqo3OtpWx9wNPUyczbFs2TXaXLz1X5Tns429GvhR++mPjjbSb8pIYR4ECUaon755ReefvppCgoK6NChA2vXqv97Hz9+PP/++y+///77/VdejkiIKsNyrsC+ReqlvrSDN9b7tVY7ogd2BnNtB8c8fyWHH7cm8l3MSc5dUYdxsLMy58nQ6gxo6Y+fm/Yd5YUQoiwq8SEOUlJSSE5OpmHDhphd6zeybds2nJycqFOnzv1VXc5IiCoHFEW9m2/bTDi0EpQCdb1TNWjyHDTuBw5VNC0xJ7+AFbFnmL0xnsMplwG131REXXcGtvInzL+S9JsSQoh7UOIh6rrro5NXr179QTZTLkmIKmfST8OOOeq4U1nn1HXmVhD0uNoRvXqopuUpisLm4+eZteEEf8fd6DdVv5oTA1v50znYCysL6TclhBB3UqIhSq/X8+GHHzJlyhSuXFHvGHJ0dOT111/nnXfeMZyZqugkRJVT+TlwYJl6dur0jhvrvcOg+ctQp4vml/qOpV1h7qZ4luw6RXae2m/K3cmavuF+PBPmg4udlab1CSGEKSvREDVq1Chmz57Ne++9R8uWLQHYuHEj48aN44UXXuCjjz66/8rLEQlRFcDpnWq/qf1LoEAdzwlnH2j+ojrulI22n/vFzFx+2pbI/M0JpF1W+03ZWprTI7Q6A1r6UaOKg6b1CSGEKSrREOXl5cWMGTPo1q2b0frly5fz8ssvc/r06XuvuBySEFWBXE6F7bPU6WWyrk3dYuUIjftA2GBw9dO0vNx8PSv3nmHWhngOJmcAar+ph+pU5blW/oTXqCz9poQQ4poSDVE2Njbs3buX2rVrG62Pi4sjJCSEq1ev3nvF5ZCEqAoo76o6EvqWr+DsYXWdzky9xBc+RL3kp2FYURSFLScuMHvjCaIPp3H9b389T7XfVNeG0m9KCCFKNESFhYURFhbGtGnTjNYPHTqUbdu2sXXr1nuvuBySEFWBKQocj4aY6XD8rxvrq4Wq/abqdQdzbcdzOnH2CnM3JfDLzlNczVPvOqziaM3TzXx4OswHdycbTesTQgitlGiI+ueff+jcuTM+Pj6Eh4cDEBMTQ1JSEqtXr6Z169b3X3k5IiFKAJB2SD0ztWchFKj9knCqpl7ma9xP89HQL2Xd6DeVmqHWZ26mIzLInT7N/WheQ4ZIEEJULCU+xMGZM2eYPn06hw+rlyzq1q3LoEGD+PDDD5k5c+b9VV3OSIgSRq6cVYdI2P4tZF4bgsDSHho9A2EvQuWampaXm6/njwMpfB9zkm0JFwzrA6o60Cfcl8caVcPRRkZDF0KUf3f7/X3fnR+8vLz46KOPWLJkCUuWLOHDDz/k4sWLzJ49+563NX36dPz8/LCxsSEsLIxt27YV2X7x4sXUqVMHGxsbgoODWb16tdHziqIwZswYPD09sbW1JSIigqNHjxa6rZycHEJCQtDpdMTGxho9t3fvXlq3bo2NjQ3e3t5MnDjxno9NCAOHKtBuBLy2H7pPh6pBkJepDpXwRSj8/DQkbIQHG7rtvllZmNG1oReLXgxnzWuteSbMBzsrc46mXWHM8gM0/zia0cv2cyT1sib1CSGEqdG8B+nChQsZPnw4Y8eOZdeuXTRs2JDIyEjS0tIKbb9582Z69+7NwIED2b17N1FRUURFRbF//35Dm4kTJzJt2jRmzJjB1q1bsbe3JzIykuzs7Fu299Zbb+Hl5XXL+oyMDDp27Iivry87d+5k0qRJjBs3Ts6yiQdnaQONnoWXNkGfZRDQEVAgbhXM6wwz26qX/vJzNSuxjocTHz0WzJa3H2Jc13rUrGJPZm4B3285ScfP/qXXNzGs2ptMXoFesxqFEEJrDzxi+c327NlD48aNKSgouOvXhIWF0bRpU7788ktAHcjT29uboUOHMnLkyFva9+rVi8zMTFauXGlY17x5c0JCQpgxYwaKouDl5cXrr7/OG2+8AUB6ejru7u7MmzePp556yvC633//neHDh7NkyRKCgoLYvXs3ISEhAHz99de88847pKSkYGWlDkw4cuRIli1bZriEeSdyOU/ctbNHrvWbWgD51+5udfRU5+kLHQB2lTQtT1EUYo6f57uYk6w9lEqBXv1no6qjNb2lI7oQopwp8ct5xSE3N5edO3cSERFhWGdmZkZERAQxMTGFviYmJsaoPUBkZKShfXx8PCkpKUZtnJ2dCQsLM9pmamoqL7zwAt9//z12dnaF7qdNmzaGAHV9P3FxcVy8eLHQ2nJycsjIyDBahLgrVWpD16kw/CB0GA0OHnA5GaLfh0/rwcr/wbnCL0mXBp1OR4tabszoE8rGEe15tUMt3BysSbucw+fRR2kx4S9e/nEnMcfPU4z/LxNCCJN2T3NTPP7440U+f+nSpXva+blz5ygoKMDd3d1ovbu7+23P9qSkpBTaPiUlxfD89XW3a6MoCv379+fFF1+kSZMmJCQkFLoff3//W7Zx/TlXV9dbXjN+/Hjee++92x2uEHdmVwnavAEtXoUDSyHmS0jZp3ZI3zEHarSDJgMh8BHNhkjwdLZleMdAXukQwJoDKXwfk8D2hIus3pfC6n0p0hFdCFFh3FOIcnZ2vuPzffv2faCCSsMXX3zB5cuXGTVqVLFud9SoUQwfPtzwOCMjA29v72Ldh6ggLKyg4VPQoJfa2TxmOhxZAyfWq4ujJzTuqw6R4FxNkxKtLMzo1tCLbg29OJScwfdbTrJs92lDR/RPfj/M442r0yfcl9rujprUKIQQJemeQtTcuXOLdedubm6Ym5uTmppqtD41NRUPD49CX+Ph4VFk++s/U1NT8fT0NGpzvb/TX3/9RUxMDNbW1kbbadKkCc888wzz58+/7X5u3sd/WVtb37JNIR6ITgf+rdXlYgLsnA+7v1cv9f3zCfw7CWo/Ak2eg5odQKPJv+t6OvHxY8GMfKQOS3ee4vstJzl+NpPvt5zk+y0nCfOvRJ9wXyKDPLA01/x+FiGEKBaa/mtmZWVFaGgo0dHRhnV6vZ7o6GjDIJ7/FR4ebtQeYO3atYb2/v7+eHh4GLXJyMhg69athjbTpk1jz549xMbGEhsbaxgiYeHChYbJk8PDw/n333/Jy8sz2k9gYGChl/KEKHGufhAxFv53EHrMAd9WoOjVu/p+fAKmhcDGzyDznGYlOtlY0r+lP+uGt+XH58PoFOSBuZmOrfEXeOWn3bSc8BefrT3CuSs5mtUohBDFpVjvzrsfCxcupF+/fnzzzTc0a9aMqVOnsmjRIg4fPoy7uzt9+/alWrVqjB8/HlCHOGjbti0TJkygc+fOLFiwgI8//phdu3ZRv359AD755BMmTJjA/Pnz8ff3Z/To0ezdu5eDBw9iY3PrHUQJCQn4+/sb3Z2Xnp5OYGAgHTt2ZMSIEezfv5/nnnuOzz77jEGDBt3VscndeaLEnY1T+0rF/gw56eo6cyuo2w2aDgSfcE3n6gNITr/KT1sT+XlbkiE82Via8VRTH15oU4NqLraa1ieEEP9V4iOWF6cvv/ySSZMmkZKSQkhICNOmTSMsLAyAdu3a4efnx7x58wztFy9ezLvvvktCQgIBAQFMnDiRRx991PC8oiiMHTuWmTNncunSJVq1asVXX311y4TJ1xUWokAdbHPIkCFs374dNzc3hg4dyogRI+76uCREiVKTmwX7l6iB6syuG+ur1FUv9TXsBTZF92ksabn5etYcSGHWhhPsPaUGPgszHVGNqvFi25rUquqgaX1CCHFdmQpR5ZWEKKGJM7vVMLXvF8jLUtdZ2kFwDzVQeTXStDxFUdh07DxfrT/G5uPnAfVkWacgD15uV4vg6tqGPSGEkBBlAiRECU1dvQR7F8GO2XD2piFDvBqrYar+E2B16xhppWl34kW+Wn+ctQdv3MTROsCNl9vVkomPhRCakRBlAiRECZOgKJAYA9tnw8HloL92s4S1M4T0VgNVlUBNS4xLucyMf46zYs8Zw2jojXxcGNKuFh3qVMXMTMKUEKL0SIgyARKihMm5chZif4Adc+HSyRvrfVtB0+egTld1jCqNJF3I4pt/j7Noxyly89V5+QLdHXm5fU06B3tiIcMjCCFKgYQoEyAhSpgsvR6O/6X2nTryuzpUAoB9FXWQz0Z91aloNJJ2OZvZG+P5cUsiV3LyAfCpZMfgtjV4onF1bCzNNatNCFH+SYgyARKiRJmQfgp2facO5Hkl5cZ67zBo1AeCHgNrbe6cS8/K47uYBOZuTuBCZi4AVRyteaG1P0+H+eJgfU/jBQshxF2REGUCJESJMqUgD47+Cbu+V38qBep6Kwc1SDXuC9WbajLuVFZuPgu3JzHz3xMkp2cD4GxrSb8Wfgxo4YervXaXIIUQ5Y+EKBMgIUqUWRnJsOdn2P0DXDh+Y71bIDTuAw2eAocqpV5Wbr6eZbGnmbH+OCfOZQJga2nO02E+vNC6Bh7Otw6mK4QQ90pClAmQECXKPEWBk5vV+foOLIP8q+p6MwsIfETtO1XrITAr3T5KBXqFPw6kMP3vYxw4kwGApbmOJxpXZ3Dbmvi72ZdqPUKI8kVClAmQECXKlex0dVT03T/A6Z031jt6qUMlNHoWKtUo1ZIUReHfo+eY/vcxtsVfAMBMB48Ge/Jyu1rU85K/d0KIeychygRIiBLlVuoBNUztWQBXL9xY79da7YxerxtYlu6ceDtPXuCrv48TfTjNsC6iblWGtK9FIx+ZNFwIcfckRJkACVGi3MvPgbjVamf0438B1/45sXZWp5lp3Ac8Q0q1M/qh5Aym/32MVfuSuf6vW6tabrzSoRZh/jIKuhDiziREmQAJUaJCuZQEsT+pZ6jSE2+sdw9Ww1Twk2BXqdTKOX72Cl+vP86y3afJvzYKehNfV17pUIu2tatImBJC3JaEKBMgIUpUSHo9xP+jdkY/tBIKctT15tZQt4t6ua9Gu1I7O2UYBX37KXIL1EFFg6s5M6R9LTrWc5cpZYQQt5AQZQIkRIkKL+sC7PsFdn8HKfturK/eDDp+AD7NS62U1Ixsvv33BD9uTeRqnjoGVm13B4a0ryVTygghjEiIMgESooS4yZlY9exU7E+Ql6Wuq9MFIt4Dt1qlVsaFzFzmbIxn/uYELl+bUsavsh0vt6tFVKNqWFlImBKiopMQZQIkRAlRiIxkWD9eDVSKHnTm0GQAtB1ZqgN4pl/N4/uYBGZvjOdiVh4AXs42vNiuJj2beMv8fEJUYBKiTICEKCGKkHYI1o2DI2vUx1aO0GoYNB8CVnalVkZmTj4/bU1k5oYTnL2s9t9yc7BmUBt/ngnzxV7m5xOiwpEQZQIkRAlxF+L/hT9HQ3Ks+tjRE9q/AyFPl+pI6Nl5BSzekcSMf05w+pI6MruLnSXPtfSnXws/nG0tS60WIYS2JESZAAlRQtwlvV4dDT36/RvDI1StBw+/D7UiSnWcqevz8329/jjx1+bnc7S2oE+4LwNb+VPZwbrUahFCaENClAmQECXEPcrLhu3fwr+T1GlmAPzbqnfyeTYs1VIK9Aqr9iUz/a9jxKVeBtTJjns382FQG5nsWIjyTEKUCZAQJcR9yroAG6bAtplQkAvooEEv6PAuuHiXail6vcK6Q6l8+fcx9p5Sg52VuRk9mlTn5XY1qe5aev23hBClQ0KUCZAQJcQDupgA0R/A/l/Ux+bW0PxFaDUcbF1KtZTrkx1/+ddRtidcBMDSXEevpt4MaV8LT+fSnStQCFFyJESZAAlRQhST07tg7RhI2KA+tnWFNm9B0+fBwqrUy9l64jyfRx9l8/HzgHpm6ukwH15uV5OqTnKZT4iyTkKUCZAQJUQxUhQ48ocaps7Fqetc/eChMRD0eKl2Pr9uy4nzfLr2CNviLwBgbWHGs819ebFtTao4Sgd0IcoqCVEmQEKUECWgIB9if4C/P4Yrqeq6aqHQ8UPwbVHq5SiKwubjapjaeVK9zGdjaUa/cD8Gt61JJfvSP1MmhHgwEqJMgIQoIUpQzhWI+RI2TYM8dSgCAh9Vp5GpUrvUy7neZ+rTtUfYk3QJAHsrc/q39OOF1jVwsZMwJURZISHKBEiIEqIUXE5Vp5HZ9R0oBeo0MqH9oP27YF+51MtRFIW/49L4dO0R9p/OAMDB2oLnWvkzsJW/DNopRBkgIcoESIgSohSdjVOnkYlbrT62c4NHJ0HQY5r0l1IUhbUHU/l07REOp6jjTDnaWPBC6xoMaOmHo42EKSFMlYQoEyAhSggNJGyEVW/A2UPq4zpdoPMUcPTQpBy9XuGPAyl8tu4IR1KvAOp0MoPa1KBfuJ/MzSeECZIQZQIkRAmhkfwcdbDODVNAnw82ztBpAjTsrclZKVDD1Kp9yUxdd4TjZ9U+XJXsrXixbQ36NPfD1qr05gkUQhRNQpQJkBAlhMZS9sHyIZC8R31cKwK6TC31Uc9vVqBXWLHnNJ+vO0rC+SwA3BysealdTZ4J88HGUsKUEFq72+9vs1Ks6bamT5+On58fNjY2hIWFsW3btiLbL168mDp16mBjY0NwcDCrV682el5RFMaMGYOnpye2trZERERw9OhRozbdunXDx8cHGxsbPD096dOnD2fOnDE8n5CQgE6nu2XZsmVL8R24EKJkeQTD83/BQ2PV0c6PrYOvmsP2WeqkxxowN9PxWKPqrBvelkk9GuBdyZZzV3L4YOVB2kz8m/mbE8jJL9CkNiHEvdE8RC1cuJDhw4czduxYdu3aRcOGDYmMjCQtLa3Q9ps3b6Z3794MHDiQ3bt3ExUVRVRUFPv37ze0mThxItOmTWPGjBls3boVe3t7IiMjyc7ONrRp3749ixYtIi4ujiVLlnD8+HF69Ohxy/7WrVtHcnKyYQkNDS3+N0EIUXLMLaD1cHhxI3iHQe4VWPU6zO8K549rVpaFuRlPNvHmr9fbMeHxYKq52JJ2OYexKw7QbtJ6fthyktx8bYKeEOLuaH45LywsjKZNm/Lll18CoNfr8fb2ZujQoYwcOfKW9r169SIzM5OVK1ca1jVv3pyQkBBmzJiBoih4eXnx+uuv88YbbwCQnp6Ou7s78+bN46mnniq0jhUrVhAVFUVOTg6WlpYkJCTg7+/P7t27CQkJuatjycnJIScnx/A4IyMDb29vuZwnhKnQF8C2byH6PcjLAgtbdVLj5i+BmbaX0XLz9SzakcSXfx0jJUP9D181F1vejAyke4gXOo36cglREZWJy3m5ubns3LmTiIgIwzozMzMiIiKIiYkp9DUxMTFG7QEiIyMN7ePj40lJSTFq4+zsTFhY2G23eeHCBX788UdatGiBpaXxbcfdunWjatWqtGrVihUrVhR5POPHj8fZ2dmweHtr1+9CCFEIM3N1AuOXNoN/G8i/Cn++A7M7QtphTUuzujZlzPo32zGuaz2qOFpz+tJVXlsYS89vYjhwJl3T+oQQt9I0RJ07d46CggLc3d2N1ru7u5OSklLoa1JSUopsf/3n3WxzxIgR2NvbU7lyZRITE1m+fLnhOQcHB6ZMmcLixYtZtWoVrVq1IioqqsggNWrUKNLT0w1LUlLSHd4BIYQmKvlD3xXQ9XOwdoLTO+Cb1vDPJCjI07Q0G0tz+rf0Z8Nb7XkzMhBbS3O2J1yk6xcbeXfZPi5l5WpanxDiBs37RGnpzTffZPfu3fz555+Ym5vTt29frl/ddHNzY/jw4YbLjRMmTODZZ59l0qRJt92etbU1Tk5ORosQwkTpdBDaH17eAgGRUJALf38I37a/cTefhmwszRnSvhbRr7elSwNP9Ar8sCWRdpPV/lIFermxWgitaRqi3NzcMDc3JzU11Wh9amoqHh6FD4zn4eFRZPvrP+9mm25ubtSuXZuHH36YBQsWsHr16iLvvgsLC+PYsWN3d3BCiLLBuRo8vRAe/xZsXdVhEWa2h+j3IS/7zq8vYV4utnz5dGN+fqE5ge6OXMrK491l++n25UZ2JFzQujwhKjRNQ5SVlRWhoaFER0cb1un1eqKjowkPDy/0NeHh4UbtAdauXWto7+/vj4eHh1GbjIwMtm7detttXt8vYNQx/L9iY2Px9PS884EJIcoWnQ4a9IQh26BelDoH34Yp8E0bSNqudXUAhNeszKpXWzGuaz0cbSw4cCaDHjNi+N/CWNIytA97QlREms83MHz4cPr160eTJk1o1qwZU6dOJTMzkwEDBgDQt29fqlWrxvjx4wEYNmwYbdu2ZcqUKXTu3JkFCxawY8cOZs6cCYBOp+O1117jww8/JCAgAH9/f0aPHo2XlxdRUVEAbN26le3bt9OqVStcXV05fvw4o0ePpmbNmoagNX/+fKysrGjUqBEAS5cuZc6cOcyaNauU3yEhRKlxqAo958PBFeowCOfiYPbD0Pxl9S4+KztNy7MwN6N/S3+6NPRi0po4Fu1M4tfdp/nzQArDIgLo38IfK4sK3UtDiNKlmIAvvvhC8fHxUaysrJRmzZopW7ZsMTzXtm1bpV+/fkbtFy1apNSuXVuxsrJSgoKClFWrVhk9r9frldGjRyvu7u6KtbW18tBDDylxcXGG5/fu3au0b99eqVSpkmJtba34+fkpL774onLq1ClDm3nz5il169ZV7OzsFCcnJ6VZs2bK4sWL7+m40tPTFUBJT0+/p9cJIUxA5nlFWTpYUcY6qcvUBopy4h+tqzISm3hR6fblRsV3xErFd8RKpf3kv5V/4tK0LkuIMu9uv781HyeqPJNpX4QoB46uhd+GQcZp9XHoAHj4fbAxjb/Ter3CL7tOMXHNYc5dUe/c61jPndFd6uFdSdszZ0KUVTJ3ngmQECVEOZGdAevGwo456mOnaurwCAEPa1vXTTKy85i69ijzYxIo0CtYW5gxuG1NXmpbUyY3FuIeSYgyARKihChn4jfAilfgYoL6OPBRaP+2OkefiTiSeplxKw6w+fh5QB31/N3OdelU30NGPRfiLkmIMgESooQoh3Iz4a+PYOvXoFyb265elBqmqgRqWtp1iqLw+/4UPlx5kDPp6p17LWtVZlzXIALcHTWuTgjTJyHKBEiIEqIcO3cU1o+H/UsBBXRmENwT2o2ASjW0rg6Aq7kFfL3+GDP+PUFuvh4LMx39W/gxLCIARxvLO29AiApKQpQJkBAlRAWQegD+/hgOX5sUXWcOjZ6BNm+Bi2nMn5l4PosPVh1k7UF1EGI3B2tGPlKHxxtVw8xMLvEJ8V8SokyAhCghKpDTu9QwdWyt+tjcChr3g9avg5NpDNK7Pi6N9387yIlzmQA08nHh/W71Ca7urHFlQpgWCVEmQEKUEBVQ4lZ1Dr74f9XHFjbQ9Hlo9T+wd9O2NiA3X8/cTfFMiz5KZm4BOh30DPXmjchAqjhaa12eECZBQpQJkBAlRAUW/y/89SEkbVUfW9pD8xehxVB1jj6NpWZkM371IZbFngHAwdqCVzrUYkBLP6wtZEgEUbFJiDIBEqKEqOAUBY5Fw18fQHKsus7aGcKHQPOXTGLAzp0nL/DebwfZeyodAJ9Kdrz9aF0ig9xlSARRYUmIMgESooQQgBqm4larQyOkHVDX2bpCy9eg2QtgZa9peXq9wq+7T/PJmsOkXVYnYW9eoxJjugRRz0v+7RIVj4QoEyAhSghhRK+Hg7/C3+Ph/FF1nX1VaD1cnU7G0kbT8jJz8vl6/XFmblCHRNDp4Kmm3rzeMRA3B+kvJSoOCVEmQEKUEKJQBfmwb7E6ztSlk+o6Ry9o+yaEPAsWVpqWd+piFhN+P8zKvclqadYWDH2oFv1aSH8pUTFIiDIBEqKEEEUqyIPYH+GfiTcmOHbxhbYjoEEvMLfQtLztCRd4/7eD7Dut9pfyrWzHO4/W5eF60l9KlG8SokyAhCghxF3Jy4Zd8+HfyZCZpq6rXAvajYKgx8HMTLPS9HqFJbtOMfGPOM5e6y/VslZlRnepRx0P+XdNlE8SokyAhCghxD3JzYLts2DjZ3D1grrOPRgeHgc1HwINz/5cycnn6/XH+HZDPLn5esx00LuZD8Mfrk1l6S8lyhkJUSZAQpQQ4r7kXIYtM2DzF5CjXkrDvw1EvAfVGmtaWtIFtb/Uqn3X+kvZWDDsoQD6hvthZaHdGTMhipOEKBMgIUoI8UCyLsCGKbBtJhTkquuCHoMOo6FyTU1L23riPO+vPMiBMxkA+LvZ886jdXmoblXpLyXKPAlRJkBClBCiWFxKVOfl27MAUMDMQh0Soe0IcKiiWVkFeoUlO9X+UueuqP2lWge48W7negR6OGpWlxAPSkKUCZAQJYQoVin7Yd24G5McWzmo08iEDwFr7ULL5ew8pv99nDkb48ktUPtLPRPmy/8erk0le22HaxDifkiIMgESooQQJSL+X1g7Fs7sUh/bV1HPSoX2B3NLzcpKPJ/Fx6sPseZACgBONhYMi6hNn+a+0l9KlCkSokyAhCghRIlRFDi4DKLfhwsn1HWVaqj9pYIe0/ROvpjjan+pQ8lqf6kabva83jGQTvU9MDeT/lLC9EmIMgESooQQJa4gTx1jav0nN8aY8moED7+v3tGnVVl6hUU7kpj8RxznM9VO8b6V7XihdQ16hFbHxlJGPhemS0KUCZAQJYQoNTlXIGY6bJ4GuVfUdbUiIGIceARrVlZGdh6zNsTzXUwCl7LyAKhsb0X/Fn70CffFxU76TAnTIyHKBEiIEkKUuitp8O8k2DEH9PmATp1Cpv3b4OqrWVlZufks2p7EtxviOX3pKgB2VuY81dSHga39qeZiq1ltQvyXhCgTICFKCKGZ88fhrw/hwFL1sbkVNH0B2rwBdpU0Kyu/QM+qfcnM+OeEoc+UuZmObg29GNSmBnU95d9KoT0JUSZAQpQQQnOnd8G6seodfQDWTtDqNQh7CazsNCtLURQ2HD3HjH+Os/n4ecP6doFVGNymJs1rVJJBO4VmJESZAAlRQgiToChwPBrWjoPUfeo6R091guOQZ8DcQtPy9p66xDf/nuD3fcnor30jNazuzOC2NYkMkjv6ROmTEGUCJEQJIUyKXg/7f4G/PlBHQQdwqw1dp4FvuLa1ASfPZzJrQzyLdiSRk68HwK+yHS+0qcETjeWOPlF6JESZAAlRQgiTlJ8D22erHdCvXgBza3jiW6jXXevKADh3JYfvNicwP+Yk6VfVO/rcHK7d0dfcD2c77QYUFRWDhCgTICFKCGHSstNh2ctweCWgg86ToenzWldlkJmTz6IdScz6zx19vZv58FwruaNPlJy7/f42iXH4p0+fjp+fHzY2NoSFhbFt27Yi2y9evJg6depgY2NDcHAwq1evNnpeURTGjBmDp6cntra2REREcPToUaM23bp1w8fHBxsbGzw9PenTpw9nzpwxarN3715at26NjY0N3t7eTJw4sXgOWAghTIGNM/T8Tp3MGAVWva7e0Wci/7e2t7ZgQEt/1r/Zjqm9Qqjj4UhWbgGzN8bTduLfDF8Yy+GUDK3LFBWY5iFq4cKFDB8+nLFjx7Jr1y4aNmxIZGQkaWlphbbfvHkzvXv3ZuDAgezevZuoqCiioqLYv3+/oc3EiROZNm0aM2bMYOvWrdjb2xMZGUl2drahTfv27Vm0aBFxcXEsWbKE48eP06NHD8PzGRkZdOzYEV9fX3bu3MmkSZMYN24cM2fOLLk3QwghSpuZOXT5TO1kDuolvhVDoSBf27puYmluRlSjavw+rDXzn2tGeI3K5OsVlu4+TaepGxgwdxtbTpxHLqyI0qb55bywsDCaNm3Kl19+CYBer8fb25uhQ4cycuTIW9r36tWLzMxMVq5caVjXvHlzQkJCmDFjBoqi4OXlxeuvv84bb7wBQHp6Ou7u7sybN4+nnnqq0DpWrFhBVFQUOTk5WFpa8vXXX/POO++QkpKClZU6ou7IkSNZtmwZhw8fvqtjk8t5QogyZcdcWDUcFD3UfgR6zNF0GISi7Em6xMx/T/D7/ht39NWv5kTfcD+6NfSSTujigZSJy3m5ubns3LmTiIgIwzozMzMiIiKIiYkp9DUxMTFG7QEiIyMN7ePj40lJSTFq4+zsTFhY2G23eeHCBX788UdatGiBpaWlYT9t2rQxBKjr+4mLi+PixYuFbicnJ4eMjAyjRQghyowmA6Dn92BhA0d+h++6Q9YFrasqVENvF6Y/05i/Xm/Hs819sLYwY//pDN76ZS/Nx0czfvUhki5kaV2mKOc0DVHnzp2joKAAd3d3o/Xu7u6kpKQU+pqUlJQi21//eTfbHDFiBPb29lSuXJnExESWL19+x/3cvI//Gj9+PM7OzobF29u70HZCCGGy6naBPsvU/lKntsGcTnApSeuqbsvPzZ4Po4KJGfUQIx+pQzUXWy5l5fHNvydoM+lvBs7bzvq4NPR6udQnip/mfaK09Oabb7J7927+/PNPzM3N6du37wNdUx81ahTp6emGJSnJdP/hEUKI2/INh+f+AKdqcC4OZneE1INaV1WkSvZWvNi2Jv++1Z5ZfZvQpnYVFAWiD6fRf+52OkxZz6wNJ0i/NgmyEMVB02Fq3dzcMDc3JzU11Wh9amoqHh4ehb7Gw8OjyPbXf6ampuLp6WnUJiQk5Jb9u7m5Ubt2berWrYu3tzdbtmwhPDz8tvu5eR//ZW1tjbW19R2OWgghyoCqdWHgn/D942qQmtsJei8A3xZaV1YkczMdEfXciajnzomzV/hhSyKLdyaRcD6LD1cdYsqfR4hq5EWf5n7U85K+quLBaHomysrKitDQUKKjow3r9Ho90dHRhIcXPnpueHi4UXuAtWvXGtr7+/vj4eFh1CYjI4OtW7fedpvX9wtqv6br+/n333/Jy7vxv5a1a9cSGBiIq6vrPR6pEEKUQc7V4bk14B2mjin1XRQc+k3rqu5ajSoOjOlaj61vP8THjwVTx8ORq3kF/LwtiUenbeDJGZtZsecMuddGRxfinikaW7BggWJtba3MmzdPOXjwoDJo0CDFxcVFSUlJURRFUfr06aOMHDnS0H7Tpk2KhYWFMnnyZOXQoUPK2LFjFUtLS2Xfvn2GNhMmTFBcXFyU5cuXK3v37lW6d++u+Pv7K1evXlUURVG2bNmifPHFF8ru3buVhIQEJTo6WmnRooVSs2ZNJTs7W1EURbl06ZLi7u6u9OnTR9m/f7+yYMECxc7OTvnmm2/u+tjS09MVQElPTy+Ot0oIIbSRm6UoPz2lKGOdFGWci6Jsm6V1RfdFr9crW0+cV17+cadSc9QqxXfESsV3xEqlyYdrlU//jFNS0q9qXaIwEXf7/a15iFIURfniiy8UHx8fxcrKSmnWrJmyZcsWw3Nt27ZV+vXrZ9R+0aJFSu3atRUrKyslKChIWbVqldHzer1eGT16tOLu7q5YW1srDz30kBIXF2d4fu/evUr79u2VSpUqKdbW1oqfn5/y4osvKqdOnTLazp49e5RWrVop1tbWSrVq1ZQJEybc03FJiBJClBv5eYqy/BU1SI11UpS/PlIUvV7rqu5bSvpV5dM/45QmH641hKmao1YpL/+4U9ly/JyiL8PHJh7c3X5/az5OVHkm40QJIcoVRYH14+GfT9THof3h0Slgrmn32geSm6/njwMpfB9zkm0JN4ZzqOPhSJ9wX6JCqmFvXXaPT9wfmTvPBEiIEkKUS9tnq1PEoEBgZ+gxGyzL/jx2h5Iz+C7mJMt2n+ZqXgEAjtYW9GhSnT7NfalRxUHjCkVpkRBlAiRECSHKrYMrYMnzUJAD3s2h989gV0nrqopF+tU8ftl5ih+2nCT+XKZhfesAN/q38KN9YFXMzHQaVihKmoQoEyAhSghRriVsgp97Q046VKkDzy5R7+grJ/R6hQ3HzvF9TALRh9MM8zLXqGLPwFb+PN6oOrZWMr1MeSQhygRIiBJClHupB+CHJ+Bysjo457NL1DGmypmkC1l8v+UkP29L5HK2Ojmzq50lzzb3pU+4L1UdbTSuUBQnCVEmQEKUEKJCuJSoBqlzR9TpYp5eBD7Nta6qRFzJyWfR9iTmbIrn1MWrAFiZm9E9xIuBrf2p4yH/1pcHEqJMgIQoIUSFkXUBfuoJp7arExj3mAN1OmtdVYkp0Cv8eSCFWRvj2XnyxqT0rQPceL51DdoEuKHTSb+pskpClAmQECWEqFBys+CXAXBkDejMoMtn6jAI5dyuxIvM3hDP7/uTuT7PcW13Bwa28qd7SDVsLKXfVFkjIcoESIgSQlQ4Bfmwchjs/kF93O5taPsWVICzMkkXspi3OYGF25O4kqP2m3JzsKJPcz+ebe5DZQeZW7WskBBlAiRECSEqJEWBvz+Cfyepj5s8B49OBrOKcUYmIzuPhduSmLspnjPp2QBYWZjxRONqDGzlT62qjhpXKO5EQpQJkBAlhKjQtn0Lq98EFAjoCI/PBNuKM4F7XoGeNftTmLXhBHtOpRvWtw+swvOta9CiZmXpN2WiJESZAAlRQogK78AyWDpIHZTT1Q96/QAewVpXVaoURWHHyYvM2nCCPw+mGsabquPhyPOta9C1oSfWFhXjLF1ZISHKBEiIEkII4EwsLOqjDoVgYQtdp0LDp7SuShMJ5zKZuymeRTtOGaaWqepoTb8WfjzdzAdXeyuNKxQgIcokSIgSQohrsi6o08Qcj1YfN30eIseDRcUMDelZefy0LZF5m+NJzcgBwMbSjB6h1enT3I9AD+k3pSUJUSZAQpQQQtxEXwDrJ8C/E9XH1ZtCz+/AyUvbujSUm69n1b4zfPtvPAeTMwzrA6o60LmBJ10aeFGrqkx8XNokRJkACVFCCFGIuDVqP6mcdLCvAj3mgn9rravSlKIobDlxgbmb4lkfd5bcAr3huToejnRp4EnnBl74u9lrWGXFISHKBEiIEkKI27hwAhb2gdT9oDOHh9+D8FcqxHhSd5J+NY91B1NZufcMG46eI19/42s6yMtJPUMV7IVPZTsNqyzfJESZAAlRQghRhNwsWPka7F2oPq4XBd2/BGvpD3Tdpaxc/jyQysp9yWw6do6CmwJVg+rOdA72pHMDT6q7SqAqThKiTICEKCGEuANFge2zYM1I0OeDW6A6DEKV2lpXZnIuZObyx4EUVu49Q8zx89yUpwjxdrl2yc8TT2db7YosJyREmQAJUUIIcZcSt8LifnA5GawcIOorqNdd66pM1rkrOfy+P4VVe8+wNf4CN3+TN/F1pUsDTx4J9sTdyUa7IsswCVEmQEKUEELcgytpsHgAnNyoPm7xKjw0FswttK3LxKVlZPP7fvUM1faEi4b1Oh009atE1waedKrvSRVHmbvvbkmIMgESooQQ4h4V5MO6sRDzpfrYr7V6955DFW3rKiOS06+yep96hmpX4iXDejMdNK9Rmc4NPOkU5CGTId+BhCgTICFKCCHu04FfYdkQyMsEp2rqeFLVm2hdVZly6mIWv+9Tz1DdPHefuZmOZn6VaBdYhXaBVant7iBz+P2HhCgTICFKCCEeQNphWPgsnD8KZpbwyCfQ5DkZBuE+JF3IYuXeZFbtO8P+0xlGz3k529A2sCrtAqvQspYbDtZy+VRClAmQECWEEA8oOwOWD4FDK9THDZ+GLp+CpdyBdr9Ons/kr8NprI87y5YT58nJvzGwp6W5jqY3naUKqFoxz1JJiDIBEqKEEKIYKApsngbrxoGiB49g6Pk9VPLXurIy72puAVtOnGd9XBrrj5zl5Pkso+erudjSNrAK7WqrZ6nsK8hZKglRJkBClBBCFKMT/8Avz0HWObBxgSdmQcDDWldVrsSfy+Tvw2qg2nLiPLk3naWyMjejqb8r7Wqrl/5qleOzVBKiTICEKCGEKGbpp2BRPzi9A9BBu5HQ5i0wM9O6snLn5rNUf8edJfHCrWeprl/2a1Gzcrk6SyUhygRIiBJCiBKQnwNrRsGO2erjgI7w+EywddW2rnJMURTiz2WyPu7sbc9SNfO/3peqCjWrlO2zVBKiTICEKCGEKEGxP8HK/0F+Nrj4qpf3vJtpXVWFcDW3gJgT59RQVchZququ185S1a5Ki1qVsbMqW2epJESZAAlRQghRwpL3wMI+cOmk+rhWBLQdCd5Nta2rAlEUhRPXz1LFpbE1/sItZ6nCalSibW310l/NKvYmf5ZKQpQJkBAlhBClIOsC/Pku7FkASoG6rmYHNUz5hGlbWwWUlZtPzPHz1y79pZF04arR896VbA2d08NrmuZZqrv9/jaJnnjTp0/Hz88PGxsbwsLC2LZtW5HtFy9eTJ06dbCxsSE4OJjVq1cbPa8oCmPGjMHT0xNbW1siIiI4evSo4fmEhAQGDhyIv78/tra21KxZk7Fjx5Kbm2vURqfT3bJs2bKleA9eCCHEg7GrpE5YPHQHhDwLOnM4/hfM6Qjzu8HJzVpXWKHYWVnwUF13Poiqz79vtif69ba827kurQPcsDI3I+nCVb7fcpKB83cQ8v5a+szeyuyN8Zw4e4Wydl5H8zNRCxcupG/fvsyYMYOwsDCmTp3K4sWLiYuLo2rVqre037x5M23atGH8+PF06dKFn376iU8++YRdu3ZRv359AD755BPGjx/P/Pnz8ff3Z/To0ezbt4+DBw9iY2PDmjVrWLhwIb1796ZWrVrs37+fF154gT59+jB58mRADVH+/v6sW7eOoKAgw/4rV66MpaXlXR2bnIkSQggNXIiHjZ+qfab0+eo6v9bqnXx+rbStrYLLzLl2lupIGn8fPsvpS8ZnqXwq2dEusArtA6vSvEZlbK3MNamzzFzOCwsLo2nTpnz5pTrZpF6vx9vbm6FDhzJy5Mhb2vfq1YvMzExWrlxpWNe8eXNCQkKYMWMGiqLg5eXF66+/zhtvvAFAeno67u7uzJs3j6eeeqrQOiZNmsTXX3/NiRMngBshavfu3YSEhNzVseTk5JCTk2N4nJGRgbe3t4QoIYTQwsWTapja/SPo89R1vq2g3Qg1VJl4v5zyTlEUjp+9wvq4s/wdl8a2+AvkFdyIJNYWZoTVqEz7a8Mo+LvZl1ptZeJyXm5uLjt37iQiIsKwzszMjIiICGJiYgp9TUxMjFF7gMjISEP7+Ph4UlJSjNo4OzsTFhZ2222CGrQqVap0y/pu3bpRtWpVWrVqxYoVK4o8nvHjx+Ps7GxYvL29i2wvhBCiBLn6QtfP4dVd6px7ZpZwciPM7wpzH4UT69XR0IUmdDodtao68nzrGvz4fHNix3Tk275NeDrMh2outuTk6/n3yFne++0g7Sevp+2kvxm34gB/x6WRnVegdfkAaNqb69y5cxQUFODu7m603t3dncOHDxf6mpSUlELbp6SkGJ6/vu52bf7r2LFjfPHFF4ZLeQAODg5MmTKFli1bYmZmxpIlS4iKimLZsmV069at0O2MGjWK4cOHGx5fPxMlhBBCQy4+0OUzaP06bPwMdn0HiZvhu+7g3Vw9M1WjvZyZ0pi9tQUP13Pn4XruKIrC0bQr6nQ0cWfZnnCBk+ezmLc5gXmbE7C2MCO8ZmXa1a7CY42r42x7d91sipvpdYkvZadPn6ZTp048+eSTvPDCC4b1bm5uRoGoadOmnDlzhkmTJt02RFlbW2NtbV3iNQshhLgPztWh8xRoNRw2TYWd8yFpC3z/GFRvpoapmg9JmDIBOp2O2u6O1HZ3ZFCbmlzJyWfTsXOGYRSS07NZH3eWf46cpVtINc3q1DREubm5YW5uTmpqqtH61NRUPDw8Cn2Nh4dHke2v/0xNTcXT09OozX/7Np05c4b27dvTokULZs6cecd6w8LCWLt27R3bCSGEMGHO1eDRSdfC1Oewcy6c2gY/PAHVmqgd0GtFSJgyIQ7WFkQGeRAZ5IGiKBxJVc9Snbp4lUr2VprVpWmfKCsrK0JDQ4mOjjas0+v1REdHEx4eXuhrwsPDjdoDrF271tDe398fDw8PozYZGRls3brVaJunT5+mXbt2hIaGMnfuXMzuYt6l2NhYo2AmhBCiDHPyhEcmwLA90HwIWNiqc/L92AO+7QBxa6TPlAnS6XQEejgyuG1NPoiqr2ktml/OGz58OP369aNJkyY0a9aMqVOnkpmZyYABAwDo27cv1apVY/z48QAMGzaMtm3bMmXKFDp37syCBQvYsWOH4UySTqfjtdde48MPPyQgIMAwxIGXlxdRUVHAjQDl6+vL5MmTOXv2rKGe62ey5s+fj5WVFY0aNQJg6dKlzJkzh1mzZpXWWyOEEKI0OHpAp4+h5TDYPA22z4Yzu+DnXuAZAm1HQOAjcmZK3ELzENWrVy/Onj3LmDFjSElJISQkhDVr1hg6hicmJhqdJWrRogU//fQT7777Lm+//TYBAQEsW7bMMEYUwFtvvUVmZiaDBg3i0qVLtGrVijVr1mBjYwOoZ66OHTvGsWPHqF69ulE9N4/48MEHH3Dy5EksLCyoU6cOCxcupEePHiX5dgghhNCKoztEfgQtX7sWpmZBciws6A0eDdQwVaMdmJmrA3qamYPOTMJVBab5OFHlmQy2KYQQZVjmOdj8BWz7FvIyi2iouylQ3RyuzG4ELqPfdYWvN7v2+loR0OZNsNCur09FV2YG2yzPJEQJIUQ5kHketkxXw1RORuns0zMEesyByjVLZ3/CiIQoEyAhSgghyhF9AeTnqJMcK3r18c0/lYJrvxeoHdKv/270vP4/r7/5eT1knIF1Y+HqRbC0V4dkCOmt9ZFXOHf7/a15nyghhBCiTDAzByu7kt9PrQhYOkgdXX3Zi+pkyp2ngI38Z9zUaDrEgRBCCCH+w7ka9FsB7d9V+0jtWwTftIZTO7WuTPyHhCghhBDC1JiZQ9s3YcBqcPaGiwkwpyNsnKpeEhQmQUKUEEIIYap8msOLG6FeFOjz1f5SPzwGlwufC1aULglRQgghhCmzdYEn50HXaeqo6ifWw9ct4cifGhcmJEQJIYQQpk6ng9B+MPgfcK8PWefgpydhzdvqHYNCExKihBBCiLKiSiA8Hw1hL6qPt0yHWRFw7qi2dVVQEqKEEEKIssTSBh75BHovANtKkLIXvmkDu3+oOBMm5+fC/qXw72RNy5AQJYQQQpRFgY/AS5vBrzXkZcHyIbBkIGSna11ZyUk/BX99CFPrwy8DYP0EuJyqWTky2KYQQghRVjl5Qt/lsGkq/PUR7F8Cp7bDE3PAu6nW1RUPvR5O/A3bZ8OR39WR3QEc3KFxXzDTLsrItC8lSKZ9EUIIUWqStsOS5+BSojpIZ4d3oOVr6phTZVHWBYj9EXbMgQsnbqz3aw1NB0KdLmBuWSK7lrnzTICEKCGEEKUqOx1W/k89IwXg3wYem6mesSoLFAVO71TPOh1YCvnZ6nprJ2jYG5o8B1XrlHgZEqJMgIQoIYQQpU5RIPYnWP2G2lfKthJEfQ2BnbSu7PZyM2HfL7BjNiTvubHeIxiaPg/1e4C1Q6mVIxMQCyGEEBWRTgeNngHvZvDLc+rdez/3UodFiHhPvbvPVJw9ogan2J8h51qHeHNrCHpMDU/Vm6jHY6LkTFQJkjNRQgghNJWfA+veU8eTAnAPhh6z1fGmtFKQB4dXwfZZkLDhxnpXP/VyXcizYF9Zs/JALueZBAlRQgghTMKRP2HZS+pI5xa2ENofXLzB0QMcPK79dC/ZS2bpp2HXfNg5H65cm/tPZwa1O0GTgVCzA5iZxshLEqJMgIQoIYQQJuNyCvw6WJ1773asHMHR/VqwcgdHTzVcXQ9Zjp7qemunu7vMptdD/Hq1o3jc76AUqOvtq0DjfjfCnImRPlFCCCGEuMHRA579FfYtUjtvX05Rlysp6oCVeZmQexnOX4bzx4reloVt0SHLvgrE/6uGpwvHb7zOt+W14Qm6goVVyR5vKZAzUSVIzkQJIYQoM3Iu3xSsUm8KWDevS73RAfxuWTlCw6fU8FS1bsnUXszkTJQQQggh7p61o7q4BRTdLjfrxtmrW0LWTT9dvNXLdcE9S3V4gtIkIUoIIYQQd8/KDirVUJcKzjS6wQshhBBClDESooQQQggh7oOEKCGEEEKI+yAhSgghhBDiPkiIEkIIIYS4DxKihBBCCCHug4QoIYQQQoj7YBIhavr06fj5+WFjY0NYWBjbtm0rsv3ixYupU6cONjY2BAcHs3r1aqPnFUVhzJgxeHp6YmtrS0REBEePHjU8n5CQwMCBA/H398fW1paaNWsyduxYcnNzjbazd+9eWrdujY2NDd7e3kycOLH4DloIIYQQZZrmIWrhwoUMHz6csWPHsmvXLho2bEhkZCRpaWmFtt+8eTO9e/dm4MCB7N69m6ioKKKioti/f7+hzcSJE5k2bRozZsxg69at2NvbExkZSXZ2NgCHDx9Gr9fzzTffcODAAT777DNmzJjB22+/bdhGRkYGHTt2xNfXl507dzJp0iTGjRvHzJkzS/YNEUIIIUTZoGisWbNmypAhQwyPCwoKFC8vL2X8+PGFtu/Zs6fSuXNno3VhYWHK4MGDFUVRFL1er3h4eCiTJk0yPH/p0iXF2tpa+fnnn29bx8SJExV/f3/D46+++kpxdXVVcnJyDOtGjBihBAYG3vWxpaenK4CSnp5+168RQgghhLbu9vtb0zNRubm57Ny5k4iICMM6MzMzIiIiiImJKfQ1MTExRu0BIiMjDe3j4+NJSUkxauPs7ExYWNhttwmQnp5OpUqVjPbTpk0brKxuzDIdGRlJXFwcFy9eLHQbOTk5ZGRkGC1CCCGEKJ80DVHnzp2joKAAd3d3o/Xu7u6kpKQU+pqUlJQi21//eS/bPHbsGF988QWDBw++435u3sd/jR8/HmdnZ8Pi7e1daDshhBBClH2a94nS2unTp+nUqRNPPvkkL7zwwgNta9SoUaSnpxuWpKSkYqpSCCGEEKZG0xDl5uaGubk5qampRutTU1Px8PAo9DUeHh5Ftr/+8262eebMGdq3b0+LFi1u6TB+u/3cvI//sra2xsnJyWgRQgghRPlkoeXOraysCA0NJTo6mqioKAD0ej3R0dG88sorhb4mPDyc6OhoXnvtNcO6tWvXEh4eDoC/vz8eHh5ER0cTEhICqHfabd26lZdeesnwmtOnT9O+fXtCQ0OZO3cuZmbGeTI8PJx33nmHvLw8LC0tDfsJDAzE1dX1ro5PURTD/oUQQghRNlz/3r7+PX5bpdLNvQgLFixQrK2tlXnz5ikHDx5UBg0apLi4uCgpKSmKoihKnz59lJEjRxrab9q0SbGwsFAmT56sHDp0SBk7dqxiaWmp7Nu3z9BmwoQJiouLi7J8+XJl7969Svfu3RV/f3/l6tWriqIoyqlTp5RatWopDz30kHLq1CklOTnZsFx36dIlxd3dXenTp4+yf/9+ZcGCBYqdnZ3yzTff3PWxJSUlKYAsssgiiyyyyFIGl6SkpCK/5zU9EwXQq1cvzp49y5gxY0hJSSEkJIQ1a9YYOnEnJiYanSVq0aIFP/30E++++y5vv/02AQEBLFu2jPr16xvavPXWW2RmZjJo0CAuXbpEq1atWLNmDTY2NoB6RunYsWMcO3aM6tWrG9WjXEudzs7O/PnnnwwZMoTQ0FDc3NwYM2YMgwYNuutj8/LyIikpCUdHR3Q63X2/R/+VkZGBt7c3SUlJFe6SYUU99op63CDHXhGPvaIeN1TcYze141YUhcuXL+Pl5VVkO52i3OlclTA1GRkZODs7k56ebhJ/2EpTRT32inrcIMdeEY+9oh43VNxjL6vHXeHvzhNCCCGEuB8SooQQQggh7oOEqDLI2tqasWPHYm1trXUppa6iHntFPW6QY6+Ix15Rjxsq7rGX1eOWPlFCCCGEEPdBzkQJIYQQQtwHCVFCCCGEEPdBQpQQQgghxH2QECWEEEIIcR8kRJmo6dOn4+fnh42NDWFhYWzbtq3I9osXL6ZOnTrY2NgQHBzM6tWrS6nS4jN+/HiaNm2Ko6MjVatWJSoqiri4uCJfM2/ePHQ6ndFyfWT6smLcuHG3HEOdOnWKfE15+LwB/Pz8bjl2nU7HkCFDCm1flj/vf//9l65du+Ll5YVOp2PZsmVGzyuKwpgxY/D09MTW1paIiAiOHj16x+3e678Vpa2o487Ly2PEiBEEBwdjb2+Pl5cXffv25cyZM0Vu837+zmjhTp95//79bzmOTp063XG7pv6Zw52PvbC/9zqdjkmTJt12m6b4uUuIMkELFy5k+PDhjB07ll27dtGwYUMiIyNJS0srtP3mzZvp3bs3AwcOZPfu3URFRREVFcX+/ftLufIH888//zBkyBC2bNnC2rVrycvLo2PHjmRmZhb5OicnJ5KTkw3LyZMnS6ni4hMUFGR0DBs3brxt2/LyeQNs377d6LjXrl0LwJNPPnnb15TVzzszM5OGDRsyffr0Qp+fOHEi06ZNY8aMGWzduhV7e3siIyPJzs6+7Tbv9d8KLRR13FlZWezatYvRo0eza9culi5dSlxcHN26dbvjdu/l74xW7vSZA3Tq1MnoOH7++ecit1kWPnO487HffMzJycnMmTMHnU7HE088UeR2Te5zv+vZdEWpadasmTJkyBDD44KCAsXLy0sZP358oe179uypdO7c2WhdWFiYMnjw4BKts6SlpaUpgPLPP//cts3cuXMVZ2fn0iuqBIwdO1Zp2LDhXbcvr5+3oijKsGHDlJo1ayp6vb7Q58vD560oigIov/76q+GxXq9XPDw8lEmTJhnWXbp0SbG2tlZ+/vnn227nXv+t0Np/j7sw27ZtUwDl5MmTt21zr39nTEFhx96vXz+le/fu97SdsvaZK8rdfe7du3dXOnToUGQbU/zc5UyUicnNzWXnzp1EREQY1pmZmREREUFMTEyhr4mJiTFqDxAZGXnb9mVFeno6AJUqVSqy3ZUrV/D19cXb25vu3btz4MCB0iivWB09ehQvLy9q1KjBM888Q2Ji4m3bltfPOzc3lx9++IHnnnuuyAm7y8Pn/V/x8fGkpKQYfa7Ozs6EhYXd9nO9n38ryoL09HR0Oh0uLi5FtruXvzOmbP369VStWpXAwEBeeuklzp8/f9u25fUzT01NZdWqVQwcOPCObU3tc5cQZWLOnTtHQUEB7u7uRuvd3d1JSUkp9DUpKSn31L4s0Ov1vPbaa7Rs2ZL69evftl1gYCBz5sxh+fLl/PDDD+j1elq0aMGpU6dKsdoHExYWxrx581izZg1ff/018fHxtG7dmsuXLxfavjx+3gDLli3j0qVL9O/f/7ZtysPnXZjrn929fK7382+FqcvOzmbEiBH07t27yElo7/XvjKnq1KkT3333HdHR0XzyySf8888/PPLIIxQUFBTavjx+5gDz58/H0dGRxx9/vMh2pvi5W2i2ZyGKMGTIEPbv33/H693h4eGEh4cbHrdo0YK6devyzTff8MEHH5R0mcXikUceMfzeoEEDwsLC8PX1ZdGiRXf1P7PyYvbs2TzyyCN4eXndtk15+LxF4fLy8ujZsyeKovD1118X2ba8/J156qmnDL8HBwfToEEDatasyfr163nooYc0rKx0zZkzh2eeeeaON4mY4ucuZ6JMjJubG+bm5qSmphqtT01NxcPDo9DXeHh43FN7U/fKK6+wcuVK/v77b6pXr35Pr7W0tKRRo0YcO3ashKoreS4uLtSuXfu2x1DePm+AkydPsm7dOp5//vl7el15+LwBw2d3L5/r/fxbYaquB6iTJ0+ydu3aIs9CFeZOf2fKiho1auDm5nbb4yhPn/l1GzZsIC4u7p7/7oNpfO4SokyMlZUVoaGhREdHG9bp9Xqio6ON/gd+s/DwcKP2AGvXrr1te1OlKAqvvPIKv/76K3/99Rf+/v73vI2CggL27duHp6dnCVRYOq5cucLx48dvewzl5fO+2dy5c6latSqdO3e+p9eVh88bwN/fHw8PD6PPNSMjg61bt/6/ffsLaer94wD+Pua2tlG5XK1VaEUmJiT0FymINEq96A9GCkPWTUMrKUgoKJleBF2EXXgxCsxuIsmgEqQGC70ZSVFTRy2p2E3UsD8Um6ZB+3wvvr8OLUt/nW9u/nm/4MDOeZ7z7PPZs3P4cPbst/Oq5V4xFX0voF68eAGfz4fMzMw/HmOia2a6eP36NT58+PDbPGbKnP+opaUFGzZsQEFBwR+fOyXmPdUr22mstrY2MRgMcvXqVXn27Jm4XC7JyMiQSCQiIiJVVVVy+vRptb/f75f09HS5cOGChEIhcbvdotPpJBgMpioFTWpqamTBggXS3d0tb9++Vbfh4WG1z8+5NzY2itfrlVevXsnjx4+lsrJS5s6dK0+fPk1FCpqcPHlSuru7JRwOi9/vl507d4rVapXBwUERmbnz/d23b98kKytLTp06NaZtJs13NBqVQCAggUBAAEhTU5MEAgH1X2jnz5+XjIwMuXPnjvT398vevXtl5cqV8uXLF3WMoqIiaW5uVvcnuldMBePl/fXrV9mzZ48sX75cent7E6770dFRdYyf857ompkqxss9Go1KXV2dPHjwQMLhsPh8Plm/fr3k5OTIyMiIOsZ0nHORib/vIiKfP38Wk8kkHo/nl2NMh3lnETVFNTc3S1ZWluj1etm8ebP09PSobdu3bxen05nQ/8aNG7JmzRrR6/WSn58vnZ2dSY74vwPwy621tVXt83PuJ06cUD8nm80mZWVl8uTJk+QH/x9UVFSI3W4XvV4vy5Ytk4qKCnn58qXaPlPn+zuv1ysAZGBgYEzbTJrvrq6uX36/v+cXj8elvr5ebDabGAwGKS4uHvOZZGdni9vtTjg23r1iKhgv73A4/NvrvqurSx3j57wnumamivFyHx4ell27dsmiRYtEp9NJdna2HD58eEwxNB3nXGTi77uIyKVLl8RoNMqnT59+OcZ0mHdFRGRSH3URERERzUBcE0VERESkAYsoIiIiIg1YRBERERFpwCKKiIiISAMWUUREREQasIgiIiIi0oBFFBEREZEGLKKIiIiINGARRUSURIqi4Pbt26kOg4j+AhZRRDRrHDp0CIqijNlKSkpSHRoRTUPpqQ6AiCiZSkpK0NramnDMYDCkKBoims74JIqIZhWDwYAlS5YkbBaLBcC/P7V5PB6UlpbCaDRi1apVuHnzZsL5wWAQRUVFMBqNyMzMhMvlQiwWS+hz5coV5Ofnw2AwwG6349ixYwnt79+/x/79+2EymZCTk4OOjo7JTZqIJgWLKCKiH9TX16O8vBx9fX1wOByorKxEKBQCAAwNDWH37t2wWCx49OgR2tvb4fP5Eookj8eDo0ePwuVyIRgMoqOjA6tXr054j8bGRhw8eBD9/f0oKyuDw+HAx48fk5onEf0FQkQ0SzidTpkzZ46YzeaE7dy5cyIiAkCqq6sTztmyZYvU1NSIiMjly5fFYrFILBZT2zs7OyUtLU0ikYiIiCxdulTOnDnz2xgAyNmzZ9X9WCwmAOTu3bt/LU8iSg6uiSKiWWXHjh3weDwJxxYuXKi+LiwsTGgrLCxEb28vACAUCqGgoABms1lt37p1K+LxOAYGBqAoCt68eYPi4uJxY1i3bp362mw2Y/78+RgcHNSaEhGlCIsoIppVzGbzmJ/X/haj0fh/9dPpdAn7iqIgHo9PRkhENIm4JoqI6Ac9PT1j9vPy8gAAeXl56Ovrw9DQkNru9/uRlpaG3NxczJs3DytWrMD9+/eTGjMRpQafRBHRrDI6OopIJJJwLD09HVarFQDQ3t6OjRs3Ytu2bbh27RoePnyIlpYWAIDD4YDb7YbT6URDQwPevXuH2tpaVFVVwWazAQAaGhpQXV2NxYsXo7S0FNFoFH6/H7W1tclNlIgmHYsoIppV7t27B7vdnnAsNzcXz58/B/DvP+fa2tpw5MgR2O12XL9+HWvXrgUAmEwmeL1eHD9+HJs2bYLJZEJ5eTmamprUsZxOJ0ZGRnDx4kXU1dXBarXiwIEDyUuQiJJGERFJdRBERFOBoii4desW9u3bl+pQiGga4JooIiIiIg1YRBERERFpwDVRRET/w9UNRPQn+CSKiIiISAMWUUREREQasIgiIiIi0oBFFBEREZEGLKKIiIiINGARRURERKQBiygiIiIiDVhEEREREWnwD1z+X35PVHS+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(transformer_train_losses, label='Transformer Train Loss')  \n",
    "plt.plot(transformer_val_losses, label='Transformer Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device)\n",
    "        non_lidar = non_lidar.to(device)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        \n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "        print(actions_pred)\n",
    "        print(actions)\n",
    "        print(loss)\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/681 [00:00<00:07, 90.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6088]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9170]], dtype=torch.float64)\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6317]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9170]], dtype=torch.float64)\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6663]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1702]], dtype=torch.float64)\n",
      "tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6880]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1702]], dtype=torch.float64)\n",
      "tensor(0.2682, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.7018]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1264]], dtype=torch.float64)\n",
      "tensor(0.3310, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6727]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1264]], dtype=torch.float64)\n",
      "tensor(0.2984, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6258]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1264]], dtype=torch.float64)\n",
      "tensor(0.2493, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5656]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0546]], dtype=torch.float64)\n",
      "tensor(0.2611, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5003]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0546]], dtype=torch.float64)\n",
      "tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4630]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8154]], dtype=torch.float64)\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4255]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8999]], dtype=torch.float64)\n",
      "tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3954]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.3655, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3987]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0571]], dtype=torch.float64)\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4445]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0567]], dtype=torch.float64)\n",
      "tensor(0.1504, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4616]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0574]], dtype=torch.float64)\n",
      "tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4322]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0574]], dtype=torch.float64)\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3810]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0574]], dtype=torch.float64)\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3565]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0519]], dtype=torch.float64)\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3376]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0519]], dtype=torch.float64)\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 29/681 [00:00<00:07, 84.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3312]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.4473, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3130]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.4720, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3393]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.4365, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3969]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.3637, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4683]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.2827, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5009]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5566]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5726]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6022]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1582, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6171]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9973]], dtype=torch.float64)\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6433]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6433]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6557]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 47/681 [00:00<00:07, 79.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6615]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6652]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9781]], dtype=torch.float64)\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6696]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8483]], dtype=torch.float64)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6643]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8532]], dtype=torch.float64)\n",
      "tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6617]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "tensor(0.4378, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6509]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "tensor(0.4236, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0115]], dtype=torch.float64)\n",
      "tensor(0.3211, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4966]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0040]], dtype=torch.float64)\n",
      "tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4660]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "tensor(0.2172, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4436]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9554]], dtype=torch.float64)\n",
      "tensor(0.2619, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4160]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9622]], dtype=torch.float64)\n",
      "tensor(0.2983, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4081]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9763]], dtype=torch.float64)\n",
      "tensor(0.3229, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4722]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9831]], dtype=torch.float64)\n",
      "tensor(0.2611, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5157]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9900]], dtype=torch.float64)\n",
      "tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5409]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2380]], dtype=torch.float64)\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5549]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2344]], dtype=torch.float64)\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 64/681 [00:00<00:07, 80.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5350]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0775]], dtype=torch.float64)\n",
      "tensor(0.2094, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5126]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0775]], dtype=torch.float64)\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4935]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0775]], dtype=torch.float64)\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4780]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0815]], dtype=torch.float64)\n",
      "tensor(0.1572, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4654]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0815]], dtype=torch.float64)\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4576]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0795]], dtype=torch.float64)\n",
      "tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4511]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0795]], dtype=torch.float64)\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4411]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0795]], dtype=torch.float64)\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4265]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0799]], dtype=torch.float64)\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4174]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.0799]], dtype=torch.float64)\n",
      "tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4027]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8706]], dtype=torch.float64)\n",
      "tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3997]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8706]], dtype=torch.float64)\n",
      "tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4279]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8706]], dtype=torch.float64)\n",
      "tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4777]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8955]], dtype=torch.float64)\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5183]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8955]], dtype=torch.float64)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5398]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8953]], dtype=torch.float64)\n",
      "tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5666]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8953]], dtype=torch.float64)\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 82/681 [00:00<00:07, 83.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6029]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8953]], dtype=torch.float64)\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6288]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8947]], dtype=torch.float64)\n",
      "tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6508]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8947]], dtype=torch.float64)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6422]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8953]], dtype=torch.float64)\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6472]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8831]], dtype=torch.float64)\n",
      "tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6169]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8831]], dtype=torch.float64)\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6236]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8840]], dtype=torch.float64)\n",
      "tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6216]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8840]], dtype=torch.float64)\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6192]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6088]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6126]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6222]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8594]], dtype=torch.float64)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6199]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8594]], dtype=torch.float64)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6432]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6507]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6600]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.8592]], dtype=torch.float64)\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6697]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3804]], dtype=torch.float64)\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.6520]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3804]], dtype=torch.float64)\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5943]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5875]], dtype=torch.float64)\n",
      "tensor(4.5678e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 100/681 [00:01<00:06, 83.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5637]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5969]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5453]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6063]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5449]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6120]], dtype=torch.float64)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5462]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6211]], dtype=torch.float64)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5547]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6302]], dtype=torch.float64)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5557]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6393]], dtype=torch.float64)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5502]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6484]], dtype=torch.float64)\n",
      "tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5483]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6626]], dtype=torch.float64)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5523]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6720]], dtype=torch.float64)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5554]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6756]], dtype=torch.float64)\n",
      "tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5508]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6847]], dtype=torch.float64)\n",
      "tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5560]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6938]], dtype=torch.float64)\n",
      "tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5678]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7029]], dtype=torch.float64)\n",
      "tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5672]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7120]], dtype=torch.float64)\n",
      "tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5625]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5731]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5498]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5731]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5731]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 125/681 [00:01<00:05, 102.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5108]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5730]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5020]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5730]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5024]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5729]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4981]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5729]], dtype=torch.float64)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4947]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5729]], dtype=torch.float64)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4930]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5729]], dtype=torch.float64)\n",
      "tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4922]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4993]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5109]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5098]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4988]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4948]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4896]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4895]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4907]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4887]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4857]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4871]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4866]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5188]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4865]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5493]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4939]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5030]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5294]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5414]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0389, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 147/681 [00:01<00:05, 96.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5517]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5592]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5773]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5799]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5791]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5842]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5946]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5817]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5742]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5678]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5627]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5660]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5730]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5711]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5682]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5673]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5717]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5691]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 158/681 [00:01<00:05, 98.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5730]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.7387]], dtype=torch.float64)\n",
      "tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5763]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067]], dtype=torch.float64)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5419]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5131]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4766]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5196]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4676]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4751]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5290]], dtype=torch.float64)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4722]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5348]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4750]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5406]], dtype=torch.float64)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4826]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5463]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4871]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5483]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5560]], dtype=torch.float64)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4962]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5560]], dtype=torch.float64)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4952]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5561]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4880]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5561]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5561]], dtype=torch.float64)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4884]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5559]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4835]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5559]], dtype=torch.float64)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4873]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5547]], dtype=torch.float64)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4864]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5547]], dtype=torch.float64)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4854]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5547]], dtype=torch.float64)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4831]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5486]], dtype=torch.float64)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 181/681 [00:01<00:04, 106.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4782]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5486]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4803]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5485]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4804]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5485]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4807]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5244]], dtype=torch.float64)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4724]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5215]], dtype=torch.float64)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4664]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5236]], dtype=torch.float64)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4652]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5255]], dtype=torch.float64)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4687]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5276]], dtype=torch.float64)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4695]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5297]], dtype=torch.float64)\n",
      "tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4775]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5414]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4813]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5441]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4764]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5465]], dtype=torch.float64)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4772]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5491]], dtype=torch.float64)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4756]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5518]], dtype=torch.float64)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4708]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5113]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4479]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5119]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4484]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5123]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4474]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5116]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4493]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5120]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4495]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5109]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4498]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5113]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4498]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5117]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4542]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5051]], dtype=torch.float64)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4551]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5052]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 207/681 [00:02<00:04, 114.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4457]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4925]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4391]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4909]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4326]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4883]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4364]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4856]], dtype=torch.float64)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4348]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4852]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4291]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4817]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4299]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4850]], dtype=torch.float64)\n",
      "tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4298]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4858]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4277]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4802]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4233]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4843]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4253]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4881]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4273]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4907]], dtype=torch.float64)\n",
      "tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4240]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4901]], dtype=torch.float64)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4275]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4933]], dtype=torch.float64)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4316]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4877]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4289]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4763]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4186]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4771]], dtype=torch.float64)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4141]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4756]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4143]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4862]], dtype=torch.float64)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4231]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4815]], dtype=torch.float64)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4249]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4766]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4156]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4761]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4144]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4711]], dtype=torch.float64)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4118]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4648]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4172]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4641]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4211]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4623]], dtype=torch.float64)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4147]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4555]], dtype=torch.float64)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4100]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 245/681 [00:02<00:03, 119.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4580]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4091]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4668]], dtype=torch.float64)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4018]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4721]], dtype=torch.float64)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3965]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4735]], dtype=torch.float64)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3949]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4375]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3888]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4305]], dtype=torch.float64)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3760]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4249]], dtype=torch.float64)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3696]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4259]], dtype=torch.float64)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3839]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4573]], dtype=torch.float64)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4013]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4834]], dtype=torch.float64)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4022]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4800]], dtype=torch.float64)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4029]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4940]], dtype=torch.float64)\n",
      "tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4040]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4678]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3916]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4731]], dtype=torch.float64)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3970]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4187]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3803]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4650]], dtype=torch.float64)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3893]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4087]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3620]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4103]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3564]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3093]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3402]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2887]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3147]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2840]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2932]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3965]], dtype=torch.float64)\n",
      "tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3214]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2859]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3286]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2894]], dtype=torch.float64)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3010]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2851]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2872]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2809]], dtype=torch.float64)\n",
      "tensor(3.9911e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 258/681 [00:02<00:03, 120.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2849]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3049]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2931]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3012]], dtype=torch.float64)\n",
      "tensor(6.5959e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2909]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2931]], dtype=torch.float64)\n",
      "tensor(4.9032e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2869]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2893]], dtype=torch.float64)\n",
      "tensor(5.6710e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2805]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2855]], dtype=torch.float64)\n",
      "tensor(2.4618e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2965]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4373]], dtype=torch.float64)\n",
      "tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3269]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4362]], dtype=torch.float64)\n",
      "tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3553]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2858]], dtype=torch.float64)\n",
      "tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3433]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2822]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3303]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2786]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3363]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2800]], dtype=torch.float64)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3471]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2764]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3481]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2602]], dtype=torch.float64)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3449]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2564]], dtype=torch.float64)\n",
      "tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3488]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2750]], dtype=torch.float64)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3530]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2356]], dtype=torch.float64)\n",
      "tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3392]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2316]], dtype=torch.float64)\n",
      "tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3282]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2272]], dtype=torch.float64)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3216]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2233]], dtype=torch.float64)\n",
      "tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3113]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2193]], dtype=torch.float64)\n",
      "tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3061]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2215]], dtype=torch.float64)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2947]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2176]], dtype=torch.float64)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2765]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2058]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2700]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2018]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2543]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.1978]], dtype=torch.float64)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2472]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2378]], dtype=torch.float64)\n",
      "tensor(8.7636e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 285/681 [00:02<00:03, 124.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2665]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2344]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2696]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2841]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2808]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2814]], dtype=torch.float64)\n",
      "tensor(3.1288e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2955]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2983]], dtype=torch.float64)\n",
      "tensor(8.0175e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3080]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2959]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3018]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3022]], dtype=torch.float64)\n",
      "tensor(1.3198e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2975]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3109]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3144]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3086]], dtype=torch.float64)\n",
      "tensor(3.3628e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3294]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3150]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3222]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3053]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3152]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3106]], dtype=torch.float64)\n",
      "tensor(2.1449e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3050]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2941]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2989]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2918]], dtype=torch.float64)\n",
      "tensor(4.9823e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3015]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2895]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3101]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2852]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3124]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2829]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3246]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2848]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3322]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2826]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3313]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2803]], dtype=torch.float64)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3312]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2872]], dtype=torch.float64)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3212]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2850]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3025]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2890]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2901]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2869]], dtype=torch.float64)\n",
      "tensor(1.0091e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2794]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2848]], dtype=torch.float64)\n",
      "tensor(2.8842e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2825]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2855]], dtype=torch.float64)\n",
      "tensor(8.7775e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2759]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2834]], dtype=torch.float64)\n",
      "tensor(5.6342e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 312/681 [00:03<00:02, 123.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2816]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2878]], dtype=torch.float64)\n",
      "tensor(3.8102e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2921]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2858]], dtype=torch.float64)\n",
      "tensor(4.0200e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3016]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2837]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3101]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2979]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3181]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2960]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3246]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2884]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3237]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2865]], dtype=torch.float64)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3200]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2846]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3131]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2842]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3044]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.2823]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.2969]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3090]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3162]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3074]], dtype=torch.float64)\n",
      "tensor(7.7299e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3126]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3028]], dtype=torch.float64)\n",
      "tensor(9.4963e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3122]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3057]], dtype=torch.float64)\n",
      "tensor(4.2839e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3143]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3040]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3117]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3068]], dtype=torch.float64)\n",
      "tensor(2.4401e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3144]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3035]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3173]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3203]], dtype=torch.float64)\n",
      "tensor(8.8227e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3203]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3188]], dtype=torch.float64)\n",
      "tensor(2.0454e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3208]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3233]], dtype=torch.float64)\n",
      "tensor(6.3865e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3195]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3219]], dtype=torch.float64)\n",
      "tensor(5.9477e-06, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 338/681 [00:03<00:02, 115.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3265]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3205]], dtype=torch.float64)\n",
      "tensor(3.5425e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3349]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3358]], dtype=torch.float64)\n",
      "tensor(8.5348e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3355]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3345]], dtype=torch.float64)\n",
      "tensor(1.0567e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3424]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3493]], dtype=torch.float64)\n",
      "tensor(4.8272e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3462]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3482]], dtype=torch.float64)\n",
      "tensor(3.7650e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3597]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3470]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3596]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3500]], dtype=torch.float64)\n",
      "tensor(9.1403e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3551]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3489]], dtype=torch.float64)\n",
      "tensor(3.8720e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3616]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3595]], dtype=torch.float64)\n",
      "tensor(4.4851e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3533]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3595]], dtype=torch.float64)\n",
      "tensor(3.8934e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3491]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3610]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3558]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3719]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3627]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3719]], dtype=torch.float64)\n",
      "tensor(8.4235e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3682]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3866]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3730]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3879]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3901]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3879]], dtype=torch.float64)\n",
      "tensor(4.9867e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3947]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3920]], dtype=torch.float64)\n",
      "tensor(7.2029e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3958]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3920]], dtype=torch.float64)\n",
      "tensor(1.4070e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4027]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3933]], dtype=torch.float64)\n",
      "tensor(8.9210e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3921]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3933]], dtype=torch.float64)\n",
      "tensor(1.4177e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3884]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3933]], dtype=torch.float64)\n",
      "tensor(2.4069e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3898]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3987]], dtype=torch.float64)\n",
      "tensor(7.7711e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3979]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3987]], dtype=torch.float64)\n",
      "tensor(5.7668e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4191]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3980]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4347]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3980]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4502]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3980]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 364/681 [00:03<00:02, 119.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4617]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3999]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4499]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.3999]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4361]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4024]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4169]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4035]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4075]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4035]], dtype=torch.float64)\n",
      "tensor(1.5545e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4119]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4094]], dtype=torch.float64)\n",
      "tensor(6.4454e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4133]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4094]], dtype=torch.float64)\n",
      "tensor(1.5528e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4210]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4131]], dtype=torch.float64)\n",
      "tensor(6.1449e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4218]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4131]], dtype=torch.float64)\n",
      "tensor(7.4255e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4242]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4131]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4215]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4179]], dtype=torch.float64)\n",
      "tensor(1.3286e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4146]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4179]], dtype=torch.float64)\n",
      "tensor(1.0942e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4054]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4208]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4013]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4200]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.3994]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4213]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4016]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4250]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4124]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4250]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4181]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4282]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4237]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4282]], dtype=torch.float64)\n",
      "tensor(1.9874e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4268]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4282]], dtype=torch.float64)\n",
      "tensor(1.9186e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4307]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4283]], dtype=torch.float64)\n",
      "tensor(5.9442e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4265]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4285]], dtype=torch.float64)\n",
      "tensor(4.3415e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4103]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4349]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4164]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4349]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4314]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4349]], dtype=torch.float64)\n",
      "tensor(1.2354e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4342]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4356]], dtype=torch.float64)\n",
      "tensor(1.9373e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4233]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4356]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 390/681 [00:03<00:02, 119.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4362]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4419]], dtype=torch.float64)\n",
      "tensor(3.2196e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4328]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4419]], dtype=torch.float64)\n",
      "tensor(8.1110e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4281]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4439]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4281]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4440]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4308]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4482]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4278]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4444]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4293]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4485]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4385]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4500]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4274]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4508]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4142]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4517]], dtype=torch.float64)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4264]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4545]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4321]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4545]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4359]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4550]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4365]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4519]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4305]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4398]], dtype=torch.float64)\n",
      "tensor(8.7284e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4220]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4672]], dtype=torch.float64)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4355]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4703]], dtype=torch.float64)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4392]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4672]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4306]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4714]], dtype=torch.float64)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4271]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4721]], dtype=torch.float64)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4380]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4691]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4334]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4663]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4229]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4703]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4161]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4736]], dtype=torch.float64)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4196]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4737]], dtype=torch.float64)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4247]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4738]], dtype=torch.float64)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 416/681 [00:03<00:02, 114.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4330]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4799]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4294]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4714]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4272]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4812]], dtype=torch.float64)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4251]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4814]], dtype=torch.float64)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4261]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4814]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4306]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4706]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4366]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4724]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4356]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4684]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4312]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4732]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4368]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4695]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4348]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4642]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4367]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4651]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4383]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5066]], dtype=torch.float64)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4383]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4614]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4653]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5089]], dtype=torch.float64)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4462]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5274]], dtype=torch.float64)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4669]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5286]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4811]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4867]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5277]], dtype=torch.float64)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4873]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5277]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4909]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5431]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4836]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5491]], dtype=torch.float64)\n",
      "tensor(0.0043, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 428/681 [00:04<00:02, 105.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4992]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5529]], dtype=torch.float64)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5096]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5563]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5498]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5736]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5259]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5700]], dtype=torch.float64)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5193]], dtype=torch.float64)\n",
      "tensor(1.7383e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5310]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5108]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5154]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5114]], dtype=torch.float64)\n",
      "tensor(1.5557e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5037]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5081]], dtype=torch.float64)\n",
      "tensor(1.9597e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5067]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5093]], dtype=torch.float64)\n",
      "tensor(6.6911e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5031]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5118]], dtype=torch.float64)\n",
      "tensor(7.6896e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5104]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5131]], dtype=torch.float64)\n",
      "tensor(7.4354e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5138]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5135]], dtype=torch.float64)\n",
      "tensor(7.8613e-08, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5155]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5125]], dtype=torch.float64)\n",
      "tensor(8.6727e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5162]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5137]], dtype=torch.float64)\n",
      "tensor(6.5202e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5108]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5108]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5148]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5108]], dtype=torch.float64)\n",
      "tensor(1.5624e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5172]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5068]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 449/681 [00:04<00:02, 90.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5173]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5068]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5804]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5804]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5804]], dtype=torch.float64)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5291]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5814]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5856]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5320]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6944]], dtype=torch.float64)\n",
      "tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5386]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6594]], dtype=torch.float64)\n",
      "tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5449]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6594]], dtype=torch.float64)\n",
      "tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5596]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6601]], dtype=torch.float64)\n",
      "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5725]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6601]], dtype=torch.float64)\n",
      "tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5810]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6514]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5835]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6514]], dtype=torch.float64)\n",
      "tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5808]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6514]], dtype=torch.float64)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5832]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6441]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5821]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6441]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 471/681 [00:04<00:02, 94.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5782]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6388]], dtype=torch.float64)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5728]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6388]], dtype=torch.float64)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5626]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6388]], dtype=torch.float64)\n",
      "tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5548]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6489]], dtype=torch.float64)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5620]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6489]], dtype=torch.float64)\n",
      "tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5554]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6335]], dtype=torch.float64)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5520]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6335]], dtype=torch.float64)\n",
      "tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5495]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6335]], dtype=torch.float64)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5543]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6028]], dtype=torch.float64)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5549]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.6028]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5445]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5928]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5398]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5928]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5304]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5928]], dtype=torch.float64)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5897]], dtype=torch.float64)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5897]], dtype=torch.float64)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5244]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5857]], dtype=torch.float64)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5324]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5857]], dtype=torch.float64)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5385]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5857]], dtype=torch.float64)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5377]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5804]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5366]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5804]], dtype=torch.float64)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5691]], dtype=torch.float64)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5269]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5691]], dtype=torch.float64)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 494/681 [00:04<00:01, 101.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5155]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5691]], dtype=torch.float64)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5682]], dtype=torch.float64)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5108]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5682]], dtype=torch.float64)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5122]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5625]], dtype=torch.float64)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5106]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5625]], dtype=torch.float64)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5146]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5625]], dtype=torch.float64)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5160]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5607]], dtype=torch.float64)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5607]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5139]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5326]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5055]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5326]], dtype=torch.float64)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4945]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5326]], dtype=torch.float64)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4938]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5324]], dtype=torch.float64)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4934]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5324]], dtype=torch.float64)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4958]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5324]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5023]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5324]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5026]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5324]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5023]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5306]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4975]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5306]], dtype=torch.float64)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4953]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5301]], dtype=torch.float64)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4939]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5301]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4902]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5301]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 517/681 [00:04<00:01, 105.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4913]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5311]], dtype=torch.float64)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4924]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5311]], dtype=torch.float64)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4947]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5312]], dtype=torch.float64)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4988]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5312]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5026]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5312]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5044]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5265]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5024]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5265]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4987]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4946]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4918]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4937]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4945]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5261]], dtype=torch.float64)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4987]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5263]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5051]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5263]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5021]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5263]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5017]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5224]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4987]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5224]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4967]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4972]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4962]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4965]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5237]], dtype=torch.float64)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4955]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5237]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4986]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5007]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 539/681 [00:05<00:01, 104.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4989]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4968]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5190]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4964]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5190]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4932]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5186]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4911]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5186]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4878]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5186]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4894]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5196]], dtype=torch.float64)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4915]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5196]], dtype=torch.float64)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4969]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5185]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4991]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5185]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4967]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5185]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4930]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5182]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4936]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5182]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4952]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5180]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4949]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5180]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4952]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5180]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4959]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5180]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4987]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5180]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5002]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5172]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5005]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5172]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5014]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5172]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.5003]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5139]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 562/681 [00:05<00:01, 107.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4972]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5139]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4939]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5139]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4913]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5124]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4881]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5124]], dtype=torch.float64)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4916]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5125]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4957]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5125]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4976]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5088]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4981]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5088]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4956]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5088]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4941]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5102]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4941]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5102]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4935]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5087]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4939]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5087]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4944]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5087]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4936]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5090]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4939]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5090]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4921]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5090]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4922]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4914]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4881]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4864]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4835]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048]], dtype=torch.float64)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4848]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 586/681 [00:05<00:00, 112.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4878]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4879]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4879]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067]], dtype=torch.float64)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4887]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4901]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4897]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4892]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4892]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5047]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4889]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5047]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4892]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5058]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4897]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5058]], dtype=torch.float64)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5058]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5050]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4898]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5050]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4878]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5019]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4884]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5019]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4867]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5019]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4864]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5003]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4851]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5003]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4847]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4843]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4856]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4861]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4987]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4886]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4987]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 610/681 [00:05<00:00, 110.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4892]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5000]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4876]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5000]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5000]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4898]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4989]], dtype=torch.float64)\n",
      "tensor(8.2527e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4875]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4989]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4878]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4965]], dtype=torch.float64)\n",
      "tensor(7.6550e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4870]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4965]], dtype=torch.float64)\n",
      "tensor(9.0530e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4876]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4965]], dtype=torch.float64)\n",
      "tensor(7.9174e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4882]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4963]], dtype=torch.float64)\n",
      "tensor(6.4788e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4880]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4963]], dtype=torch.float64)\n",
      "tensor(6.7437e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4888]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4971]], dtype=torch.float64)\n",
      "tensor(6.9657e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4882]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4971]], dtype=torch.float64)\n",
      "tensor(7.8754e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4874]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4971]], dtype=torch.float64)\n",
      "tensor(9.3839e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4858]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4944]], dtype=torch.float64)\n",
      "tensor(7.3898e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4854]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4944]], dtype=torch.float64)\n",
      "tensor(8.1370e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4846]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4934]], dtype=torch.float64)\n",
      "tensor(7.7241e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4813]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4934]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4808]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4934]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4789]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4931]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4790]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4931]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4785]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4881]], dtype=torch.float64)\n",
      "tensor(9.1767e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4794]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4881]], dtype=torch.float64)\n",
      "tensor(7.4766e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4787]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4881]], dtype=torch.float64)\n",
      "tensor(8.7719e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4794]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4876]], dtype=torch.float64)\n",
      "tensor(6.7622e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 635/681 [00:06<00:00, 108.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4792]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4876]], dtype=torch.float64)\n",
      "tensor(7.0818e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4892]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4782]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4892]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4786]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4892]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4779]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4882]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4799]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4882]], dtype=torch.float64)\n",
      "tensor(6.8907e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4796]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4877]], dtype=torch.float64)\n",
      "tensor(6.6697e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4809]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4877]], dtype=torch.float64)\n",
      "tensor(4.6822e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4836]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4877]], dtype=torch.float64)\n",
      "tensor(1.7010e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4836]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4865]], dtype=torch.float64)\n",
      "tensor(8.6771e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4818]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4865]], dtype=torch.float64)\n",
      "tensor(2.2920e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4836]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4826]], dtype=torch.float64)\n",
      "tensor(1.0860e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4848]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4826]], dtype=torch.float64)\n",
      "tensor(4.8399e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4837]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4826]], dtype=torch.float64)\n",
      "tensor(1.2336e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4809]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4704]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4799]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4704]], dtype=torch.float64)\n",
      "tensor(9.1361e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4773]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4708]], dtype=torch.float64)\n",
      "tensor(4.3178e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4778]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4708]], dtype=torch.float64)\n",
      "tensor(4.9391e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4780]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4708]], dtype=torch.float64)\n",
      "tensor(5.1991e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 646/681 [00:06<00:00, 98.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4782]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4733]], dtype=torch.float64)\n",
      "tensor(2.4589e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4779]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4733]], dtype=torch.float64)\n",
      "tensor(2.1506e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4784]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4731]], dtype=torch.float64)\n",
      "tensor(2.8017e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4790]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4731]], dtype=torch.float64)\n",
      "tensor(3.4503e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4731]], dtype=torch.float64)\n",
      "tensor(2.4666e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4796]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4740]], dtype=torch.float64)\n",
      "tensor(3.1198e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4792]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4740]], dtype=torch.float64)\n",
      "tensor(2.6410e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4801]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4737]], dtype=torch.float64)\n",
      "tensor(4.2036e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4814]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4737]], dtype=torch.float64)\n",
      "tensor(5.9120e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4816]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4737]], dtype=torch.float64)\n",
      "tensor(6.3636e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4802]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4723]], dtype=torch.float64)\n",
      "tensor(6.3799e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4789]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4723]], dtype=torch.float64)\n",
      "tensor(4.4040e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4827]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4716]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4848]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4716]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4840]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4716]], dtype=torch.float64)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4806]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4748]], dtype=torch.float64)\n",
      "tensor(3.3408e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 667/681 [00:06<00:00, 91.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4786]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4748]], dtype=torch.float64)\n",
      "tensor(1.4564e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4791]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4742]], dtype=torch.float64)\n",
      "tensor(2.3947e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4792]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4742]], dtype=torch.float64)\n",
      "tensor(2.5001e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4791]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4742]], dtype=torch.float64)\n",
      "tensor(2.3892e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4787]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4740]], dtype=torch.float64)\n",
      "tensor(2.2415e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4783]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4740]], dtype=torch.float64)\n",
      "tensor(1.8405e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4778]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4761]], dtype=torch.float64)\n",
      "tensor(2.9597e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4783]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4761]], dtype=torch.float64)\n",
      "tensor(4.7226e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4788]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4761]], dtype=torch.float64)\n",
      "tensor(7.0680e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4800]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4743]], dtype=torch.float64)\n",
      "tensor(3.1845e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4821]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4743]], dtype=torch.float64)\n",
      "tensor(6.1159e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4841]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4722]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4838]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4722]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4820]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4722]], dtype=torch.float64)\n",
      "tensor(9.7682e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4794]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4779]], dtype=torch.float64)\n",
      "tensor(2.1790e-06, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4820]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4779]], dtype=torch.float64)\n",
      "tensor(1.6400e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4864]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4748]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4859]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4748]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4835]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4748]], dtype=torch.float64)\n",
      "tensor(7.6149e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:06<00:00, 103.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4811]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4700]], dtype=torch.float64)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4795]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4700]], dtype=torch.float64)\n",
      "tensor(8.8910e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4778]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4709]], dtype=torch.float64)\n",
      "tensor(4.7636e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4780]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4709]], dtype=torch.float64)\n",
      "tensor(5.1302e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4779]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4709]], dtype=torch.float64)\n",
      "tensor(4.9590e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4714]], dtype=torch.float64)\n",
      "tensor(4.4651e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4714]], dtype=torch.float64)\n",
      "tensor(4.5394e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4777]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4693]], dtype=torch.float64)\n",
      "tensor(6.9593e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4779]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4693]], dtype=torch.float64)\n",
      "tensor(7.3856e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4788]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4693]], dtype=torch.float64)\n",
      "tensor(8.9586e-05, grad_fn=<MseLossBackward0>)\n",
      "tensor([[0.4827]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4761]], dtype=torch.float64)\n",
      "tensor(4.3565e-05, grad_fn=<MseLossBackward0>)\n",
      "Final val loss: 0.025164775331228642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load file and check MSELoss\n",
    "model = TransformerModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "model.load_state_dict(torch.load('transformer_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0][df['timestep']>200], \"val\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OmegaConf\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import shutil\n",
    "from diffusion_policy.policy.diffusion_unet_lowdim_policy import DiffusionUnetLowdimPolicy\n",
    "from diffusion_policy.workspace.train_diffusion_unet_lowdim_workspace import TrainDiffusionUnetLowdimWorkspace\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusion_policy.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusion_policy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLowdimDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'diffusion_policy.dataset'"
     ]
    }
   ],
   "source": [
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "from diffusion_policy.common.replay_buffer import ReplayBuffer\n",
    "from diffusion_policy.common.sampler import (\n",
    "    SequenceSampler, get_val_mask, downsample_mask)\n",
    "from diffusion_policy.model.common.normalizer import LinearNormalizer\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "\n",
    "\n",
    "class KULBarnDiffusionDataset(BaseLowdimDataset):\n",
    "    def __init__(self, df, horizon=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = df\n",
    "        self.get_local_goal()\n",
    "\n",
    "        self.data = self.data.drop(columns=[\n",
    "            'timestep', 'actual_time', 'optimal_time', \n",
    "            'pos_x', 'pos_y', 'pose_heading', 'goal_x', 'goal_y', 'success'\n",
    "        ])\n",
    "        \n",
    "        self.data = pd.DataFrame(self.data, columns=self.data.columns)\n",
    "        self.horizon = horizon\n",
    "\n",
    "        # Process data columns\n",
    "        self.lidar_cols = [col for col in self.data.columns if 'lidar' in col]\n",
    "        self.actions_cols = [col for col in self.data.columns if 'cmd' in col]\n",
    "        self.non_lidar_cols = [col for col in self.data.columns if col not in self.lidar_cols and col not in self.actions_cols and col != 'world_idx']\n",
    "\n",
    "        self.lidar_data = self.data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.data[self.actions_cols].values\n",
    "\n",
    "        print(\"Lidar Columns:\", self.lidar_cols)\n",
    "        print(\"Non Lidar Columns:\", self.non_lidar_cols)\n",
    "        print(\"Action Columns:\", self.actions_cols)     \n",
    "\n",
    "        self.grouped_data = self.data.groupby(self.data['world_idx'])\n",
    "        self.horizon = horizon\n",
    "        path_lengths = [len(group) for name, group in self.grouped_data]\n",
    "        self.indices = self.make_indices(path_lengths, horizon)\n",
    "\n",
    "    def get_local_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        self.data['local_x'] = (goal_x - x) * np.cos(theta) + (goal_y - y) * np.sin(theta)\n",
    "        self.data['local_y'] = -(goal_x - x) * np.sin(theta) + (goal_y - y) * np.cos(theta)\n",
    "\n",
    "    def make_indices(self, path_lengths, horizon):\n",
    "        indices = []\n",
    "        for i, path_length in enumerate(path_lengths):\n",
    "            max_start = path_length - horizon\n",
    "            for start in range(max_start):\n",
    "                end = start + horizon\n",
    "                indices.append((i, start, end))\n",
    "        indices = np.array(indices)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        idx = self.indices[idx]\n",
    "        start = idx[1]\n",
    "        end = idx[2]\n",
    "\n",
    "        data = {\n",
    "            'obs': self.lidar_data[start:end],\n",
    "            'cond': self.non_lidar_data[start:end],\n",
    "            'action': self.actions_data[start:end],\n",
    "        }\n",
    "        torch_data = dict_apply(data, torch.from_numpy)\n",
    "        return torch_data\n",
    "\n",
    "    def get_normalizer(self, mode='limits', **kwargs):\n",
    "        normalizer = LinearNormalizer()\n",
    "        # train it in using self.data as a dictionary\n",
    "        data_dict = {\n",
    "            'obs': self.lidar_data,\n",
    "            'cond': self.non_lidar_data,\n",
    "            'action': self.actions_data\n",
    "        }\n",
    "        normalizer.fit(data=data_dict, mode=mode, **kwargs)\n",
    "        return normalizer\n",
    "\n",
    "    def get_all_actions(self) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.actions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lidar Columns: ['lidar_0', 'lidar_1', 'lidar_2', 'lidar_3', 'lidar_4', 'lidar_5', 'lidar_6', 'lidar_7', 'lidar_8', 'lidar_9', 'lidar_10', 'lidar_11', 'lidar_12', 'lidar_13', 'lidar_14', 'lidar_15', 'lidar_16', 'lidar_17', 'lidar_18', 'lidar_19', 'lidar_20', 'lidar_21', 'lidar_22', 'lidar_23', 'lidar_24', 'lidar_25', 'lidar_26', 'lidar_27', 'lidar_28', 'lidar_29', 'lidar_30', 'lidar_31', 'lidar_32', 'lidar_33', 'lidar_34', 'lidar_35', 'lidar_36', 'lidar_37', 'lidar_38', 'lidar_39', 'lidar_40', 'lidar_41', 'lidar_42', 'lidar_43', 'lidar_44', 'lidar_45', 'lidar_46', 'lidar_47', 'lidar_48', 'lidar_49', 'lidar_50', 'lidar_51', 'lidar_52', 'lidar_53', 'lidar_54', 'lidar_55', 'lidar_56', 'lidar_57', 'lidar_58', 'lidar_59', 'lidar_60', 'lidar_61', 'lidar_62', 'lidar_63', 'lidar_64', 'lidar_65', 'lidar_66', 'lidar_67', 'lidar_68', 'lidar_69', 'lidar_70', 'lidar_71', 'lidar_72', 'lidar_73', 'lidar_74', 'lidar_75', 'lidar_76', 'lidar_77', 'lidar_78', 'lidar_79', 'lidar_80', 'lidar_81', 'lidar_82', 'lidar_83', 'lidar_84', 'lidar_85', 'lidar_86', 'lidar_87', 'lidar_88', 'lidar_89', 'lidar_90', 'lidar_91', 'lidar_92', 'lidar_93', 'lidar_94', 'lidar_95', 'lidar_96', 'lidar_97', 'lidar_98', 'lidar_99', 'lidar_100', 'lidar_101', 'lidar_102', 'lidar_103', 'lidar_104', 'lidar_105', 'lidar_106', 'lidar_107', 'lidar_108', 'lidar_109', 'lidar_110', 'lidar_111', 'lidar_112', 'lidar_113', 'lidar_114', 'lidar_115', 'lidar_116', 'lidar_117', 'lidar_118', 'lidar_119', 'lidar_120', 'lidar_121', 'lidar_122', 'lidar_123', 'lidar_124', 'lidar_125', 'lidar_126', 'lidar_127', 'lidar_128', 'lidar_129', 'lidar_130', 'lidar_131', 'lidar_132', 'lidar_133', 'lidar_134', 'lidar_135', 'lidar_136', 'lidar_137', 'lidar_138', 'lidar_139', 'lidar_140', 'lidar_141', 'lidar_142', 'lidar_143', 'lidar_144', 'lidar_145', 'lidar_146', 'lidar_147', 'lidar_148', 'lidar_149', 'lidar_150', 'lidar_151', 'lidar_152', 'lidar_153', 'lidar_154', 'lidar_155', 'lidar_156', 'lidar_157', 'lidar_158', 'lidar_159', 'lidar_160', 'lidar_161', 'lidar_162', 'lidar_163', 'lidar_164', 'lidar_165', 'lidar_166', 'lidar_167', 'lidar_168', 'lidar_169', 'lidar_170', 'lidar_171', 'lidar_172', 'lidar_173', 'lidar_174', 'lidar_175', 'lidar_176', 'lidar_177', 'lidar_178', 'lidar_179', 'lidar_180', 'lidar_181', 'lidar_182', 'lidar_183', 'lidar_184', 'lidar_185', 'lidar_186', 'lidar_187', 'lidar_188', 'lidar_189', 'lidar_190', 'lidar_191', 'lidar_192', 'lidar_193', 'lidar_194', 'lidar_195', 'lidar_196', 'lidar_197', 'lidar_198', 'lidar_199', 'lidar_200', 'lidar_201', 'lidar_202', 'lidar_203', 'lidar_204', 'lidar_205', 'lidar_206', 'lidar_207', 'lidar_208', 'lidar_209', 'lidar_210', 'lidar_211', 'lidar_212', 'lidar_213', 'lidar_214', 'lidar_215', 'lidar_216', 'lidar_217', 'lidar_218', 'lidar_219', 'lidar_220', 'lidar_221', 'lidar_222', 'lidar_223', 'lidar_224', 'lidar_225', 'lidar_226', 'lidar_227', 'lidar_228', 'lidar_229', 'lidar_230', 'lidar_231', 'lidar_232', 'lidar_233', 'lidar_234', 'lidar_235', 'lidar_236', 'lidar_237', 'lidar_238', 'lidar_239', 'lidar_240', 'lidar_241', 'lidar_242', 'lidar_243', 'lidar_244', 'lidar_245', 'lidar_246', 'lidar_247', 'lidar_248', 'lidar_249', 'lidar_250', 'lidar_251', 'lidar_252', 'lidar_253', 'lidar_254', 'lidar_255', 'lidar_256', 'lidar_257', 'lidar_258', 'lidar_259', 'lidar_260', 'lidar_261', 'lidar_262', 'lidar_263', 'lidar_264', 'lidar_265', 'lidar_266', 'lidar_267', 'lidar_268', 'lidar_269', 'lidar_270', 'lidar_271', 'lidar_272', 'lidar_273', 'lidar_274', 'lidar_275', 'lidar_276', 'lidar_277', 'lidar_278', 'lidar_279', 'lidar_280', 'lidar_281', 'lidar_282', 'lidar_283', 'lidar_284', 'lidar_285', 'lidar_286', 'lidar_287', 'lidar_288', 'lidar_289', 'lidar_290', 'lidar_291', 'lidar_292', 'lidar_293', 'lidar_294', 'lidar_295', 'lidar_296', 'lidar_297', 'lidar_298', 'lidar_299', 'lidar_300', 'lidar_301', 'lidar_302', 'lidar_303', 'lidar_304', 'lidar_305', 'lidar_306', 'lidar_307', 'lidar_308', 'lidar_309', 'lidar_310', 'lidar_311', 'lidar_312', 'lidar_313', 'lidar_314', 'lidar_315', 'lidar_316', 'lidar_317', 'lidar_318', 'lidar_319', 'lidar_320', 'lidar_321', 'lidar_322', 'lidar_323', 'lidar_324', 'lidar_325', 'lidar_326', 'lidar_327', 'lidar_328', 'lidar_329', 'lidar_330', 'lidar_331', 'lidar_332', 'lidar_333', 'lidar_334', 'lidar_335', 'lidar_336', 'lidar_337', 'lidar_338', 'lidar_339', 'lidar_340', 'lidar_341', 'lidar_342', 'lidar_343', 'lidar_344', 'lidar_345', 'lidar_346', 'lidar_347', 'lidar_348', 'lidar_349', 'lidar_350', 'lidar_351', 'lidar_352', 'lidar_353', 'lidar_354', 'lidar_355', 'lidar_356', 'lidar_357', 'lidar_358', 'lidar_359', 'lidar_360', 'lidar_361', 'lidar_362', 'lidar_363', 'lidar_364', 'lidar_365', 'lidar_366', 'lidar_367', 'lidar_368', 'lidar_369', 'lidar_370', 'lidar_371', 'lidar_372', 'lidar_373', 'lidar_374', 'lidar_375', 'lidar_376', 'lidar_377', 'lidar_378', 'lidar_379', 'lidar_380', 'lidar_381', 'lidar_382', 'lidar_383', 'lidar_384', 'lidar_385', 'lidar_386', 'lidar_387', 'lidar_388', 'lidar_389', 'lidar_390', 'lidar_391', 'lidar_392', 'lidar_393', 'lidar_394', 'lidar_395', 'lidar_396', 'lidar_397', 'lidar_398', 'lidar_399', 'lidar_400', 'lidar_401', 'lidar_402', 'lidar_403', 'lidar_404', 'lidar_405', 'lidar_406', 'lidar_407', 'lidar_408', 'lidar_409', 'lidar_410', 'lidar_411', 'lidar_412', 'lidar_413', 'lidar_414', 'lidar_415', 'lidar_416', 'lidar_417', 'lidar_418', 'lidar_419', 'lidar_420', 'lidar_421', 'lidar_422', 'lidar_423', 'lidar_424', 'lidar_425', 'lidar_426', 'lidar_427', 'lidar_428', 'lidar_429', 'lidar_430', 'lidar_431', 'lidar_432', 'lidar_433', 'lidar_434', 'lidar_435', 'lidar_436', 'lidar_437', 'lidar_438', 'lidar_439', 'lidar_440', 'lidar_441', 'lidar_442', 'lidar_443', 'lidar_444', 'lidar_445', 'lidar_446', 'lidar_447', 'lidar_448', 'lidar_449', 'lidar_450', 'lidar_451', 'lidar_452', 'lidar_453', 'lidar_454', 'lidar_455', 'lidar_456', 'lidar_457', 'lidar_458', 'lidar_459', 'lidar_460', 'lidar_461', 'lidar_462', 'lidar_463', 'lidar_464', 'lidar_465', 'lidar_466', 'lidar_467', 'lidar_468', 'lidar_469', 'lidar_470', 'lidar_471', 'lidar_472', 'lidar_473', 'lidar_474', 'lidar_475', 'lidar_476', 'lidar_477', 'lidar_478', 'lidar_479', 'lidar_480', 'lidar_481', 'lidar_482', 'lidar_483', 'lidar_484', 'lidar_485', 'lidar_486', 'lidar_487', 'lidar_488', 'lidar_489', 'lidar_490', 'lidar_491', 'lidar_492', 'lidar_493', 'lidar_494', 'lidar_495', 'lidar_496', 'lidar_497', 'lidar_498', 'lidar_499', 'lidar_500', 'lidar_501', 'lidar_502', 'lidar_503', 'lidar_504', 'lidar_505', 'lidar_506', 'lidar_507', 'lidar_508', 'lidar_509', 'lidar_510', 'lidar_511', 'lidar_512', 'lidar_513', 'lidar_514', 'lidar_515', 'lidar_516', 'lidar_517', 'lidar_518', 'lidar_519', 'lidar_520', 'lidar_521', 'lidar_522', 'lidar_523', 'lidar_524', 'lidar_525', 'lidar_526', 'lidar_527', 'lidar_528', 'lidar_529', 'lidar_530', 'lidar_531', 'lidar_532', 'lidar_533', 'lidar_534', 'lidar_535', 'lidar_536', 'lidar_537', 'lidar_538', 'lidar_539', 'lidar_540', 'lidar_541', 'lidar_542', 'lidar_543', 'lidar_544', 'lidar_545', 'lidar_546', 'lidar_547', 'lidar_548', 'lidar_549', 'lidar_550', 'lidar_551', 'lidar_552', 'lidar_553', 'lidar_554', 'lidar_555', 'lidar_556', 'lidar_557', 'lidar_558', 'lidar_559', 'lidar_560', 'lidar_561', 'lidar_562', 'lidar_563', 'lidar_564', 'lidar_565', 'lidar_566', 'lidar_567', 'lidar_568', 'lidar_569', 'lidar_570', 'lidar_571', 'lidar_572', 'lidar_573', 'lidar_574', 'lidar_575', 'lidar_576', 'lidar_577', 'lidar_578', 'lidar_579', 'lidar_580', 'lidar_581', 'lidar_582', 'lidar_583', 'lidar_584', 'lidar_585', 'lidar_586', 'lidar_587', 'lidar_588', 'lidar_589', 'lidar_590', 'lidar_591', 'lidar_592', 'lidar_593', 'lidar_594', 'lidar_595', 'lidar_596', 'lidar_597', 'lidar_598', 'lidar_599', 'lidar_600', 'lidar_601', 'lidar_602', 'lidar_603', 'lidar_604', 'lidar_605', 'lidar_606', 'lidar_607', 'lidar_608', 'lidar_609', 'lidar_610', 'lidar_611', 'lidar_612', 'lidar_613', 'lidar_614', 'lidar_615', 'lidar_616', 'lidar_617', 'lidar_618', 'lidar_619', 'lidar_620', 'lidar_621', 'lidar_622', 'lidar_623', 'lidar_624', 'lidar_625', 'lidar_626', 'lidar_627', 'lidar_628', 'lidar_629', 'lidar_630', 'lidar_631', 'lidar_632', 'lidar_633', 'lidar_634', 'lidar_635', 'lidar_636', 'lidar_637', 'lidar_638', 'lidar_639', 'lidar_640', 'lidar_641', 'lidar_642', 'lidar_643', 'lidar_644', 'lidar_645', 'lidar_646', 'lidar_647', 'lidar_648', 'lidar_649', 'lidar_650', 'lidar_651', 'lidar_652', 'lidar_653', 'lidar_654', 'lidar_655', 'lidar_656', 'lidar_657', 'lidar_658', 'lidar_659', 'lidar_660', 'lidar_661', 'lidar_662', 'lidar_663', 'lidar_664', 'lidar_665', 'lidar_666', 'lidar_667', 'lidar_668', 'lidar_669', 'lidar_670', 'lidar_671', 'lidar_672', 'lidar_673', 'lidar_674', 'lidar_675', 'lidar_676', 'lidar_677', 'lidar_678', 'lidar_679', 'lidar_680', 'lidar_681', 'lidar_682', 'lidar_683', 'lidar_684', 'lidar_685', 'lidar_686', 'lidar_687', 'lidar_688', 'lidar_689', 'lidar_690', 'lidar_691', 'lidar_692', 'lidar_693', 'lidar_694', 'lidar_695', 'lidar_696', 'lidar_697', 'lidar_698', 'lidar_699', 'lidar_700', 'lidar_701', 'lidar_702', 'lidar_703', 'lidar_704', 'lidar_705', 'lidar_706', 'lidar_707', 'lidar_708', 'lidar_709', 'lidar_710', 'lidar_711', 'lidar_712', 'lidar_713', 'lidar_714', 'lidar_715', 'lidar_716', 'lidar_717', 'lidar_718', 'lidar_719']\n",
      "Non Lidar Columns: ['twist_linear', 'twist_angular', 'local_x', 'local_y']\n",
      "Action Columns: ['cmd_vel_linear', 'cmd_vel_angular']\n",
      "141127\n"
     ]
    }
   ],
   "source": [
    "train_dataset = KULBarnDiffusionDataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "normalizer = train_dataset.get_normalizer()\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 720])\n",
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    # print(batch)\n",
    "    print(batch['obs'].shape)\n",
    "    print(batch['cond'].shape)\n",
    "    print(batch['action'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_policy.policy.diffusion_unet_lidar_policy import DiffusionUnetLidarPolicy\n",
    "from diffusion_policy.model.diffusion.conditional_unet1d import ConditionalUnet1D\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "\n",
    "obs_dim = batch['obs'].shape[-1]\n",
    "action_dim = batch['action'].shape[-1]\n",
    "input_dim = obs_dim + action_dim\n",
    "model = ConditionalUnet1D(input_dim=input_dim)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='linear')\n",
    "horizon = 4\n",
    "policy = DiffusionUnetLidarPolicy(\n",
    "    model=model, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    horizon=horizon, \n",
    "    obs_dim=obs_dim, \n",
    "    action_dim=action_dim, \n",
    "    n_obs_steps=4,\n",
    "    n_action_steps=4,\n",
    "    pred_action_steps_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.set_normalizer(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141127 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m---> 13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/raid/joshua/codes/mlda-barn-2024/train_imitation/diffusion_policy/diffusion_policy/policy/diffusion_unet_lidar_policy.py:242\u001b[0m, in \u001b[0;36mDiffusionUnetLidarPolicy.compute_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    239\u001b[0m noisy_trajectory[condition_mask] \u001b[38;5;241m=\u001b[39m trajectory[condition_mask]\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Predict the noise residual, passing 'cond' as an additional conditioning input\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_trajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlocal_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m pred_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_scheduler\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_type\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/robodiff/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/joshua/codes/mlda-barn-2024/train_imitation/diffusion_policy/diffusion_policy/model/diffusion/conditional_unet1d.py:199\u001b[0m, in \u001b[0;36mConditionalUnet1D.forward\u001b[0;34m(self, sample, timestep, local_cond, global_cond, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m global_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_step_encoder(timesteps)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     global_feature \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_cond\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# encode local features\u001b[39;00m\n\u001b[1;32m    204\u001b[0m h_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "losses = []\n",
    "save_loss_every = 1000\n",
    "total_loss = 0\n",
    "count = 0\n",
    "\n",
    "optimizer = optim.Adam(policy.model.parameters(), lr=5e-5)\n",
    "policy.model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        loss = policy.compute_loss(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        count += 1\n",
    "        if count >= save_loss_every:\n",
    "            curr_loss = total_loss / save_loss_every\n",
    "            print(\"Loss:\", curr_loss)\n",
    "            losses.append(curr_loss)\n",
    "            total_loss = 0\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
