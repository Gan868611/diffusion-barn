{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.905783</td>\n",
       "      <td>2.813742</td>\n",
       "      <td>2.794768</td>\n",
       "      <td>...</td>\n",
       "      <td>3.112071</td>\n",
       "      <td>0.205052</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>1.505057</td>\n",
       "      <td>0.806594</td>\n",
       "      <td>0.345266</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>0.121720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.840575</td>\n",
       "      <td>2.808143</td>\n",
       "      <td>2.803064</td>\n",
       "      <td>...</td>\n",
       "      <td>3.122633</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.726503</td>\n",
       "      <td>1.505057</td>\n",
       "      <td>0.806516</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.116774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.828396</td>\n",
       "      <td>2.813796</td>\n",
       "      <td>2.754563</td>\n",
       "      <td>...</td>\n",
       "      <td>3.135067</td>\n",
       "      <td>0.207049</td>\n",
       "      <td>0.742490</td>\n",
       "      <td>1.512638</td>\n",
       "      <td>0.806259</td>\n",
       "      <td>0.187503</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>1.008845</td>\n",
       "      <td>0.065822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.828840</td>\n",
       "      <td>2.826287</td>\n",
       "      <td>2.733729</td>\n",
       "      <td>...</td>\n",
       "      <td>3.145574</td>\n",
       "      <td>0.207960</td>\n",
       "      <td>0.758481</td>\n",
       "      <td>1.512638</td>\n",
       "      <td>0.806190</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.112035</td>\n",
       "      <td>1.018013</td>\n",
       "      <td>0.063720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.837754</td>\n",
       "      <td>2.764232</td>\n",
       "      <td>2.733025</td>\n",
       "      <td>...</td>\n",
       "      <td>3.158681</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>0.774463</td>\n",
       "      <td>1.519358</td>\n",
       "      <td>0.805715</td>\n",
       "      <td>0.178778</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.112035</td>\n",
       "      <td>1.002209</td>\n",
       "      <td>0.060449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   success  actual_time  optimal_time  world_idx  timestep  goal_x  goal_y  \\\n",
       "0     True       11.589      6.789547          0         0     0.0    10.0   \n",
       "1     True       11.589      6.789547          0         1     0.0    10.0   \n",
       "2     True       11.589      6.789547          0         2     0.0    10.0   \n",
       "3     True       11.589      6.789547          0         3     0.0    10.0   \n",
       "4     True       11.589      6.789547          0         4     0.0    10.0   \n",
       "\n",
       "    lidar_0   lidar_1   lidar_2  ...  lidar_359     pos_x     pos_y  \\\n",
       "0  2.905783  2.813742  2.794768  ...   3.112071  0.205052  0.710515   \n",
       "1  2.840575  2.808143  2.803064  ...   3.122633  0.206083  0.726503   \n",
       "2  2.828396  2.813796  2.754563  ...   3.135067  0.207049  0.742490   \n",
       "3  2.828840  2.826287  2.733729  ...   3.145574  0.207960  0.758481   \n",
       "4  2.837754  2.764232  2.733025  ...   3.158681  0.208817  0.774463   \n",
       "\n",
       "   pose_heading  twist_linear  twist_angular  cmd_vel_linear  cmd_vel_angular  \\\n",
       "0      1.505057      0.806594       0.345266             0.8         0.129909   \n",
       "1      1.505057      0.806516       0.285427             0.8         0.129909   \n",
       "2      1.512638      0.806259       0.187503             0.8         0.129909   \n",
       "3      1.512638      0.806190       0.184242             0.8         0.112035   \n",
       "4      1.519358      0.805715       0.178778             0.8         0.112035   \n",
       "\n",
       "   local_goal_x  local_goal_y  \n",
       "0      1.010742      0.121720  \n",
       "1      0.995312      0.116774  \n",
       "2      1.008845      0.065822  \n",
       "3      1.018013      0.063720  \n",
       "4      1.002209      0.060449  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../../kul_data_50Hz.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.905783</td>\n",
       "      <td>2.813742</td>\n",
       "      <td>2.794768</td>\n",
       "      <td>...</td>\n",
       "      <td>3.112071</td>\n",
       "      <td>0.205052</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>1.505057</td>\n",
       "      <td>0.806594</td>\n",
       "      <td>0.345266</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>0.121720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.840575</td>\n",
       "      <td>2.808143</td>\n",
       "      <td>2.803064</td>\n",
       "      <td>...</td>\n",
       "      <td>3.122633</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.726503</td>\n",
       "      <td>1.505057</td>\n",
       "      <td>0.806516</td>\n",
       "      <td>0.285427</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.116774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.828396</td>\n",
       "      <td>2.813796</td>\n",
       "      <td>2.754563</td>\n",
       "      <td>...</td>\n",
       "      <td>3.135067</td>\n",
       "      <td>0.207049</td>\n",
       "      <td>0.742490</td>\n",
       "      <td>1.512638</td>\n",
       "      <td>0.806259</td>\n",
       "      <td>0.187503</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>1.008845</td>\n",
       "      <td>0.065822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.828840</td>\n",
       "      <td>2.826287</td>\n",
       "      <td>2.733729</td>\n",
       "      <td>...</td>\n",
       "      <td>3.145574</td>\n",
       "      <td>0.207960</td>\n",
       "      <td>0.758481</td>\n",
       "      <td>1.512638</td>\n",
       "      <td>0.806190</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.112035</td>\n",
       "      <td>1.018013</td>\n",
       "      <td>0.063720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>11.589</td>\n",
       "      <td>6.789547</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.837754</td>\n",
       "      <td>2.764232</td>\n",
       "      <td>2.733025</td>\n",
       "      <td>...</td>\n",
       "      <td>3.158681</td>\n",
       "      <td>0.208817</td>\n",
       "      <td>0.774463</td>\n",
       "      <td>1.519358</td>\n",
       "      <td>0.805715</td>\n",
       "      <td>0.178778</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.112035</td>\n",
       "      <td>1.002209</td>\n",
       "      <td>0.060449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>True</td>\n",
       "      <td>11.569</td>\n",
       "      <td>6.861213</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.660380</td>\n",
       "      <td>3.600206</td>\n",
       "      <td>3.553994</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.120648</td>\n",
       "      <td>9.086782</td>\n",
       "      <td>1.518276</td>\n",
       "      <td>0.799525</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.112408</td>\n",
       "      <td>0.927478</td>\n",
       "      <td>-0.070416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>True</td>\n",
       "      <td>11.569</td>\n",
       "      <td>6.861213</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.672478</td>\n",
       "      <td>3.590072</td>\n",
       "      <td>3.562314</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.119782</td>\n",
       "      <td>9.103562</td>\n",
       "      <td>1.519303</td>\n",
       "      <td>0.799877</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.116968</td>\n",
       "      <td>0.910604</td>\n",
       "      <td>-0.071368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>True</td>\n",
       "      <td>11.569</td>\n",
       "      <td>6.861213</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.683901</td>\n",
       "      <td>3.591197</td>\n",
       "      <td>3.572896</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.119001</td>\n",
       "      <td>9.118737</td>\n",
       "      <td>1.519529</td>\n",
       "      <td>0.799824</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.116968</td>\n",
       "      <td>0.895392</td>\n",
       "      <td>-0.071571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>True</td>\n",
       "      <td>11.569</td>\n",
       "      <td>6.861213</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.696190</td>\n",
       "      <td>3.596281</td>\n",
       "      <td>3.584990</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.118174</td>\n",
       "      <td>9.134708</td>\n",
       "      <td>1.518961</td>\n",
       "      <td>0.799701</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.109731</td>\n",
       "      <td>0.879440</td>\n",
       "      <td>-0.071064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>True</td>\n",
       "      <td>11.569</td>\n",
       "      <td>6.861213</td>\n",
       "      <td>0</td>\n",
       "      <td>536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.707110</td>\n",
       "      <td>3.605811</td>\n",
       "      <td>3.596151</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.117333</td>\n",
       "      <td>9.150677</td>\n",
       "      <td>1.517657</td>\n",
       "      <td>0.799591</td>\n",
       "      <td>-0.037118</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.109731</td>\n",
       "      <td>0.863541</td>\n",
       "      <td>-0.069925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      success  actual_time  optimal_time  world_idx  timestep  goal_x  goal_y  \\\n",
       "0        True       11.589      6.789547          0         0     0.0    10.0   \n",
       "1        True       11.589      6.789547          0         1     0.0    10.0   \n",
       "2        True       11.589      6.789547          0         2     0.0    10.0   \n",
       "3        True       11.589      6.789547          0         3     0.0    10.0   \n",
       "4        True       11.589      6.789547          0         4     0.0    10.0   \n",
       "...       ...          ...           ...        ...       ...     ...     ...   \n",
       "1619     True       11.569      6.861213          0       532     0.0    10.0   \n",
       "1620     True       11.569      6.861213          0       533     0.0    10.0   \n",
       "1621     True       11.569      6.861213          0       534     0.0    10.0   \n",
       "1622     True       11.569      6.861213          0       535     0.0    10.0   \n",
       "1623     True       11.569      6.861213          0       536     0.0    10.0   \n",
       "\n",
       "       lidar_0   lidar_1   lidar_2  ...  lidar_359     pos_x     pos_y  \\\n",
       "0     2.905783  2.813742  2.794768  ...   3.112071  0.205052  0.710515   \n",
       "1     2.840575  2.808143  2.803064  ...   3.122633  0.206083  0.726503   \n",
       "2     2.828396  2.813796  2.754563  ...   3.135067  0.207049  0.742490   \n",
       "3     2.828840  2.826287  2.733729  ...   3.145574  0.207960  0.758481   \n",
       "4     2.837754  2.764232  2.733025  ...   3.158681  0.208817  0.774463   \n",
       "...        ...       ...       ...  ...        ...       ...       ...   \n",
       "1619  3.660380  3.600206  3.553994  ...   5.000000 -0.120648  9.086782   \n",
       "1620  3.672478  3.590072  3.562314  ...   5.000000 -0.119782  9.103562   \n",
       "1621  3.683901  3.591197  3.572896  ...   5.000000 -0.119001  9.118737   \n",
       "1622  3.696190  3.596281  3.584990  ...   5.000000 -0.118174  9.134708   \n",
       "1623  3.707110  3.605811  3.596151  ...   5.000000 -0.117333  9.150677   \n",
       "\n",
       "      pose_heading  twist_linear  twist_angular  cmd_vel_linear  \\\n",
       "0         1.505057      0.806594       0.345266             0.8   \n",
       "1         1.505057      0.806516       0.285427             0.8   \n",
       "2         1.512638      0.806259       0.187503             0.8   \n",
       "3         1.512638      0.806190       0.184242             0.8   \n",
       "4         1.519358      0.805715       0.178778             0.8   \n",
       "...            ...           ...            ...             ...   \n",
       "1619      1.518276      0.799525      -0.045950             0.8   \n",
       "1620      1.519303      0.799877       0.006273             0.8   \n",
       "1621      1.519529      0.799824       0.008816             0.8   \n",
       "1622      1.518961      0.799701      -0.007960             0.8   \n",
       "1623      1.517657      0.799591      -0.037118             0.8   \n",
       "\n",
       "      cmd_vel_angular  local_goal_x  local_goal_y  \n",
       "0            0.129909      1.010742      0.121720  \n",
       "1            0.129909      0.995312      0.116774  \n",
       "2            0.129909      1.008845      0.065822  \n",
       "3            0.112035      1.018013      0.063720  \n",
       "4            0.112035      1.002209      0.060449  \n",
       "...               ...           ...           ...  \n",
       "1619        -0.112408      0.927478     -0.070416  \n",
       "1620        -0.116968      0.910604     -0.071368  \n",
       "1621        -0.116968      0.895392     -0.071571  \n",
       "1622        -0.109731      0.879440     -0.071064  \n",
       "1623        -0.109731      0.863541     -0.069925  \n",
       "\n",
       "[1624 rows x 376 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['world_idx'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove rows with success = 0\n",
    "df = df[df['success'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check number of local_goal_x ** 2 + local_goal_y ** 2 < 0.25\n",
    "# df['distance'] = df['local_goal_x'] ** 2 + df['local_goal_y'] ** 2\n",
    "# df = df[df['distance'] > 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.75000e+02, 1.39000e+02, 1.85000e+02, 2.12000e+02, 2.91000e+02,\n",
       "        3.08000e+02, 2.78000e+02, 3.02000e+02, 4.36000e+02, 4.73000e+02,\n",
       "        6.44000e+02, 7.43000e+02, 9.27000e+02, 4.96800e+03, 1.72900e+03,\n",
       "        2.16300e+03, 2.84600e+03, 3.92200e+03, 4.94700e+03, 6.86900e+03,\n",
       "        9.92400e+03, 1.48750e+04, 2.96650e+04, 7.33390e+04, 1.09328e+05,\n",
       "        1.14623e+05, 5.12640e+04, 2.27860e+04, 1.33320e+04, 9.00000e+03,\n",
       "        7.05400e+03, 5.36000e+03, 3.93200e+03, 3.00800e+03, 2.48700e+03,\n",
       "        1.97200e+03, 4.08600e+03, 1.26200e+03, 1.10600e+03, 7.84000e+02,\n",
       "        7.15000e+02, 5.86000e+02, 4.86000e+02, 4.11000e+02, 4.93000e+02,\n",
       "        3.30000e+02, 2.14000e+02, 2.34000e+02, 1.13000e+02, 8.04000e+02]),\n",
       " array([-1.57079633e+00, -1.50796447e+00, -1.44513262e+00, -1.38230077e+00,\n",
       "        -1.31946891e+00, -1.25663706e+00, -1.19380521e+00, -1.13097336e+00,\n",
       "        -1.06814150e+00, -1.00530965e+00, -9.42477796e-01, -8.79645943e-01,\n",
       "        -8.16814090e-01, -7.53982237e-01, -6.91150384e-01, -6.28318531e-01,\n",
       "        -5.65486678e-01, -5.02654825e-01, -4.39822972e-01, -3.76991118e-01,\n",
       "        -3.14159265e-01, -2.51327412e-01, -1.88495559e-01, -1.25663706e-01,\n",
       "        -6.28318531e-02,  2.22044605e-16,  6.28318531e-02,  1.25663706e-01,\n",
       "         1.88495559e-01,  2.51327412e-01,  3.14159265e-01,  3.76991118e-01,\n",
       "         4.39822972e-01,  5.02654825e-01,  5.65486678e-01,  6.28318531e-01,\n",
       "         6.91150384e-01,  7.53982237e-01,  8.16814090e-01,  8.79645943e-01,\n",
       "         9.42477796e-01,  1.00530965e+00,  1.06814150e+00,  1.13097336e+00,\n",
       "         1.19380521e+00,  1.25663706e+00,  1.31946891e+00,  1.38230077e+00,\n",
       "         1.44513262e+00,  1.50796447e+00,  1.57079633e+00]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of cmd_vel_angular\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['cmd_vel_angular'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot histogram of cmd_vel_angular\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(df_filtered['cmd_vel_angular'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    516930\n",
       "Name: success, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of unsuccesful worlds\n",
    "df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_time</th>\n",
       "      <th>optimal_time</th>\n",
       "      <th>world_idx</th>\n",
       "      <th>timestep</th>\n",
       "      <th>goal_x</th>\n",
       "      <th>goal_y</th>\n",
       "      <th>lidar_0</th>\n",
       "      <th>lidar_1</th>\n",
       "      <th>lidar_2</th>\n",
       "      <th>lidar_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lidar_359</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pose_heading</th>\n",
       "      <th>twist_linear</th>\n",
       "      <th>twist_angular</th>\n",
       "      <th>cmd_vel_linear</th>\n",
       "      <th>cmd_vel_angular</th>\n",
       "      <th>local_goal_x</th>\n",
       "      <th>local_goal_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.0</td>\n",
       "      <td>516930.0</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "      <td>516930.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.364529</td>\n",
       "      <td>5.716047</td>\n",
       "      <td>153.040715</td>\n",
       "      <td>294.051167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.593196</td>\n",
       "      <td>2.578447</td>\n",
       "      <td>2.564354</td>\n",
       "      <td>2.550596</td>\n",
       "      <td>...</td>\n",
       "      <td>2.539596</td>\n",
       "      <td>-0.037224</td>\n",
       "      <td>4.797787</td>\n",
       "      <td>1.543883</td>\n",
       "      <td>0.781458</td>\n",
       "      <td>-0.004127</td>\n",
       "      <td>0.780020</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.505377</td>\n",
       "      <td>0.374405</td>\n",
       "      <td>86.863824</td>\n",
       "      <td>185.166268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335533</td>\n",
       "      <td>1.334920</td>\n",
       "      <td>1.335188</td>\n",
       "      <td>1.335395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356660</td>\n",
       "      <td>0.594841</td>\n",
       "      <td>2.455889</td>\n",
       "      <td>0.417316</td>\n",
       "      <td>0.118762</td>\n",
       "      <td>0.298939</td>\n",
       "      <td>0.118863</td>\n",
       "      <td>0.267846</td>\n",
       "      <td>0.159340</td>\n",
       "      <td>0.186782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.164000</td>\n",
       "      <td>5.006761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.292025</td>\n",
       "      <td>0.287717</td>\n",
       "      <td>0.285514</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219143</td>\n",
       "      <td>-1.882896</td>\n",
       "      <td>0.155551</td>\n",
       "      <td>-3.141500</td>\n",
       "      <td>-0.319516</td>\n",
       "      <td>-2.291173</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>-1.024090</td>\n",
       "      <td>-1.033593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.425000</td>\n",
       "      <td>5.448120</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.427225</td>\n",
       "      <td>1.418428</td>\n",
       "      <td>1.408925</td>\n",
       "      <td>1.398811</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362727</td>\n",
       "      <td>-0.417042</td>\n",
       "      <td>2.695819</td>\n",
       "      <td>1.438216</td>\n",
       "      <td>0.800045</td>\n",
       "      <td>-0.079541</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.084388</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.054256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.630000</td>\n",
       "      <td>5.620692</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.574854</td>\n",
       "      <td>2.553946</td>\n",
       "      <td>2.533804</td>\n",
       "      <td>2.515511</td>\n",
       "      <td>...</td>\n",
       "      <td>2.491284</td>\n",
       "      <td>-0.039007</td>\n",
       "      <td>4.697096</td>\n",
       "      <td>1.584143</td>\n",
       "      <td>0.800483</td>\n",
       "      <td>-0.003124</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.007501</td>\n",
       "      <td>1.007277</td>\n",
       "      <td>-0.003204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.037000</td>\n",
       "      <td>5.922397</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.441431</td>\n",
       "      <td>3.413008</td>\n",
       "      <td>3.386460</td>\n",
       "      <td>3.361030</td>\n",
       "      <td>...</td>\n",
       "      <td>3.392179</td>\n",
       "      <td>0.342896</td>\n",
       "      <td>6.909458</td>\n",
       "      <td>1.703568</td>\n",
       "      <td>0.801716</td>\n",
       "      <td>0.055921</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>1.015003</td>\n",
       "      <td>0.046966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.584000</td>\n",
       "      <td>6.933848</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.874988</td>\n",
       "      <td>9.379641</td>\n",
       "      <td>3.140724</td>\n",
       "      <td>0.815349</td>\n",
       "      <td>2.165141</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>1.049791</td>\n",
       "      <td>1.023601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_time   optimal_time      world_idx       timestep    goal_x  \\\n",
       "count  516930.000000  516930.000000  516930.000000  516930.000000  516930.0   \n",
       "mean       12.364529       5.716047     153.040715     294.051167       0.0   \n",
       "std         2.505377       0.374405      86.863824     185.166268       0.0   \n",
       "min        11.164000       5.006761       0.000000       0.000000       0.0   \n",
       "25%        11.425000       5.448120      78.000000     143.000000       0.0   \n",
       "50%        11.630000       5.620692     154.000000     286.000000       0.0   \n",
       "75%        12.037000       5.922397     229.000000     430.000000       0.0   \n",
       "max        30.584000       6.933848     299.000000    1502.000000       0.0   \n",
       "\n",
       "         goal_y        lidar_0        lidar_1        lidar_2        lidar_3  \\\n",
       "count  516930.0  516930.000000  516930.000000  516930.000000  516930.000000   \n",
       "mean       10.0       2.593196       2.578447       2.564354       2.550596   \n",
       "std         0.0       1.335533       1.334920       1.335188       1.335395   \n",
       "min        10.0       0.292025       0.287717       0.285514       0.280797   \n",
       "25%        10.0       1.427225       1.418428       1.408925       1.398811   \n",
       "50%        10.0       2.574854       2.553946       2.533804       2.515511   \n",
       "75%        10.0       3.441431       3.413008       3.386460       3.361030   \n",
       "max        10.0       5.000000       5.000000       5.000000       5.000000   \n",
       "\n",
       "       ...      lidar_359          pos_x          pos_y   pose_heading  \\\n",
       "count  ...  516930.000000  516930.000000  516930.000000  516930.000000   \n",
       "mean   ...       2.539596      -0.037224       4.797787       1.543883   \n",
       "std    ...       1.356660       0.594841       2.455889       0.417316   \n",
       "min    ...       0.219143      -1.882896       0.155551      -3.141500   \n",
       "25%    ...       1.362727      -0.417042       2.695819       1.438216   \n",
       "50%    ...       2.491284      -0.039007       4.697096       1.584143   \n",
       "75%    ...       3.392179       0.342896       6.909458       1.703568   \n",
       "max    ...       5.000000       1.874988       9.379641       3.140724   \n",
       "\n",
       "        twist_linear  twist_angular  cmd_vel_linear  cmd_vel_angular  \\\n",
       "count  516930.000000  516930.000000   516930.000000    516930.000000   \n",
       "mean        0.781458      -0.004127        0.780020        -0.003866   \n",
       "std         0.118762       0.298939        0.118863         0.267846   \n",
       "min        -0.319516      -2.291173       -0.300000        -1.570796   \n",
       "25%         0.800045      -0.079541        0.800000        -0.084388   \n",
       "50%         0.800483      -0.003124        0.800000        -0.007501   \n",
       "75%         0.801716       0.055921        0.800000         0.064685   \n",
       "max         0.815349       2.165141        0.800000         1.570796   \n",
       "\n",
       "        local_goal_x   local_goal_y  \n",
       "count  516930.000000  516930.000000  \n",
       "mean        0.981002       0.001193  \n",
       "std         0.159340       0.186782  \n",
       "min        -1.024090      -1.033593  \n",
       "25%         0.999997      -0.054256  \n",
       "50%         1.007277      -0.003204  \n",
       "75%         1.015003       0.046966  \n",
       "max         1.049791       1.023601  \n",
       "\n",
       "[8 rows x 375 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [success, actual_time, optimal_time, world_idx, timestep, goal_x, goal_y, lidar_0, lidar_1, lidar_2, lidar_3, lidar_4, lidar_5, lidar_6, lidar_7, lidar_8, lidar_9, lidar_10, lidar_11, lidar_12, lidar_13, lidar_14, lidar_15, lidar_16, lidar_17, lidar_18, lidar_19, lidar_20, lidar_21, lidar_22, lidar_23, lidar_24, lidar_25, lidar_26, lidar_27, lidar_28, lidar_29, lidar_30, lidar_31, lidar_32, lidar_33, lidar_34, lidar_35, lidar_36, lidar_37, lidar_38, lidar_39, lidar_40, lidar_41, lidar_42, lidar_43, lidar_44, lidar_45, lidar_46, lidar_47, lidar_48, lidar_49, lidar_50, lidar_51, lidar_52, lidar_53, lidar_54, lidar_55, lidar_56, lidar_57, lidar_58, lidar_59, lidar_60, lidar_61, lidar_62, lidar_63, lidar_64, lidar_65, lidar_66, lidar_67, lidar_68, lidar_69, lidar_70, lidar_71, lidar_72, lidar_73, lidar_74, lidar_75, lidar_76, lidar_77, lidar_78, lidar_79, lidar_80, lidar_81, lidar_82, lidar_83, lidar_84, lidar_85, lidar_86, lidar_87, lidar_88, lidar_89, lidar_90, lidar_91, lidar_92, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 376 columns]\n"
     ]
    }
   ],
   "source": [
    "# print rows with missing values\n",
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class KULBarnDataset(Dataset):\n",
    "    def get_normalized_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        self.data['goal_x'] = np.cos(theta) * (goal_x - x) + np.sin(theta) * (goal_y - y)\n",
    "        self.data['goal_y'] = -np.sin(theta) * (goal_x - x) + np.cos(theta) * (goal_y - y)\n",
    "        # dist = np.sqrt(self.data['goal_x'] ** 2 + self.data['goal_y'] ** 2)\n",
    "        # self.data['goal_x'] /= dist\n",
    "        # self.data['goal_y'] /= dist\n",
    "    \n",
    "    def __init__(self, df, mode=\"train\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = df\n",
    "        self.get_normalized_goal()  \n",
    "        \n",
    "        # get all the column values that contain the word lidar\n",
    "        self.lidar_cols = [\"lidar_\" + str(i) for i in range(0, 360, 1)]\n",
    "        # get actions columns\n",
    "        self.actions_cols = ['cmd_vel_linear', 'cmd_vel_angular']\n",
    "        # get other columns\n",
    "        self.non_lidar_cols = ['local_goal_x', 'local_goal_y', 'goal_x', 'goal_y']\n",
    "\n",
    "        # if mode == \"train\":\n",
    "        #     # Manually compute the min and max values for each column\n",
    "        #     self.min = self.data.min()\n",
    "        #     self.max = self.data.max()\n",
    "        #     # Save the mean and std to a JSON file\n",
    "        #     scaler_params = {\n",
    "        #         'min': self.min.to_dict(),\n",
    "        #         'max': self.max.to_dict()\n",
    "        #     }\n",
    "        #     with open('scaler_params.json', 'w') as f:\n",
    "        #         json.dump(scaler_params, f)\n",
    "        # else:\n",
    "        #     # Load the mean and std from the JSON file\n",
    "        #     with open('scaler_params.json', 'r') as f:\n",
    "        #         scaler_params = json.load(f)\n",
    "        #     self.min = pd.Series(scaler_params['min'])\n",
    "        #     self.max = pd.Series(scaler_params['max'])\n",
    "        \n",
    "        # dont normalizer local_x and local_y\n",
    "        # self.normalized_data = (self.data - self.min) / (self.max - self.min)\n",
    "        self.normalized_data = self.data\n",
    "         \n",
    "        self.lidar_data = self.normalized_data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.normalized_data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.normalized_data[self.actions_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lidar = self.lidar_data[idx]\n",
    "        non_lidar = self.non_lidar_data[idx]\n",
    "        actions = self.actions_data[idx]\n",
    "        return lidar, non_lidar, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random 90% of the world ids for training\n",
    "ids = df['world_idx'].unique()\n",
    "\n",
    "test_ids = list(range(0, 300, 5))\n",
    "\n",
    "non_test_ids = np.setdiff1d(ids, test_ids)\n",
    "\n",
    "train_ids = np.random.choice(non_test_ids, int(0.8 * len(non_test_ids)), replace=False)\n",
    "train_df = df[df['world_idx'].isin(train_ids)]\n",
    "train_dataset = KULBarnDataset(train_df, mode=\"train\")\n",
    "\n",
    "# take the remaining of the world ids for validation\n",
    "val_ids = np.setdiff1d(non_test_ids, train_ids)\n",
    "val_df = df[df['world_idx'].isin(val_ids)]\n",
    "val_dataset = KULBarnDataset(val_df, mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 48\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 5,\n",
       " 10,\n",
       " 15,\n",
       " 20,\n",
       " 25,\n",
       " 30,\n",
       " 35,\n",
       " 40,\n",
       " 45,\n",
       " 50,\n",
       " 55,\n",
       " 60,\n",
       " 65,\n",
       " 70,\n",
       " 75,\n",
       " 80,\n",
       " 85,\n",
       " 90,\n",
       " 95,\n",
       " 100,\n",
       " 105,\n",
       " 110,\n",
       " 115,\n",
       " 120,\n",
       " 125,\n",
       " 130,\n",
       " 135,\n",
       " 140,\n",
       " 145,\n",
       " 150,\n",
       " 155,\n",
       " 160,\n",
       " 165,\n",
       " 170,\n",
       " 175,\n",
       " 180,\n",
       " 185,\n",
       " 190,\n",
       " 195,\n",
       " 200,\n",
       " 205,\n",
       " 210,\n",
       " 215,\n",
       " 220,\n",
       " 225,\n",
       " 230,\n",
       " 235,\n",
       " 240,\n",
       " 245,\n",
       " 250,\n",
       " 255,\n",
       " 260,\n",
       " 265,\n",
       " 270,\n",
       " 275,\n",
       " 280,\n",
       " 285,\n",
       " 290,\n",
       " 295]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 328181\n",
      "Val Dataset Length: 86832\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Length:\", len(train_dataset))\n",
    "print(\"Val Dataset Length:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non lidar shape: torch.Size([64, 4])\n",
      "Lidar shape: torch.Size([64, 360])\n",
      "Train loader size: 5128\n",
      "Val loader size: 1357\n",
      "tensor([[5.0000, 5.0000, 5.0000,  ..., 0.6286, 0.6247, 0.6309],\n",
      "        [1.0795, 1.0797, 1.0836,  ..., 1.0961, 1.0934, 1.0903],\n",
      "        [2.6551, 2.6365, 2.6364,  ..., 3.3111, 3.3189, 3.4283],\n",
      "        ...,\n",
      "        [2.5813, 2.5768, 2.5877,  ..., 3.6216, 3.6779, 3.7541],\n",
      "        [5.0000, 5.0000, 5.0000,  ..., 5.0000, 5.0000, 5.0000],\n",
      "        [3.2849, 3.2577, 3.2603,  ..., 2.5820, 2.6610, 2.6622]],\n",
      "       dtype=torch.float64) tensor([[ 9.8250e-01, -1.9034e-01,  3.5345e+00,  2.1111e+00],\n",
      "        [ 1.0070e+00, -4.9800e-02,  5.8422e+00, -7.2059e+00],\n",
      "        [ 1.0182e+00,  2.5418e-02,  9.3392e+00, -1.0325e+01],\n",
      "        [ 1.0179e+00, -4.2955e-02,  3.2724e+00, -3.6671e+00],\n",
      "        [ 1.0133e+00, -1.7332e-03,  4.7490e+00, -5.1418e+00],\n",
      "        [ 1.0180e+00, -1.6225e-02,  6.8391e+00, -7.3570e+00],\n",
      "        [ 9.3743e-01, -3.8701e-01,  7.2407e+00, -6.0233e-01],\n",
      "        [ 7.2958e-01,  7.0551e-01,  8.5447e+00, -1.0472e+01],\n",
      "        [ 9.8152e-01,  2.2504e-01,  7.8543e+00, -7.4491e+00],\n",
      "        [ 1.0146e+00, -8.5760e-02,  4.8920e+00, -5.6834e+00],\n",
      "        [ 1.0160e+00,  2.8748e-02,  1.6379e+00, -1.4866e+00],\n",
      "        [ 1.0095e+00, -1.0176e-01,  8.3571e+00, -5.2794e+00],\n",
      "        [ 9.5005e-01,  3.5372e-01,  6.8922e+00, -3.5965e+00],\n",
      "        [ 1.0102e+00, -7.4333e-02,  4.1891e+00, -5.1899e+00],\n",
      "        [ 9.9837e-01, -1.8645e-01,  7.2917e+00, -9.2966e+00],\n",
      "        [ 9.9995e-01, -1.3963e-01,  8.9811e+00, -1.1328e+01],\n",
      "        [ 1.0090e+00, -1.4932e-02,  4.0003e+00, -4.3114e+00],\n",
      "        [ 9.9975e-01, -4.9331e-02,  4.1933e+00, -5.4813e+00],\n",
      "        [ 1.0007e+00, -3.2297e-02,  2.6121e+00, -2.9101e+00],\n",
      "        [ 1.0013e+00, -2.0629e-03,  2.3525e+00, -2.2389e+00],\n",
      "        [ 1.0149e+00,  3.0501e-03,  1.2188e+00, -1.1553e+00],\n",
      "        [ 1.0008e+00, -1.5805e-01,  3.8900e+00, -5.2096e+00],\n",
      "        [ 9.2045e-01, -4.1244e-01,  6.0824e+00, -2.7411e+00],\n",
      "        [ 9.8388e-01,  2.8225e-01,  3.5522e+00, -1.9354e+00],\n",
      "        [ 8.6115e-01,  5.2371e-01,  4.7669e+00,  3.3129e+00],\n",
      "        [ 9.9031e-01,  2.4431e-01,  5.9324e+00, -1.0553e+01],\n",
      "        [ 1.0010e+00, -1.6689e-01,  8.5275e+00, -8.5391e+00],\n",
      "        [ 1.0198e+00,  4.5119e-02,  8.8463e+00, -6.6495e+00],\n",
      "        [ 1.0231e+00, -1.0942e-02,  3.7732e+00, -3.8262e+00],\n",
      "        [ 1.0132e+00,  2.5759e-03,  9.2042e+00, -9.1897e+00],\n",
      "        [ 1.0096e+00, -7.6425e-02,  8.9734e+00, -8.9392e+00],\n",
      "        [ 1.0035e+00, -1.0615e-01,  8.5227e+00, -6.3473e+00],\n",
      "        [ 9.9241e-01,  2.3261e-01,  4.7478e+00, -2.6795e+00],\n",
      "        [ 1.0142e+00, -5.8035e-02,  1.0051e+00, -1.0623e+00],\n",
      "        [ 1.0017e+00, -1.3311e-01,  5.0494e+00, -2.5116e+00],\n",
      "        [ 9.4799e-01,  3.3874e-01,  4.5799e+00,  2.4204e+00],\n",
      "        [ 1.0210e+00, -8.8080e-02,  8.2984e+00, -6.7921e+00],\n",
      "        [ 1.0004e+00, -2.8615e-02,  6.3126e+00, -7.2084e+00],\n",
      "        [ 1.0159e+00, -3.3880e-02,  4.0230e+00, -4.4451e+00],\n",
      "        [ 1.0142e+00,  1.0874e-01,  9.0963e+00, -7.2593e+00],\n",
      "        [ 1.0224e+00, -5.1646e-02,  2.5118e+00, -2.8012e+00],\n",
      "        [ 1.0170e+00,  1.4209e-02,  4.3246e+00, -1.3197e-01],\n",
      "        [ 9.8170e-01,  2.4857e-01,  4.1196e+00, -1.4320e+00],\n",
      "        [ 1.0097e+00, -1.0387e-02,  2.2607e+00, -2.2652e+00],\n",
      "        [ 8.6917e-01,  5.3574e-01,  2.9101e+00,  3.9479e+00],\n",
      "        [ 9.6752e-01,  2.6980e-01,  2.0960e+00, -5.1791e+00],\n",
      "        [ 9.6283e-01,  2.8157e-01,  3.4867e+00, -2.1740e+00],\n",
      "        [ 1.0096e+00,  5.3061e-02,  3.9656e+00, -3.4091e+00],\n",
      "        [ 1.0018e+00, -2.7466e-02,  3.1328e+00, -3.0954e+00],\n",
      "        [ 1.0146e+00, -1.6534e-02,  3.9917e+00, -4.4291e+00],\n",
      "        [ 1.0135e+00,  3.9561e-03,  1.8409e+00, -1.7518e+00],\n",
      "        [ 9.8599e-01, -1.9763e-01,  9.1389e+00, -8.3789e+00],\n",
      "        [ 9.9981e-01, -3.5042e-02,  1.2970e+00, -1.3759e+00],\n",
      "        [ 9.9915e-01, -2.1573e-01,  3.7239e+00, -4.8918e+00],\n",
      "        [ 1.0185e+00, -5.2290e-02,  3.8922e+00, -3.9177e+00],\n",
      "        [ 1.0131e+00, -1.2280e-01,  8.7501e+00, -7.1256e+00],\n",
      "        [ 1.0116e+00,  2.4629e-02,  1.4922e+00, -1.3827e+00],\n",
      "        [ 9.9683e-01, -1.7956e-01,  5.0839e+00, -7.7030e+00],\n",
      "        [ 1.0126e+00,  4.7927e-02,  3.2335e+00, -2.8847e+00],\n",
      "        [ 1.0128e+00, -8.5835e-02,  6.3508e+00, -4.3397e+00],\n",
      "        [ 1.0021e+00, -9.1386e-02,  5.5565e+00, -3.4366e+00],\n",
      "        [ 1.0045e+00,  5.9955e-02,  7.9146e+00, -9.4615e+00],\n",
      "        [ 1.0142e+00, -8.5773e-02,  2.6765e+00, -2.9896e+00],\n",
      "        [ 9.9587e-01,  2.3150e-01,  8.1088e+00, -8.2957e+00]],\n",
      "       dtype=torch.float64) tensor([[ 2.0000e-01, -5.0141e-01],\n",
      "        [ 8.0000e-01, -2.8874e-02],\n",
      "        [ 8.0000e-01,  5.4282e-02],\n",
      "        [ 8.0000e-01, -5.3759e-02],\n",
      "        [ 8.0000e-01,  3.9237e-02],\n",
      "        [ 8.0000e-01, -2.8472e-02],\n",
      "        [ 8.0000e-01, -7.1616e-01],\n",
      "        [ 5.2971e-01,  1.5708e+00],\n",
      "        [ 8.0000e-01,  3.3753e-01],\n",
      "        [ 8.0000e-01, -1.4804e-01],\n",
      "        [ 8.0000e-01,  4.4719e-02],\n",
      "        [ 8.0000e-01, -1.4117e-01],\n",
      "        [ 8.0000e-01,  6.4077e-01],\n",
      "        [ 8.0000e-01, -1.3213e-01],\n",
      "        [ 8.0000e-01, -2.2344e-01],\n",
      "        [ 8.0000e-01, -2.0551e-01],\n",
      "        [ 8.0000e-01, -1.2589e-02],\n",
      "        [ 8.0000e-01, -4.7943e-03],\n",
      "        [ 8.0000e-01, -3.4301e-02],\n",
      "        [ 8.0000e-01, -7.4102e-03],\n",
      "        [ 8.0000e-01,  6.5605e-02],\n",
      "        [ 8.0000e-01, -7.9679e-02],\n",
      "        [-0.0000e+00, -7.5000e-01],\n",
      "        [ 8.0000e-01,  5.2296e-01],\n",
      "        [ 8.0000e-01,  6.8429e-01],\n",
      "        [ 7.1000e-01,  4.4341e-01],\n",
      "        [ 8.0000e-01, -2.7312e-01],\n",
      "        [ 8.0000e-01,  9.2189e-02],\n",
      "        [ 8.0000e-01, -1.9902e-02],\n",
      "        [ 8.0000e-01,  1.2108e-03],\n",
      "        [ 8.0000e-01, -1.0555e-01],\n",
      "        [ 8.0000e-01, -1.1858e-01],\n",
      "        [ 8.0000e-01,  4.6113e-01],\n",
      "        [ 8.0000e-01, -6.8097e-02],\n",
      "        [ 8.0000e-01, -2.8557e-01],\n",
      "        [ 8.0000e-01, -1.6417e-03],\n",
      "        [ 8.0000e-01, -1.2443e-01],\n",
      "        [ 8.0000e-01, -1.1370e-01],\n",
      "        [ 8.0000e-01, -1.5283e-02],\n",
      "        [ 8.0000e-01,  2.1177e-01],\n",
      "        [ 8.0000e-01, -8.1049e-02],\n",
      "        [ 8.0000e-01, -1.5418e-02],\n",
      "        [ 8.0000e-01,  1.8070e-01],\n",
      "        [ 8.0000e-01, -3.1176e-02],\n",
      "        [ 8.0000e-01,  5.9479e-01],\n",
      "        [ 2.0000e-01,  4.2552e-01],\n",
      "        [ 8.0000e-01,  5.2559e-01],\n",
      "        [ 8.0000e-01,  6.8897e-02],\n",
      "        [ 8.0000e-01, -4.0892e-02],\n",
      "        [ 8.0000e-01,  5.1138e-03],\n",
      "        [ 8.0000e-01,  1.1870e-02],\n",
      "        [ 8.0000e-01, -3.3167e-01],\n",
      "        [ 8.0000e-01, -6.9073e-02],\n",
      "        [ 8.0000e-01, -3.4301e-01],\n",
      "        [ 8.0000e-01, -4.8451e-02],\n",
      "        [ 8.0000e-01, -1.7224e-01],\n",
      "        [ 8.0000e-01,  5.2380e-02],\n",
      "        [ 8.0000e-01, -2.4172e-01],\n",
      "        [ 8.0000e-01,  6.6502e-02],\n",
      "        [ 8.0000e-01, -1.4199e-01],\n",
      "        [ 8.0000e-01, -1.7530e-01],\n",
      "        [ 8.0000e-01,  6.1302e-02],\n",
      "        [ 8.0000e-01, -1.1604e-01],\n",
      "        [ 8.0000e-01, -2.9234e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "# test dataloader\n",
    "lidar, non_lidar, actions = next(iter(train_loader))\n",
    "print(f\"Non lidar shape: {non_lidar.shape}\")\n",
    "print(f\"Lidar shape: {lidar.shape}\")\n",
    "# print size dataloader\n",
    "print(f\"Train loader size: {len(train_loader)}\")\n",
    "print(f\"Val loader size: {len(val_loader)}\")\n",
    "print(lidar, non_lidar, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6092, 1.6088, 1.6161,  ..., 1.3218, 1.3338, 1.0595],\n",
       "        [5.0000, 5.0000, 5.0000,  ..., 2.2191, 2.1918, 2.1830],\n",
       "        [4.2073, 0.6491, 0.6202,  ..., 1.3644, 1.3874, 1.4640],\n",
       "        ...,\n",
       "        [3.2884, 3.2538, 3.1591,  ..., 2.8489, 2.8723, 2.9261],\n",
       "        [0.9781, 0.9903, 1.0098,  ..., 2.6384, 2.6119, 2.6074],\n",
       "        [1.5713, 1.5445, 1.5324,  ..., 1.6371, 1.6459, 1.5770]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0091e+00,  3.4736e-02,  3.6073e+00, -3.3174e+00],\n",
       "        [ 1.0018e+00,  1.5209e-01,  6.1021e+00, -2.5544e+00],\n",
       "        [ 9.7821e-01, -2.0824e-01,  7.2972e+00, -9.4909e+00],\n",
       "        [ 1.0063e+00, -2.8745e-02,  7.5510e+00, -2.6345e+00],\n",
       "        [ 8.7097e-01, -5.2260e-01,  5.1767e+00, -8.9806e+00],\n",
       "        [ 1.0231e+00,  5.4826e-02,  2.8687e+00, -2.5559e+00],\n",
       "        [ 1.0132e+00, -2.5516e-02,  9.0718e+00, -9.5370e+00],\n",
       "        [ 1.0142e+00,  3.4468e-02,  7.1633e+00, -9.0050e+00],\n",
       "        [ 7.3588e-01,  6.8362e-01,  6.4479e+00, -7.4488e+00],\n",
       "        [ 1.0025e+00,  1.0595e-01,  4.8259e+00, -4.4851e+00],\n",
       "        [ 1.0201e+00,  1.1445e-02,  3.3215e+00, -3.1967e+00],\n",
       "        [ 1.0220e+00, -3.8996e-02,  6.8600e+00, -7.2668e+00],\n",
       "        [ 1.0051e+00,  1.0385e-02,  8.9801e+00, -8.9755e+00],\n",
       "        [ 1.0176e+00,  4.6899e-02,  7.3459e+00, -7.7309e+00],\n",
       "        [ 1.0022e+00, -6.4589e-02,  6.6757e+00, -4.4872e+00],\n",
       "        [ 1.0097e+00,  1.1752e-02,  1.5869e+00, -1.5193e+00],\n",
       "        [ 1.0166e+00,  3.6969e-03,  3.1682e+00, -3.0728e+00],\n",
       "        [ 1.0212e+00,  1.7114e-02,  2.1009e+00, -1.9907e+00],\n",
       "        [ 1.0043e+00, -1.4533e-01,  4.1711e+00, -6.4430e+00],\n",
       "        [ 1.0045e+00, -1.7899e-02,  6.8134e+00, -7.5518e+00],\n",
       "        [ 1.0073e+00, -2.9450e-02,  8.7005e+00, -7.9541e+00],\n",
       "        [ 1.0018e+00,  8.7705e-02,  6.3694e+00, -1.0530e+01],\n",
       "        [ 1.0124e+00, -1.4426e-01,  9.2040e+00, -1.0806e+01],\n",
       "        [ 1.0103e+00,  1.2613e-01,  9.1687e+00, -9.1037e+00],\n",
       "        [ 1.0122e+00,  3.6723e-03,  7.7226e+00, -8.4194e+00],\n",
       "        [ 1.0180e+00, -3.8521e-02,  3.2723e+00, -3.6583e+00],\n",
       "        [ 1.0050e+00, -2.0444e-03,  2.4455e+00, -2.4823e+00],\n",
       "        [ 1.0071e+00, -2.5595e-02,  6.1689e+00, -5.7796e+00],\n",
       "        [ 1.0153e+00,  1.2699e-01,  5.7989e+00, -3.7586e+00],\n",
       "        [ 1.0125e+00, -8.6819e-02,  5.2507e+00, -6.6521e+00],\n",
       "        [ 1.0141e+00, -3.4057e-02,  5.2641e+00, -4.0227e+00],\n",
       "        [ 1.0077e+00, -1.7861e-02,  4.1872e+00, -4.6175e+00],\n",
       "        [ 1.0194e+00, -4.5116e-02,  2.5327e+00, -2.8227e+00],\n",
       "        [ 9.6622e-01,  4.2698e-02,  9.5744e-01, -8.8479e-01],\n",
       "        [ 1.0212e+00, -6.2872e-02,  7.6321e+00, -7.6579e+00],\n",
       "        [ 1.0030e+00, -1.1639e-03,  6.6830e+00, -5.6704e+00],\n",
       "        [ 1.0016e+00, -4.1515e-02,  6.5568e+00, -2.9331e+00],\n",
       "        [ 9.9210e-01, -1.5762e-01,  7.5366e+00, -9.5214e+00],\n",
       "        [ 1.0057e+00,  5.4702e-02,  3.3283e+00, -2.9697e+00],\n",
       "        [ 5.2131e-01,  8.7833e-01, -3.7308e+00,  1.6933e+00],\n",
       "        [ 9.8639e-01,  2.2559e-01,  5.1467e+00, -3.7412e+00],\n",
       "        [ 1.0180e+00,  2.3161e-03,  2.7759e+00, -2.9728e+00],\n",
       "        [ 1.0243e+00,  1.1687e-02,  1.5778e+00, -1.4795e+00],\n",
       "        [ 1.0159e+00,  3.5549e-02,  6.7975e+00, -1.0190e+01],\n",
       "        [ 9.8801e-01,  2.1274e-01,  9.3514e+00, -9.2251e+00],\n",
       "        [ 1.0058e+00, -2.4397e-02,  3.0942e+00, -3.3982e+00],\n",
       "        [ 5.5358e-01, -8.5062e-01,  5.4053e-01, -6.1712e+00],\n",
       "        [ 1.0168e+00, -1.0739e-01,  6.3433e+00, -7.1922e+00],\n",
       "        [ 1.0007e+00, -3.8203e-03,  2.9913e+00, -3.2248e+00],\n",
       "        [ 1.0131e+00,  4.8640e-02,  7.9584e+00, -8.7409e+00],\n",
       "        [ 1.0077e+00, -2.9201e-02,  1.9275e+00, -2.1119e+00],\n",
       "        [ 1.0214e+00,  3.5574e-02,  2.1147e+00, -1.8830e+00],\n",
       "        [ 1.0145e+00,  5.3417e-02,  9.2355e+00, -8.9171e+00],\n",
       "        [ 1.0171e+00, -3.7865e-02,  4.0325e+00, -4.5553e+00],\n",
       "        [ 1.0061e+00,  1.1949e-01,  8.8500e+00, -8.6828e+00],\n",
       "        [ 1.0024e+00,  2.3955e-02,  4.0110e+00, -4.2415e+00],\n",
       "        [ 1.0041e+00,  2.0263e-01,  7.5563e+00, -5.4825e+00],\n",
       "        [ 1.0104e+00,  1.5551e-01,  9.3342e+00, -8.2096e+00],\n",
       "        [ 9.3429e-01, -3.7486e-01,  9.4533e+00, -9.7724e+00],\n",
       "        [ 1.0175e+00,  2.0830e-03,  5.0941e+00, -4.8914e+00],\n",
       "        [ 1.0180e+00,  3.7023e-02,  3.4407e+00, -3.5954e+00],\n",
       "        [ 9.9999e-01,  1.1837e-01,  7.6345e+00, -5.2644e+00],\n",
       "        [ 9.9592e-01,  2.1921e-01,  4.7548e+00, -1.5176e+00],\n",
       "        [ 1.0104e+00,  3.2264e-02,  2.5120e+00, -2.2885e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.0000e-01,  4.9842e-02],\n",
       "        [ 8.0000e-01, -4.8258e-03],\n",
       "        [ 8.0000e-01, -3.5748e-01],\n",
       "        [ 8.0000e-01, -1.2351e-01],\n",
       "        [ 8.0000e-01, -6.4605e-01],\n",
       "        [ 8.0000e-01,  7.3738e-02],\n",
       "        [ 8.0000e-01, -5.3960e-02],\n",
       "        [ 8.0000e-01,  7.2669e-02],\n",
       "        [-0.0000e+00,  7.5000e-01],\n",
       "        [ 8.0000e-01,  1.3807e-01],\n",
       "        [ 8.0000e-01,  1.8982e-02],\n",
       "        [ 8.0000e-01, -1.3793e-01],\n",
       "        [ 8.0000e-01,  1.1570e-02],\n",
       "        [ 8.0000e-01,  3.9176e-02],\n",
       "        [ 8.0000e-01, -6.1145e-02],\n",
       "        [ 8.0000e-01,  3.9917e-02],\n",
       "        [ 8.0000e-01,  1.1721e-02],\n",
       "        [ 8.0000e-01,  3.7801e-02],\n",
       "        [ 8.0000e-01, -1.4153e-02],\n",
       "        [ 8.0000e-01, -3.7373e-02],\n",
       "        [ 8.0000e-01, -3.2628e-02],\n",
       "        [ 8.0000e-01,  2.0687e-01],\n",
       "        [ 8.0000e-01, -2.4044e-01],\n",
       "        [ 8.0000e-01,  1.9833e-01],\n",
       "        [ 8.0000e-01,  7.1959e-05],\n",
       "        [ 8.0000e-01, -3.8664e-02],\n",
       "        [ 8.0000e-01,  8.3562e-03],\n",
       "        [ 8.0000e-01, -1.9137e-02],\n",
       "        [ 8.0000e-01,  1.7646e-01],\n",
       "        [ 8.0000e-01, -1.5844e-01],\n",
       "        [ 8.0000e-01, -1.1105e-01],\n",
       "        [ 8.0000e-01, -1.2081e-02],\n",
       "        [ 8.0000e-01, -6.3861e-02],\n",
       "        [ 8.0000e-01,  6.0567e-02],\n",
       "        [ 8.0000e-01, -9.5848e-02],\n",
       "        [ 8.0000e-01, -1.4909e-02],\n",
       "        [ 8.0000e-01, -6.3367e-03],\n",
       "        [ 8.0000e-01, -3.0145e-01],\n",
       "        [ 8.0000e-01,  8.0571e-02],\n",
       "        [ 8.0000e-01,  1.0668e+00],\n",
       "        [ 8.0000e-01,  1.1450e-01],\n",
       "        [ 8.0000e-01, -1.4019e-02],\n",
       "        [ 8.0000e-01,  3.3380e-02],\n",
       "        [ 8.0000e-01,  4.2616e-02],\n",
       "        [ 8.0000e-01,  3.4674e-01],\n",
       "        [ 8.0000e-01, -2.2565e-02],\n",
       "        [ 8.0000e-01, -1.1505e+00],\n",
       "        [ 8.0000e-01, -2.1658e-01],\n",
       "        [ 8.0000e-01, -1.5742e-02],\n",
       "        [ 8.0000e-01,  2.7516e-02],\n",
       "        [ 8.0000e-01, -3.1327e-02],\n",
       "        [ 8.0000e-01,  4.8681e-02],\n",
       "        [ 8.0000e-01,  9.2316e-02],\n",
       "        [ 8.0000e-01, -2.9896e-02],\n",
       "        [ 8.0000e-01,  1.4373e-01],\n",
       "        [ 8.0000e-01,  4.0126e-02],\n",
       "        [ 8.0000e-01,  3.4329e-01],\n",
       "        [ 8.0000e-01,  1.8271e-01],\n",
       "        [ 8.0000e-01, -6.6526e-01],\n",
       "        [ 8.0000e-01, -1.1092e-02],\n",
       "        [ 8.0000e-01,  9.2352e-02],\n",
       "        [ 8.0000e-01,  9.8971e-02],\n",
       "        [ 8.0000e-01, -5.8272e-03],\n",
       "        [ 8.0000e-01,  5.1957e-02]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_lidar_features, num_non_lidar_features, num_actions, nframes=1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.act_fea_cv1 = nn.Conv1d(\n",
    "            in_channels=nframes, out_channels=32, kernel_size=5, stride=2, padding=6, padding_mode='circular'\n",
    "        )\n",
    "        self.act_fea_cv2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.randn(1, nframes, num_lidar_features)\n",
    "            sample_output = self.act_fea_cv1(sample_input)\n",
    "            sample_output = self.act_fea_cv2(sample_output)\n",
    "            conv_output_size = sample_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Calculate the output size of the CNN\n",
    "        self.fc1 = nn.Linear(conv_output_size, 64)\n",
    "        self.fc2 = nn.Linear(64 + num_non_lidar_features * nframes, 64)\n",
    "        self.fc3 = nn.Linear(64, num_actions)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, lidar, non_lidar):\n",
    "        feat = F.relu(self.act_fea_cv1(lidar))\n",
    "        feat = F.relu(self.act_fea_cv2(feat))\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        feat = F.relu(self.fc1(feat))\n",
    "        # feat = torch.cat((feat, non_lidar.view(non_lidar.shape[0], -1)), dim=-1)\n",
    "        feat = torch.cat((feat, non_lidar.flatten(start_dim=1)), dim=-1)\n",
    "        feat = F.relu(self.fc2(feat))\n",
    "        feat = self.fc3(feat)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a CustomLoss prioritizing the angular velocity\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # increase the loss of the second element of the prediction\n",
    "        # this is the angular velocity\n",
    "        loss = (pred - target) ** 2\n",
    "        loss[:, 1] *= 2\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 492.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random val loss: 0.8185131336283007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 563.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.03477196830792306 | Val Loss: 0.04523613122725739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 540.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.019062136132050343 | Val Loss: 0.03916491466264802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 201.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:03<00:00, 418.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.0163056290791662 | Val Loss: 0.03590369830372881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 197.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 486.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.014455712143482144 | Val Loss: 0.03261315547363691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 203.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 534.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.0129716305598666 | Val Loss: 0.0307190118183506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 208.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:01<00:00, 713.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.011762176653952882 | Val Loss: 0.029479937901888638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 203.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 567.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.010780408419405332 | Val Loss: 0.027853184163160075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 201.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 585.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.01000603592937595 | Val Loss: 0.02684525865598726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 209.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:03<00:00, 433.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.009393689817355404 | Val Loss: 0.025539754634893056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 207.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 616.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.008914935668082177 | Val Loss: 0.025232353605655643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 209.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 558.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.008530844770479157 | Val Loss: 0.024990845315163344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 535.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.008218234152340239 | Val Loss: 0.02412093720787273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 562.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.00795585878110108 | Val Loss: 0.0240950824195335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:23<00:00, 217.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 626.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.007729178736783734 | Val Loss: 0.023631326076956168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 201.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 551.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.007536111713282916 | Val Loss: 0.023589260034676977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 205.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 525.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.007362285031764165 | Val Loss: 0.02327951028564712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 544.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.007206137939386234 | Val Loss: 0.023348205542170545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:03<00:00, 437.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.007057960221601389 | Val Loss: 0.023063093937487386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 498.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.006921871323121222 | Val Loss: 0.02344501419770713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 202.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 591.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.0067996730415213905 | Val Loss: 0.02310242533438357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:24<00:00, 205.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 553.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.00668021280999283 | Val Loss: 0.023057419721107024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 569.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.006573095471427853 | Val Loss: 0.02329463143621834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 512.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.006471918626153473 | Val Loss: 0.023123010998043935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 199.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 574.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.006379582312074944 | Val Loss: 0.02285372833946428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 579.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.006287113879205693 | Val Loss: 0.0227601714527894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 200.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 550.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.006206611206802444 | Val Loss: 0.023073279410774812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 203.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 540.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.006127463832041107 | Val Loss: 0.022980836212790897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5128/5128 [00:25<00:00, 204.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1357/1357 [00:02<00:00, 570.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.00604751235687856 | Val Loss: 0.022906158379047532\n",
      "Early stopping due to no improvement after 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "sys.stdout.flush()\n",
    "\n",
    "cnn_train_losses = []\n",
    "cnn_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    cnn_train_losses.append(train_loss)\n",
    "    cnn_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cnn_train_losses, label='Train Loss')\n",
    "plt.plot(cnn_val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# torch.save(model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        if loss.item() > 0.1:\n",
    "            print(\"---------------------------\")\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Predicted:\", actions_pred)\n",
    "            print(\"Actual:\", actions)\n",
    "            print(\"Non lidar:\", non_lidar)\n",
    "            continue\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1647 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1300/1647 [00:01<00:00, 1111.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Loss: 0.1398124247789383\n",
      "Predicted: tensor([[0.8128, 0.0417]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.8000, 0.5704]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[ 1.0200e+00,  6.1390e-03,  7.9452e+00, -7.9543e+00]]],\n",
      "       dtype=torch.float64)\n",
      "---------------------------\n",
      "Loss: 0.14218294620513916\n",
      "Predicted: tensor([[0.8077, 0.0372]], grad_fn=<AddmmBackward0>)\n",
      "Actual: tensor([[0.8000, 0.5704]], dtype=torch.float64)\n",
      "Non lidar: tensor([[[ 1.0040e+00,  6.3563e-03,  7.9292e+00, -7.9366e+00]]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1647/1647 [00:01<00:00, 1126.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val loss: 0.0023418728097762314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load file and check MSELoss\n",
    "model = CNNModel(num_lidar_features, num_non_lidar_features, num_actions)\n",
    "model.load_state_dict(torch.load('cnn_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 100], \"val\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            dropout=0.0,\n",
    "            bias=False,\n",
    "            encoder_decoder_attention=False,\n",
    "            causal=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.k_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.q_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(input_dim, input_dim, bias=bias)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_dim,)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def multi_head_scaled_dot_product(self,\n",
    "                                      query: torch.Tensor,\n",
    "                                      key: torch.Tensor,\n",
    "                                      value: torch.Tensor,\n",
    "                                      attention_mask: torch.BoolTensor):\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2) / math.sqrt(self.input_dim))\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
    "            else:\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_probs, value)\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.input_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            query: torch.Tensor,\n",
    "            key: torch.Tensor,\n",
    "            attention_mask: torch.BoolTensor):\n",
    "        q = self.q_proj(query)\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.multi_head_scaled_dot_product(q, k, v, attention_mask)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(input_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, input_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class EmbeddingLidar(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.len_lidar = config.lidar_dim\n",
    "        self.num_patch = config.num_patch\n",
    "        self.dim_patch = self.len_lidar // self.num_patch\n",
    "        self.model_dim = config.model_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.pos_embed = nn.Parameter(torch.randn(self.num_patch, self.model_dim))\n",
    "\n",
    "        self.linear = nn.Linear(self.dim_patch, self.model_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view([-1, self.num_patch, self.dim_patch])\n",
    "        x = self.linear(x)\n",
    "        x = x + self.pos_embed\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        self.embedding = EmbeddingLidar(config)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, inputs, attention_mask=None):\n",
    "        x = self.embedding(inputs)\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "\n",
    "        return x, self_attn_scores\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_dim = config.input_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.dropout = config.dropout\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            input_dim=self.input_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.input_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.input_dim)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask=None,\n",
    "    ):\n",
    "        residual = x\n",
    "        x, cross_attn_weights = self.encoder_attn(\n",
    "            query=x,\n",
    "            key=encoder_hidden_states,\n",
    "            attention_mask=encoder_attention_mask,\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.encoder_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        return (\n",
    "            x,\n",
    "            cross_attn_weights,\n",
    "        )\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.model_dim = config.model_dim\n",
    "        self.linear = nn.Linear(1, self.model_dim)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            inputs,\n",
    "            encoder_hidden_states,\n",
    "    ):\n",
    "        x = inputs\n",
    "        x = self.linear(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        cross_attention_scores = []\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "            x, layer_cross_attn = decoder_layer(\n",
    "                x,\n",
    "                encoder_hidden_states,\n",
    "            )\n",
    "            cross_attention_scores.append(layer_cross_attn.detach())\n",
    "        return x, cross_attention_scores\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.non_lidar_dim = config.non_lidar_dim\n",
    "        self.model_dim = config.model_dim\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "        self.prediction_head = nn.Linear(self.model_dim * self.non_lidar_dim, 2)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            inputs=src\n",
    "        )\n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg,\n",
    "            encoder_output\n",
    "        )\n",
    "        decoder_output = decoder_output.view(-1, self.model_dim * self.non_lidar_dim)\n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "        \n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(train_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())\n",
    "\n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "# Initialize the model\n",
    "num_lidar_features = len(train_dataset.lidar_cols)\n",
    "num_non_lidar_features = len(train_dataset.non_lidar_cols)\n",
    "num_actions = len(train_dataset.actions_cols)\n",
    "\n",
    "config_dict = easydict.EasyDict({\n",
    "    \"input_dim\": 32,\n",
    "    \"num_patch\": 36,\n",
    "    \"model_dim\": 32,\n",
    "    \"ffn_dim\": 256,\n",
    "    \"attention_heads\": 4,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dropout\": 0.5,\n",
    "    \"encoder_layers\": 2,\n",
    "    \"decoder_layers\": 2,\n",
    "    \"lidar_dim\": 360,\n",
    "    \"non_lidar_dim\": 4,\n",
    "    \"device\": \"cpu\",\n",
    "})\n",
    "\n",
    "model = Transformer(config_dict)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "random_val_loss = test_model(model, val_loader, loss_fn)\n",
    "print(\"Random val loss:\", random_val_loss)\n",
    "\n",
    "transformer_train_losses = []\n",
    "transformer_val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve_epochs = 0\n",
    "save_every = 5\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    val_loss = test_model(model, val_loader, loss_fn)\n",
    "    transformer_train_losses.append(train_loss)\n",
    "    transformer_val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping due to no improvement after {} epochs.\".format(patience))\n",
    "            break\n",
    "    \n",
    "    # if epoch % save_every == 0:\n",
    "    #     torch.save(model.state_dict(), f'transformer_model_{epoch}.pth')\n",
    "    #     print(f\"Model saved at epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(transformer_train_losses, label='Transformer Train Loss')  \n",
    "plt.plot(transformer_val_losses, label='Transformer Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    for lidar, non_lidar, actions in tqdm(test_loader):\n",
    "        # Move the data to the device that is used\n",
    "        lidar = lidar.to(device).unsqueeze(-1)\n",
    "        non_lidar = non_lidar.to(device).unsqueeze(-1)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        actions_pred, _, _ = model(lidar.float(), non_lidar.float())        \n",
    "        loss = loss_fn(actions_pred, actions.float())\n",
    "        if loss.item() > 0.01:\n",
    "            print(actions_pred - actions)\n",
    "            print(loss)\n",
    "\n",
    "        # Save the loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # return the average loss for this epoch\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(config_dict)\n",
    "model.load_state_dict(torch.load('transformer_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "# take world idx 0 as example\n",
    "dataset = KULBarnDataset(df[df['world_idx'] == 0], \"val\")\n",
    "print(len(dataset))\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "final_val_loss = test_model(model, loader, loss_fn)\n",
    "print(\"Final val loss:\", final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import shutil\n",
    "from diffusion_policy.policy.diffusion_unet_lowdim_policy import DiffusionUnetLowdimPolicy\n",
    "from diffusion_policy.workspace.train_diffusion_unet_lowdim_workspace import TrainDiffusionUnetLowdimWorkspace\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "from diffusion_policy.common.replay_buffer import ReplayBuffer\n",
    "from diffusion_policy.common.sampler import (\n",
    "    SequenceSampler, get_val_mask, downsample_mask)\n",
    "from diffusion_policy.model.common.normalizer import LinearNormalizer\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "\n",
    "\n",
    "class KULBarnDiffusionDataset(BaseLowdimDataset):\n",
    "    def __init__(self, df, horizon=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = df\n",
    "        self.get_local_goal()\n",
    "\n",
    "        self.data = self.data.drop(columns=[\n",
    "            'timestep', 'actual_time', 'optimal_time', \n",
    "            'pos_x', 'pos_y', 'pose_heading', 'goal_x', 'goal_y', 'success'\n",
    "        ])\n",
    "        \n",
    "        self.data = pd.DataFrame(self.data, columns=self.data.columns)\n",
    "        self.horizon = horizon\n",
    "\n",
    "        # Process data columns\n",
    "        self.lidar_cols = [col for col in self.data.columns if 'lidar' in col]\n",
    "        self.actions_cols = [col for col in self.data.columns if 'cmd' in col]\n",
    "        self.non_lidar_cols = [col for col in self.data.columns if col not in self.lidar_cols and col not in self.actions_cols and col != 'world_idx']\n",
    "\n",
    "        self.lidar_data = self.data[self.lidar_cols].values\n",
    "        self.non_lidar_data = self.data[self.non_lidar_cols].values\n",
    "        self.actions_data = self.data[self.actions_cols].values\n",
    "\n",
    "        print(\"Lidar Columns:\", self.lidar_cols)\n",
    "        print(\"Non Lidar Columns:\", self.non_lidar_cols)\n",
    "        print(\"Action Columns:\", self.actions_cols)     \n",
    "\n",
    "        self.grouped_data = self.data.groupby(self.data['world_idx'])\n",
    "        self.horizon = horizon\n",
    "        path_lengths = [len(group) for name, group in self.grouped_data]\n",
    "        self.indices = self.make_indices(path_lengths, horizon)\n",
    "\n",
    "    def get_local_goal(self):\n",
    "        x = self.data['pos_x']\n",
    "        y = self.data['pos_y']\n",
    "        theta = self.data['pose_heading']\n",
    "        goal_x = self.data['goal_x']\n",
    "        goal_y = self.data['goal_y']\n",
    "        self.data['local_x'] = (goal_x - x) * np.cos(theta) + (goal_y - y) * np.sin(theta)\n",
    "        self.data['local_y'] = -(goal_x - x) * np.sin(theta) + (goal_y - y) * np.cos(theta)\n",
    "\n",
    "    def make_indices(self, path_lengths, horizon):\n",
    "        indices = []\n",
    "        for i, path_length in enumerate(path_lengths):\n",
    "            max_start = path_length - horizon\n",
    "            for start in range(max_start):\n",
    "                end = start + horizon\n",
    "                indices.append((i, start, end))\n",
    "        indices = np.array(indices)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        idx = self.indices[idx]\n",
    "        start = idx[1]\n",
    "        end = idx[2]\n",
    "\n",
    "        data = {\n",
    "            'obs': self.lidar_data[start:end],\n",
    "            'cond': self.non_lidar_data[start:end],\n",
    "            'action': self.actions_data[start:end],\n",
    "        }\n",
    "        torch_data = dict_apply(data, torch.from_numpy)\n",
    "        return torch_data\n",
    "\n",
    "    def get_normalizer(self, mode='limits', **kwargs):\n",
    "        normalizer = LinearNormalizer()\n",
    "        # train it in using self.data as a dictionary\n",
    "        data_dict = {\n",
    "            'obs': self.lidar_data,\n",
    "            'cond': self.non_lidar_data,\n",
    "            'action': self.actions_data\n",
    "        }\n",
    "        normalizer.fit(data=data_dict, mode=mode, **kwargs)\n",
    "        return normalizer\n",
    "\n",
    "    def get_all_actions(self) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.actions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KULBarnDiffusionDataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "normalizer = train_dataset.get_normalizer()\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    # print(batch)\n",
    "    print(batch['obs'].shape)\n",
    "    print(batch['cond'].shape)\n",
    "    print(batch['action'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_policy.policy.diffusion_unet_lidar_policy import DiffusionUnetLidarPolicy\n",
    "from diffusion_policy.model.diffusion.conditional_unet1d import ConditionalUnet1D\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "\n",
    "obs_dim = batch['obs'].shape[-1]\n",
    "action_dim = batch['action'].shape[-1]\n",
    "input_dim = obs_dim + action_dim\n",
    "model = ConditionalUnet1D(input_dim=input_dim)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='linear')\n",
    "horizon = 4\n",
    "policy = DiffusionUnetLidarPolicy(\n",
    "    model=model, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    horizon=horizon, \n",
    "    obs_dim=obs_dim, \n",
    "    action_dim=action_dim, \n",
    "    n_obs_steps=4,\n",
    "    n_action_steps=4,\n",
    "    pred_action_steps_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.set_normalizer(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "losses = []\n",
    "save_loss_every = 1000\n",
    "total_loss = 0\n",
    "count = 0\n",
    "\n",
    "optimizer = optim.Adam(policy.model.parameters(), lr=5e-5)\n",
    "policy.model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        loss = policy.compute_loss(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        count += 1\n",
    "        if count >= save_loss_every:\n",
    "            curr_loss = total_loss / save_loss_every\n",
    "            print(\"Loss:\", curr_loss)\n",
    "            losses.append(curr_loss)\n",
    "            total_loss = 0\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
